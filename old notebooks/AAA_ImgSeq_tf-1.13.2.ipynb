{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": false
   },
   "source": [
    "# AAA Image Segmentation\n",
    "This notebook will set up and either train a network or predict segmentations based on previous training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Preliminary steps\n",
    "Load all the relevant libraries and set up some global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "preamble",
     "main",
     "main-no_create"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.6\n",
      "3.7.6 (default, Feb 17 2020, 15:12:51) \n",
      "[GCC 7.4.0]\n",
      "2.1.0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "`get_session` is not available when using TensorFlow 2.0.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5ea7316bfb1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m#Clean session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_tf_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         raise RuntimeError(\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0;34m'`get_session` is not available '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             'when using TensorFlow 2.0.')\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: `get_session` is not available when using TensorFlow 2.0."
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import sys\n",
    "import os\n",
    "import os.path as osp\n",
    "import shutil\n",
    "import datetime\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import traceback\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam\n",
    "from keras_radam import RAdam\n",
    "from tensorflow.keras.layers import ReLU\n",
    "from keras_contrib.layers.advanced_activations.swish import Swish\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "#from keras.backend.tensorflow_backend import clear_session\n",
    "#from keras.backend.tensorflow_backend import get_session\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from tqdm.keras import TqdmCallback\n",
    "#import talos as ta\n",
    "from talos.model.early_stopper import early_stopper\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "# local package\n",
    "from tf_mmciad.utils.io import create_samples, load_slides_as_dict\n",
    "from tf_mmciad.utils.generator import DataGenerator\n",
    "from tf_mmciad.utils.u_net import u_net\n",
    "from tf_mmciad.utils.u_resnet import u_resnet\n",
    "from tf_mmciad.utils.custom_loss import weighted_loss, jaccard2_loss, tversky_loss, categorical_focal_loss, get_weighted_categorical_crossentropy\n",
    "from tf_mmciad.utils.preprocessing import calculate_stats, augmentor, calculate_class_weights, class_ratio\n",
    "from tf_mmciad.utils.callbacks import PatchedModelCheckpoint, DeadReluDetector\n",
    "\n",
    "\n",
    "\n",
    "print(platform.python_version())\n",
    "print(sys.version)\n",
    "###################################\n",
    "#Clean session\n",
    "print(tf.__version__)\n",
    "sess = get_session()\n",
    "clear_session()\n",
    "sess.close()\n",
    "# TensorFlow wizardry\n",
    "config = tf.ConfigProto(log_device_placement=True)\n",
    "\n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "# Only allow a total of half the GPU memory to be allocated\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "\n",
    "# Create a session with the above options specified.\n",
    "K.tensorflow_backend.set_session(tf.Session(config=config))\n",
    "###################################\n",
    "\n",
    "# Magic used by the notebook to show figures inline\n",
    "\n",
    "%matplotlib inline\n",
    "# matplotlib default values\n",
    "plt.rcParams[\"figure.figsize\"] = (20.0, 16.0)\n",
    "plt.rcParams[\"image.interpolation\"] = \"nearest\"\n",
    "plt.rcParams[\"image.cmap\"] = \"jet\"\n",
    "\n",
    "# auto-reloading packages\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "preamble",
     "main",
     "main-no_create"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ignore*', 'Zone 1', 'Zone 2', 'Thrombus']\n",
      "{1: [180, 180, 180], 2: [0, 0, 255], 3: [0, 255, 0], 4: [255, 0, 0]}\n",
      "(4, 3)\n"
     ]
    }
   ],
   "source": [
    "from skimage.io import imread, imsave\n",
    "from glob import glob\n",
    "\n",
    "class_map = {\n",
    "    \"None\": 0,\n",
    "    \"Ignore*\": 1,\n",
    "    \"Zone 1\": 2,\n",
    "    \"Zone 2\": 3,\n",
    "    \"Thrombus\": 4,\n",
    "}\n",
    "\n",
    "class_colors = {\n",
    "    0: [0, 0, 0],\n",
    "    1: [180, 180, 180],\n",
    "    2: [0, 0, 255],\n",
    "    3: [0, 255, 0],\n",
    "    4: [255, 0, 0],\n",
    "}\n",
    "active_labels = [1, 2, 3, 4]\n",
    "active_classes = [sorted(class_map, key=class_map.get)[i] for i in active_labels]\n",
    "print(active_classes)\n",
    "colorvec = np.asarray([class_colors[i] for i in active_labels])\n",
    "active_colors = {class_: class_colors[class_] for class_ in active_labels}\n",
    "num_cls = len(active_labels)\n",
    "print(active_colors)\n",
    "print(colorvec.shape)\n",
    "ignore_cls = 0\n",
    "\n",
    "data_path = \"data/\"\n",
    "wsi_path = \"data/WSI/\"\n",
    "train_path = \"training/\"\n",
    "val_path = \"validation/\"\n",
    "test_path = \"testing/\"\n",
    "model_storage = \"models\"\n",
    "ignore_color = class_colors[0]\n",
    "TILE_SIZE = (384, 384)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "main"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Train set:\n",
      "    ---------\n",
      "    Created 2905 X tiles in directory: data/training/.\n",
      "    Created 2905 Y tiles in directory: data/training/gt/.\n",
      "    \n",
      "    Validation set:\n",
      "    ---------------\n",
      "    Created 1154 X tiles in directory: data/validation/.\n",
      "    Created 1154 Y tiles in directory: data/validation/gt/.\n",
      "    \n",
      "    Test set:\n",
      "    ---------\n",
      "    Created 0 X tiles in directory data/testing/.\n",
      "    Created 0 Y tiles in directory data/testing/gt/.\n"
     ]
    }
   ],
   "source": [
    "#duplicate = [class_colors[label] for label in [2, 3, 6, 9, 11]]\n",
    "def get_color(name: str) -> list:\n",
    "    return class_colors[class_map[name]]\n",
    "\n",
    "filter_dict = {\n",
    "    \"Ignore*\": (get_color(\"Ignore*\"), 0.9, 0.9, 1.0),\n",
    "}\n",
    "\n",
    "patient_IDs = {osp.splitext(osp.basename(fname))[0] for fname in glob(osp.join(wsi_path, \"train-*.tif\"))}\n",
    "patient_patterns = [patient_ID + '*' for patient_ID in patient_IDs]\n",
    "\n",
    "#create_samples(osp.join(wsi_path), filter_dict, output_dir=\"../training\", tile_size=TILE_SIZE)\n",
    "#create_samples(data_path, filter_dict, \"test\")\n",
    "\n",
    "# Create a random list of training tiles\n",
    "# train_list = glob(osp.join(data_path, train_path, \"*.tif\"))\n",
    "# np.random.shuffle(train_list)\n",
    "# VAL_FRACTION = .25\n",
    "# sample_length = len(train_list)\n",
    "# val_size = round(sample_length*VAL_FRACTION)\n",
    "\n",
    "# val_from_list = train_list[:val_size]\n",
    "# Create a mirror list of GT tiles\n",
    "# val_from_gt_list = [\n",
    "#     osp.join(data_path, train_path, \"gt/\", osp.split(i)[1]) for i in val_from_list\n",
    "# ]\n",
    "# Create list of target paths for each element in val_from_list and val_from_gt_list\n",
    "# val_to_list = [\n",
    "#     osp.join(data_path, val_path, osp.split(val_from_list[i])[1]) for i in range(val_size)\n",
    "# ]\n",
    "# val_to_gt_list = [\n",
    "#     osp.join(data_path, val_path, \"gt/\", osp.split(val_from_gt_list[i])[1])\n",
    "#     for i in range(val_size)\n",
    "# ]\n",
    "# # Copy the chosen tiles from train to val\n",
    "# os.makedirs(osp.join(data_path, val_path, \"gt\", \"\"), exist_ok=True)\n",
    "# for i in range(val_size):\n",
    "#     os.rename(val_from_list[i], val_to_list[i])\n",
    "#     os.rename(val_from_gt_list[i], val_to_gt_list[i])\n",
    "\n",
    "def file_counter(path: str) -> int:\n",
    "    if osp.exists(path):\n",
    "        return len([name for name in os.listdir(path) if os.path.isfile(osp.join(path, name))])\n",
    "    return \"no\"\n",
    "\n",
    "ds = {\n",
    "    'x':  osp.join(data_path, train_path),\n",
    "    'y':  osp.join(data_path, train_path, \"gt/\"),\n",
    "    'xv': osp.join(data_path, val_path),\n",
    "    'yv': osp.join(data_path, val_path, \"gt/\"),\n",
    "    'xt': osp.join(data_path, test_path),\n",
    "    'yt': osp.join(data_path, test_path, \"gt/\"),\n",
    "}\n",
    "\n",
    "print(\n",
    "    \"\"\"\n",
    "    Train set:\n",
    "    ---------\n",
    "    Created {} X tiles in directory: {}.\n",
    "    Created {} Y tiles in directory: {}.\n",
    "    \n",
    "    Validation set:\n",
    "    ---------------\n",
    "    Created {} X tiles in directory: {}.\n",
    "    Created {} Y tiles in directory: {}.\n",
    "    \n",
    "    Test set:\n",
    "    ---------\n",
    "    Created {} X tiles in directory {}.\n",
    "    Created {} Y tiles in directory {}.\"\"\".\n",
    "    format(\n",
    "        file_counter(ds['x']), ds['x'],\n",
    "        file_counter(ds['y']), ds['y'],\n",
    "        file_counter(ds['xv']), ds['xv'],\n",
    "        file_counter(ds['yv']), ds['yv'],\n",
    "        file_counter(ds['xt']), ds['xt'],\n",
    "        file_counter(ds['yt']), ds['yt'],\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "main",
     "preamble",
     "main-no_create"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:59<00:00,  7.50s/it]\n"
     ]
    }
   ],
   "source": [
    "train_m, train_s, x_min, x_max = calculate_stats(path=\"data/WSI/\") #, local=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import imgaug as ia\n",
    "from imgaug import augmenters as iaa\n",
    "plt.rcParams['figure.figsize'] = (20.0, 16.0)\n",
    "mytest = imread(\"./data/train/gt/X_1001.tif\")\n",
    "warp = iaa.PiecewiseAffine(scale=0.05, nb_rows=6, nb_cols=6, mode='reflect')\n",
    "trans = iaa.ElasticTransformation(alpha=80, sigma=(8.0), mode=\"reflect\")\n",
    "warp_label = warp.augment_image(mytest)\n",
    "twarp_label = trans.augment_image(warp_label)\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(mytest)\n",
    "plt.title(\"label\")\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(warp_label)\n",
    "plt.title(\"warp\")\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(twarp_label)\n",
    "plt.title(\"warp+elastic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Data Augmentation for Segmentation\n",
    "This part will artificially increase the data set to improve the networks ability to generalize.\n",
    "Currently this is a very rudimentary procedure involving flips and 90 degree rotations. This can be changed in the future (See e.g. [ImgAug](https://github.com/aleju/imgaug))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "toc-hr-collapsed": false
   },
   "source": [
    "## U-net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "main",
     "model_init",
     "main-no_create"
    ]
   },
   "outputs": [],
   "source": [
    "# Calculate the class weights for the training data set\n",
    "# Optionally exclude a label by settings its weight to 0 using the ignore=label option\n",
    "cls_wgts = calculate_class_weights(data_path, active_labels, class_colors, ignore=ignore_cls)\n",
    "print(\"cls_wgts:\\n\", cls_wgts)\n",
    "class_ratios = class_ratio(data_path, active_labels, class_colors)\n",
    "print(\"class_ratios:\\n\", class_ratios)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from mmciad.utils.custom_loss import w_categorical_crossentropy\n",
    "cls_wgts = {0: 0.6462842253714038, 1: 4.277279367175925, 2: 0.7650382887989682, 3: 2.3366233721836207,\n",
    "            5: 0.38495865467512297, 6: 11.749891543465838, 7: 0.7357313031667244,\n",
    "            9: 3.3815931126719256, 10: 107.61779250337312, 11: 0.5449941506459005, 12: 0}\n",
    "w_array = np.ones((num_cls,num_cls))\n",
    "for cls_id, weight in enumerate(cls_wgts.values()):\n",
    "    w_array[cls_id, :] = weight # populate False negatives\n",
    "w_array[:, -1] = 100.0 # Increase False Negative penalty for IGNORE class\n",
    "np.fill_diagonal(w_array, 1) # Populate True positives\n",
    "w_array[-1, :] = 0.0 # Remove False positives penalty for IGNORE class\n",
    "#w_array_t = w_array.swapaxes(0, 1)\n",
    "w_array[2,  7] = 70 # Guessing Epithelium as Dysplasia\n",
    "w_array[2,  9] = 80 # Guessing Epithelium as Cancer\n",
    "w_array[9,  2] = 100 # Guessing Cancer as Epithelium\n",
    "w_array[7,  2] = 90 # Guessing Dysplasia as Epithelium\n",
    "w_array[4,  6] = 2 # Guessing Stroma as Inflammation\n",
    "w_array[4,  9] = 40 # Guessing Stroma as Cancer\n",
    "w_array[6,  4] = 4 # Guessing Inflammation as Stroma\n",
    "w_array[6,  9] = 30 # Guessing Inflammation as Cancer\n",
    "\n",
    "\n",
    "\n",
    "r\"\"\"\n",
    "    Example weight matrix\n",
    "\n",
    " -> False positives\n",
    " v  False negatives\n",
    " \\ True positives, always 1\n",
    "\n",
    "                True class\n",
    "P\n",
    "r    ___|  A  |  B  |  C  |  D  |  E\n",
    "e c   A |  1  | 3.0 | 0.5 | 1.7 | 0.3 \n",
    "d l   B | 0.6 |  1  | 0.5 | 1.7 | 0.3\n",
    "i a   C | 0.6 | 3.0 |  1  | 1.7 | 0.3\n",
    "c s   D | 0.6 | 3.0 | 0.5 |  1  | 0.3\n",
    "t s   E | 0.6 | 3.0 | 0.5 | 1.7 |  1\n",
    "e\n",
    "d\n",
    "\"\"\"\n",
    "with np.printoptions(precision=3, suppress=True, linewidth=100):\n",
    "    print(w_array)\n",
    "w_ce = partial(w_categorical_crossentropy, weights=w_array)\n",
    "w_ce.__name__ = 'weighted_categorical_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "main",
     "train",
     "model_init",
     "main-no_create"
    ]
   },
   "outputs": [],
   "source": [
    "w_TL = weighted_loss(tversky_loss, cls_wgts)\n",
    "#w_cat_CE = weighted_loss(categorical_crossentropy, cls_wgts)\n",
    "#w_cat_CE = get_weighted_categorical_crossentropy(weights=[v for v in cls_wgts.values()])\n",
    "w_TL.__name__ = \"w_TL\"\n",
    "#w_cat_CE.__name__ = \"w_cat_CE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true,
    "tags": [
     "main",
     "train",
     "model_init",
     "main-no_create"
    ]
   },
   "outputs": [],
   "source": [
    "from mmciad.utils.hyper import talos_presets\n",
    "\n",
    "# I/O Params\n",
    "weight_path = \"./weights/\"\n",
    "\n",
    "IMG_ROWS, IMG_COLS, IMG_CHANNELS = (None, None, 3)\n",
    "# architecture params\n",
    "NB_FILTERS_0 = 64\n",
    "SIGMA_NOISE = 0.01\n",
    "\n",
    "# ****  deep learning model\n",
    "SHAPE = (IMG_ROWS, IMG_COLS, IMG_CHANNELS)\n",
    "BATCH_SIZE = 16\n",
    "NB_EPOCH = 400\n",
    "NB_FROZEN = 40\n",
    "VERBOSE = 0\n",
    "\n",
    "# ****  train\n",
    "today_str = str(datetime.date.today())\n",
    "\n",
    "train_generator = DataGenerator(\n",
    "    osp.join(data_path, train_path),\n",
    "    colorvec,\n",
    "    train_m,\n",
    "    train_s,\n",
    "    x_min,\n",
    "    x_max,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    dim=(208, 208),\n",
    "    n_channels=3,\n",
    "    n_classes=num_cls,\n",
    "    shuffle=True,\n",
    "    augmenter=True,\n",
    ")\n",
    "\n",
    "val_generator = DataGenerator(\n",
    "    osp.join(data_path, val_path),\n",
    "    colorvec,\n",
    "    train_m,\n",
    "    train_s,\n",
    "    x_min,\n",
    "    x_max,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    dim=(208, 208),\n",
    "    n_channels=3,\n",
    "    n_classes=num_cls,\n",
    "    shuffle=True,\n",
    "    augmenter=True,\n",
    ")\n",
    "\n",
    "statics = {\n",
    "    \"shape\": SHAPE,\n",
    "    \"nb_epoch\": NB_EPOCH,\n",
    "    \"nb_frozen\": NB_FROZEN,\n",
    "    \"nb_filters_0\": NB_FILTERS_0,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"verbose\": VERBOSE,\n",
    "    \"num_cls\": num_cls,\n",
    "    \"batchnorm\": True,\n",
    "    \"maxpool\": False,\n",
    "    \"today_str\": today_str,\n",
    "    \"opt\": Adam,\n",
    "    \"depth\": 4,\n",
    "    \"arch\": \"U-Net\",\n",
    "    \"dropout\": 0,\n",
    "    \"decay\": 0.0,\n",
    "    \"sigma_noise\": 0,\n",
    "    #\"act\": 'relu',\n",
    "    \"pretrain\": 0,\n",
    "    \"lr\": 1e-4,\n",
    "    \"class_weights\": False,\n",
    "    \"loss_func\": \"cat_CE\",\n",
    "    \"init\": \"he_normal\",\n",
    "}\n",
    "\n",
    "# fit params\n",
    "p = {\n",
    "    #\"dropout\": [0],\n",
    "    #\"decay\": [0.0],\n",
    "    #\"lr\": [1e-3, 1e-4, 1e-5],\n",
    "    #\"sigma_noise\": [0],\n",
    "    \"nb_filters_0\": [12, 16, 32],\n",
    "    #\"pretrain\": [0, 2, 4],\n",
    "    #\"class_weights\": [True, False],\n",
    "    #\"loss_func\": [\"cat_CE\", \"tversky_loss\", \"cat_FL\"],\n",
    "    \"arch\": [\"U-ResNet\"],\n",
    "    \"act\": [Swish, ReLU],\n",
    "    #\"opt\": [RAdam, Adam]\n",
    "    #\"init\": [\"he_normal\", \"glorot_uniform\"]\n",
    "}\n",
    "\n",
    "talos_model = talos_presets(weight_path, cls_wgts, statics, train_generator, val_generator)\n",
    "\n",
    "dummy_x = np.empty((1, BATCH_SIZE, 208, 208))\n",
    "dummy_y = np.empty((1, BATCH_SIZE))\n",
    "try:\n",
    "    t = ta.Scan(\n",
    "        x=dummy_x,\n",
    "        y=dummy_y,\n",
    "        disable_progress_bar=False,\n",
    "        print_params=True,\n",
    "        model=talos_model,\n",
    "        params=p,\n",
    "        experiment_name=today_str,\n",
    "    )\n",
    "except Exception as e:\n",
    "    logger.error(str(e))\n",
    "    logger.error(traceback.format_exc())\n",
    "    raise\n",
    "\n",
    "#print(model.summary(line_length=124))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "r = ta.Reporting('2019-09-20.csv')\n",
    "\n",
    "r.data.replace(to_replace=r\"[<][a-z '_.]*(Swish'>)\",value='Swish', inplace=True, regex=True)\n",
    "r.data.replace(to_replace=r\"[<][a-z '_.]*(ReLU'>)\",value='Relu', inplace=True, regex=True)\n",
    "r.data.replace(to_replace=r\"[<][a-z '_.]*(RAdam'>)\",value=\"RAdam\", inplace=True, regex=True)\n",
    "r.data.replace(to_replace=r\"[<][a-z '_.]*(Adam'>)\",value=\"Adam\", inplace=True, regex=True)\n",
    "r.data.drop(labels=[\"lr\"], axis=1, inplace=True)\n",
    "#r.data.drop(labels=[\"weighted_acc\", \"val_weighted_acc\",\"lr\", \"decay\",\"dropout\",\"sigma_noise\",\"lr.1\"], axis=1, inplace=True)\n",
    "#r.plot_corr('val_categorical_accuracy')\n",
    "#r.best_params('val_categorical_accuracy')\n",
    "r.plot_corr(\"acc\", color_grades=5)\n",
    "r.plot_box(x=\"act\", y=\"acc\")\n",
    "r.plot_box(x=\"opt\", y=\"acc\")\n",
    "#r.best_params()\n",
    "r.table(\"acc\", sort_by=\"acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('talos_scan_object.pickle', mode='w+b') as f:\n",
    "    pickle.dump(t, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#ta.Deploy(t,\"U-nets\", metric=\"acc\")\n",
    "#t.best_model(metric=\"acc\")\n",
    "from keras.models import model_from_json\n",
    "custom_layers = {'Swish': Swish, 'RAdam': RAdam}\n",
    "best_model = model_from_json(t.saved_models[7], custom_layers)\n",
    "best_model.set_weights(t.saved_weights[7])\n",
    "best_model.save(\"best_model.h5\")\n",
    "best_model.summary(line_length=127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "main",
     "train"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3589.2V Weigert*\n"
     ]
    }
   ],
   "source": [
    "# I/O Params\n",
    "weight_path = \"./weights/\"\n",
    "\n",
    "IMG_ROWS, IMG_COLS, IMG_CHANNELS = (*TILE_SIZE, 3)\n",
    "#IMG_ROWS, IMG_COLS, IMG_CHANNELS = (None, None, 3)\n",
    "# architecture params\n",
    "NB_FILTERS_0 = 64\n",
    "SIGMA_NOISE = 0.01\n",
    "\n",
    "# ****  deep learning model\n",
    "SHAPE = (IMG_ROWS, IMG_COLS, IMG_CHANNELS)\n",
    "BATCH_SIZE = 12\n",
    "NB_EPOCH = 400\n",
    "NB_FROZEN = 40\n",
    "VERBOSE = 0\n",
    "# fit params\n",
    "today_str = str(datetime.date.today())\n",
    "DROP = 0\n",
    "\n",
    "OPT_NAME = \"adam\"  # choices:adadelta; sgd, rmsprop, adagrad, adam\n",
    "if OPT_NAME == \"sgd\":\n",
    "    OPT = SGD(lr=0.1)\n",
    "elif OPT_NAME == \"rmsprop\":\n",
    "    OPT = RMSprop()\n",
    "elif OPT_NAME == \"adagrad\":\n",
    "    OPT = Adagrad()\n",
    "elif OPT_NAME == \"adadelta\":\n",
    "    OPT = Adadelta()\n",
    "elif OPT_NAME == \"adam\":\n",
    "    OPT = Adam(lr=1e-3, decay=0.0)\n",
    "elif OPT_NAME == \"amsgrad\":\n",
    "    OPT = Adam(lr=1e-4, amsgrad=True)\n",
    "elif OPT_NAME == \"adamax\":\n",
    "    OPT = Adamax()\n",
    "elif OPT_NAME == \"nadam\":\n",
    "    OPT = Nadam()\n",
    "else:\n",
    "    raise NameError(\"Wrong optimizer name\")\n",
    "\n",
    "def moveFilesinDir(src_dir: str, dst_dir: str, pattern=None) -> None:\n",
    "    # Check if both the are directories\n",
    "    if os.path.isdir(src_dir) and os.path.isdir(dst_dir) :\n",
    "        # Iterate over all the files in source directory\n",
    "        if pattern is None:\n",
    "            files = glob(src_dir + '*')\n",
    "            with tqdm(total=len(files)) as pbar:\n",
    "                for file_path in files:\n",
    "                    # Move each file to destination Directory\n",
    "                    shutil.move(file_path, dst_dir)\n",
    "                    pbar.update(1)\n",
    "        if isinstance(pattern, str):\n",
    "            files = glob(src_dir + pattern)\n",
    "            with tqdm(total=len(files)) as pbar:\n",
    "                for file_path in files:\n",
    "                    # Move each file to destination Directory\n",
    "                    shutil.move(file_path, dst_dir)\n",
    "                    pbar.update(1)\n",
    "        if isinstance(pattern, list):\n",
    "            with tqdm(total=len(pattern)) as pbar:\n",
    "                for group in pattern:\n",
    "                    files = glob(src_dir + group)\n",
    "                    with tqdm(total=len(files)) as inner_pbar:\n",
    "                        for file_path in files:\n",
    "                            # Move each file to destination Directory\n",
    "                            shutil.move(file_path, dst_dir)\n",
    "                            inner_pbar.update(1)\n",
    "                    pbar.update(1)\n",
    "    else:\n",
    "        print(\"src_dir & dst_dir should be directories\")\n",
    "\n",
    "patient_patterns = [name.replace('train-','') for name in patient_patterns]\n",
    "print(patient_patterns[-1])\n",
    "moveFilesinDir(osp.join(data_path, train_path, ''), osp.join(data_path, val_path, ''), patient_patterns[-1])\n",
    "moveFilesinDir(osp.join(data_path, train_path, 'gt', ''), osp.join(data_path, val_path, 'gt', ''), patient_patterns[-1])\n",
    "\n",
    "train_generator = DataGenerator(\n",
    "    osp.join(data_path, train_path),\n",
    "    active_colors,\n",
    "    train_m,\n",
    "    train_s,\n",
    "    x_min,\n",
    "    x_max,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    dim=TILE_SIZE,\n",
    "    n_channels=3,\n",
    "    n_classes=num_cls,\n",
    "    shuffle=True,\n",
    "    augment=True,\n",
    ")\n",
    "\n",
    "val_generator = DataGenerator(\n",
    "    osp.join(data_path, val_path),\n",
    "    active_colors,\n",
    "    train_m,\n",
    "    train_s,\n",
    "    x_min,\n",
    "    x_max,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    dim=TILE_SIZE,\n",
    "    n_channels=3,\n",
    "    n_classes=num_cls,\n",
    "    shuffle=True,\n",
    "    augment=False,\n",
    ")\n",
    "\n",
    "# test_generator = DataGenerator(\n",
    "#     osp.join(data_path, test_path),\n",
    "#     colorvec,\n",
    "#     train_m,\n",
    "#     train_s,\n",
    "#     x_min,\n",
    "#     x_max,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     dim=(208, 208),\n",
    "#     n_channels=3,\n",
    "#     n_classes=num_cls,\n",
    "#     shuffle=True,\n",
    "#     augmenter=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "main",
     "train"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BU-Net\"\n",
      "____________________________________________________________________________________________________________________________\n",
      "Layer (type)                            Output Shape                Param #        Connected to                             \n",
      "============================================================================================================================\n",
      "input_layer (InputLayer)                (None, 384, 384, 3)         0                                                       \n",
      "____________________________________________________________________________________________________________________________\n",
      "block1_d_conv1 (Conv2D)                 (None, 384, 384, 64)        1792           input_layer[0][0]                        \n",
      "____________________________________________________________________________________________________________________________\n",
      "block1_d_bn1 (BatchNormalization)       (None, 384, 384, 64)        256            block1_d_conv1[0][0]                     \n",
      "____________________________________________________________________________________________________________________________\n",
      "block1_d_ReLU1 (ReLU)                   (None, 384, 384, 64)        0              block1_d_bn1[0][0]                       \n",
      "____________________________________________________________________________________________________________________________\n",
      "block1_d_conv2 (Conv2D)                 (None, 384, 384, 64)        36928          block1_d_ReLU1[0][0]                     \n",
      "____________________________________________________________________________________________________________________________\n",
      "block1_d_bn2 (BatchNormalization)       (None, 384, 384, 64)        256            block1_d_conv2[0][0]                     \n",
      "____________________________________________________________________________________________________________________________\n",
      "block1_d_ReLU2 (ReLU)                   (None, 384, 384, 64)        0              block1_d_bn2[0][0]                       \n",
      "____________________________________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                       (None, 192, 192, 64)        36928          block1_d_ReLU2[0][0]                     \n",
      "____________________________________________________________________________________________________________________________\n",
      "block2_d_conv1 (Conv2D)                 (None, 192, 192, 128)       73856          conv2d_1[0][0]                           \n",
      "____________________________________________________________________________________________________________________________\n",
      "block2_d_bn1 (BatchNormalization)       (None, 192, 192, 128)       512            block2_d_conv1[0][0]                     \n",
      "____________________________________________________________________________________________________________________________\n",
      "block2_d_ReLU1 (ReLU)                   (None, 192, 192, 128)       0              block2_d_bn1[0][0]                       \n",
      "____________________________________________________________________________________________________________________________\n",
      "block2_d_conv2 (Conv2D)                 (None, 192, 192, 128)       147584         block2_d_ReLU1[0][0]                     \n",
      "____________________________________________________________________________________________________________________________\n",
      "block2_d_bn2 (BatchNormalization)       (None, 192, 192, 128)       512            block2_d_conv2[0][0]                     \n",
      "____________________________________________________________________________________________________________________________\n",
      "block2_d_ReLU2 (ReLU)                   (None, 192, 192, 128)       0              block2_d_bn2[0][0]                       \n",
      "____________________________________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                       (None, 96, 96, 128)         147584         block2_d_ReLU2[0][0]                     \n",
      "____________________________________________________________________________________________________________________________\n",
      "block3_d_conv1 (Conv2D)                 (None, 96, 96, 256)         295168         conv2d_2[0][0]                           \n",
      "____________________________________________________________________________________________________________________________\n",
      "block3_d_bn1 (BatchNormalization)       (None, 96, 96, 256)         1024           block3_d_conv1[0][0]                     \n",
      "____________________________________________________________________________________________________________________________\n",
      "block3_d_ReLU1 (ReLU)                   (None, 96, 96, 256)         0              block3_d_bn1[0][0]                       \n",
      "____________________________________________________________________________________________________________________________\n",
      "block3_d_conv2 (Conv2D)                 (None, 96, 96, 256)         590080         block3_d_ReLU1[0][0]                     \n",
      "____________________________________________________________________________________________________________________________\n",
      "block3_d_bn2 (BatchNormalization)       (None, 96, 96, 256)         1024           block3_d_conv2[0][0]                     \n",
      "____________________________________________________________________________________________________________________________\n",
      "block3_d_ReLU2 (ReLU)                   (None, 96, 96, 256)         0              block3_d_bn2[0][0]                       \n",
      "____________________________________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                       (None, 48, 48, 256)         590080         block3_d_ReLU2[0][0]                     \n",
      "____________________________________________________________________________________________________________________________\n",
      "block4_d_conv1 (Conv2D)                 (None, 48, 48, 512)         1180160        conv2d_3[0][0]                           \n",
      "____________________________________________________________________________________________________________________________\n",
      "block4_d_bn1 (BatchNormalization)       (None, 48, 48, 512)         2048           block4_d_conv1[0][0]                     \n",
      "____________________________________________________________________________________________________________________________\n",
      "block4_d_ReLU1 (ReLU)                   (None, 48, 48, 512)         0              block4_d_bn1[0][0]                       \n",
      "____________________________________________________________________________________________________________________________\n",
      "block4_d_conv2 (Conv2D)                 (None, 48, 48, 512)         2359808        block4_d_ReLU1[0][0]                     \n",
      "____________________________________________________________________________________________________________________________\n",
      "block4_d_bn2 (BatchNormalization)       (None, 48, 48, 512)         2048           block4_d_conv2[0][0]                     \n",
      "____________________________________________________________________________________________________________________________\n",
      "block4_d_ReLU2 (ReLU)                   (None, 48, 48, 512)         0              block4_d_bn2[0][0]                       \n",
      "____________________________________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                       (None, 24, 24, 512)         2359808        block4_d_ReLU2[0][0]                     \n",
      "____________________________________________________________________________________________________________________________\n",
      "block5_bottom_conv1 (Conv2D)            (None, 24, 24, 1024)        4719616        conv2d_4[0][0]                           \n",
      "____________________________________________________________________________________________________________________________\n",
      "block5_bottom_bn1 (BatchNormalization)  (None, 24, 24, 1024)        4096           block5_bottom_conv1[0][0]                \n",
      "____________________________________________________________________________________________________________________________\n",
      "block5_bottom_ReLU1 (ReLU)              (None, 24, 24, 1024)        0              block5_bottom_bn1[0][0]                  \n",
      "____________________________________________________________________________________________________________________________\n",
      "block5_bottom_conv2 (Conv2D)            (None, 24, 24, 1024)        9438208        block5_bottom_ReLU1[0][0]                \n",
      "____________________________________________________________________________________________________________________________\n",
      "block5_bottom_bn2 (BatchNormalization)  (None, 24, 24, 1024)        4096           block5_bottom_conv2[0][0]                \n",
      "____________________________________________________________________________________________________________________________\n",
      "block5_bottom_ReLU2 (ReLU)              (None, 24, 24, 1024)        0              block5_bottom_bn2[0][0]                  \n",
      "____________________________________________________________________________________________________________________________\n",
      "block4_u_upsampling (UpSampling2D)      (None, 48, 48, 1024)        0              block5_bottom_ReLU2[0][0]                \n",
      "____________________________________________________________________________________________________________________________\n",
      "Concatenate_1 (Concatenate)             (None, 48, 48, 1536)        0              block4_d_ReLU2[0][0]                     \n",
      "                                                                                   block4_u_upsampling[0][0]                \n",
      "____________________________________________________________________________________________________________________________\n",
      "block4_u_conv1 (Conv2D)                 (None, 48, 48, 512)         7078400        Concatenate_1[0][0]                      \n",
      "____________________________________________________________________________________________________________________________\n",
      "block4_u_bn1 (BatchNormalization)       (None, 48, 48, 512)         2048           block4_u_conv1[0][0]                     \n",
      "____________________________________________________________________________________________________________________________\n",
      "block4_u_ReLU1 (ReLU)                   (None, 48, 48, 512)         0              block4_u_bn1[0][0]                       \n",
      "____________________________________________________________________________________________________________________________\n",
      "block4_u_conv2 (Conv2D)                 (None, 48, 48, 512)         2359808        block4_u_ReLU1[0][0]                     \n",
      "____________________________________________________________________________________________________________________________\n",
      "block4_u_bn2 (BatchNormalization)       (None, 48, 48, 512)         2048           block4_u_conv2[0][0]                     \n",
      "____________________________________________________________________________________________________________________________\n",
      "block4_u_ReLU2 (ReLU)                   (None, 48, 48, 512)         0              block4_u_bn2[0][0]                       \n",
      "____________________________________________________________________________________________________________________________\n",
      "block3_u_upsampling (UpSampling2D)      (None, 96, 96, 512)         0              block4_u_ReLU2[0][0]                     \n",
      "____________________________________________________________________________________________________________________________\n",
      "Concatenate_2 (Concatenate)             (None, 96, 96, 768)         0              block3_d_ReLU2[0][0]                     \n",
      "                                                                                   block3_u_upsampling[0][0]                \n",
      "____________________________________________________________________________________________________________________________\n",
      "block3_u_conv1 (Conv2D)                 (None, 96, 96, 256)         1769728        Concatenate_2[0][0]                      \n",
      "____________________________________________________________________________________________________________________________\n",
      "block3_u_bn1 (BatchNormalization)       (None, 96, 96, 256)         1024           block3_u_conv1[0][0]                     \n",
      "____________________________________________________________________________________________________________________________\n",
      "block3_u_ReLU1 (ReLU)                   (None, 96, 96, 256)         0              block3_u_bn1[0][0]                       \n",
      "____________________________________________________________________________________________________________________________\n",
      "block3_u_conv2 (Conv2D)                 (None, 96, 96, 256)         590080         block3_u_ReLU1[0][0]                     \n",
      "____________________________________________________________________________________________________________________________\n",
      "block3_u_bn2 (BatchNormalization)       (None, 96, 96, 256)         1024           block3_u_conv2[0][0]                     \n",
      "____________________________________________________________________________________________________________________________\n",
      "block3_u_ReLU2 (ReLU)                   (None, 96, 96, 256)         0              block3_u_bn2[0][0]                       \n",
      "____________________________________________________________________________________________________________________________\n",
      "block2_u_upsampling (UpSampling2D)      (None, 192, 192, 256)       0              block3_u_ReLU2[0][0]                     \n",
      "____________________________________________________________________________________________________________________________\n",
      "Concatenate_3 (Concatenate)             (None, 192, 192, 384)       0              block2_d_ReLU2[0][0]                     \n",
      "                                                                                   block2_u_upsampling[0][0]                \n",
      "____________________________________________________________________________________________________________________________\n",
      "block2_u_conv1 (Conv2D)                 (None, 192, 192, 128)       442496         Concatenate_3[0][0]                      \n",
      "____________________________________________________________________________________________________________________________\n",
      "block2_u_bn1 (BatchNormalization)       (None, 192, 192, 128)       512            block2_u_conv1[0][0]                     \n",
      "____________________________________________________________________________________________________________________________\n",
      "block2_u_ReLU1 (ReLU)                   (None, 192, 192, 128)       0              block2_u_bn1[0][0]                       \n",
      "____________________________________________________________________________________________________________________________\n",
      "block2_u_conv2 (Conv2D)                 (None, 192, 192, 128)       147584         block2_u_ReLU1[0][0]                     \n",
      "____________________________________________________________________________________________________________________________\n",
      "block2_u_bn2 (BatchNormalization)       (None, 192, 192, 128)       512            block2_u_conv2[0][0]                     \n",
      "____________________________________________________________________________________________________________________________\n",
      "block2_u_ReLU2 (ReLU)                   (None, 192, 192, 128)       0              block2_u_bn2[0][0]                       \n",
      "____________________________________________________________________________________________________________________________\n",
      "block1_u_upsampling (UpSampling2D)      (None, 384, 384, 128)       0              block2_u_ReLU2[0][0]                     \n",
      "____________________________________________________________________________________________________________________________\n",
      "Concatenate_4 (Concatenate)             (None, 384, 384, 192)       0              block1_d_ReLU2[0][0]                     \n",
      "                                                                                   block1_u_upsampling[0][0]                \n",
      "____________________________________________________________________________________________________________________________\n",
      "block1_u_conv1 (Conv2D)                 (None, 384, 384, 64)        110656         Concatenate_4[0][0]                      \n",
      "____________________________________________________________________________________________________________________________\n",
      "block1_u_bn1 (BatchNormalization)       (None, 384, 384, 64)        256            block1_u_conv1[0][0]                     \n",
      "____________________________________________________________________________________________________________________________\n",
      "block1_u_ReLU1 (ReLU)                   (None, 384, 384, 64)        0              block1_u_bn1[0][0]                       \n",
      "____________________________________________________________________________________________________________________________\n",
      "block1_u_conv2 (Conv2D)                 (None, 384, 384, 64)        36928          block1_u_ReLU1[0][0]                     \n",
      "____________________________________________________________________________________________________________________________\n",
      "block1_u_bn2 (BatchNormalization)       (None, 384, 384, 64)        256            block1_u_conv2[0][0]                     \n",
      "____________________________________________________________________________________________________________________________\n",
      "block1_u_ReLU2 (ReLU)                   (None, 384, 384, 64)        0              block1_u_bn2[0][0]                       \n",
      "____________________________________________________________________________________________________________________________\n",
      "GaussianNoise_preout (GaussianNoise)    (None, 384, 384, 64)        0              block1_u_ReLU2[0][0]                     \n",
      "____________________________________________________________________________________________________________________________\n",
      "conv_out (Conv2D)                       (None, 384, 384, 4)         260            GaussianNoise_preout[0][0]               \n",
      "============================================================================================================================\n",
      "Total params: 34,537,092\n",
      "Trainable params: 34,525,316\n",
      "Non-trainable params: 11,776\n",
      "____________________________________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_kwargs = {\n",
    "    \"nb_filters\": NB_FILTERS_0,\n",
    "    \"sigma_noise\": SIGMA_NOISE,\n",
    "    \"depth\": 4,\n",
    "    \"maxpool\": False,\n",
    "    \"initialization\": \"he_normal\",\n",
    "    \"activation\": ReLU,\n",
    "    \"dropout\": 0,\n",
    "    \"output_channels\": num_cls,\n",
    "    \"batchnorm\": True,\n",
    "    \"arch\": \"U-Net\",\n",
    "}\n",
    "cat_fl = categorical_focal_loss()\n",
    "loss_func = categorical_crossentropy\n",
    "model_base_path = osp.join(weight_path, today_str, loss_func.__name__, \"arch-\" + model_kwargs[\"arch\"])\n",
    "pretrain_model = osp.join(weight_path,\"2019-09-20\",\"pretrain_U-net_model.h5\")\n",
    "path_elements = [\n",
    "    '{}_{}'.format(key, val.__name__)\n",
    "    if hasattr(val, '__name__')\n",
    "    else '{}_{}'.format(key, val) for key, val in model_kwargs.items()\n",
    "]\n",
    "path_elements.remove('{}_{}'.format(\"arch\", model_kwargs[\"arch\"]))\n",
    "\n",
    "if not os.path.exists(model_base_path):\n",
    "    os.makedirs(model_base_path, exist_ok=True)\n",
    "\n",
    "modelpath = osp.join(\n",
    "    model_base_path,\n",
    "    '-'.join(path_elements) + \".h5\"\n",
    ")\n",
    "\n",
    "log_path = osp.join(\n",
    "    \"./logs/\",\n",
    "    today_str,\n",
    "    loss_func.__name__,\n",
    "    model_kwargs[\"arch\"],\n",
    "    *path_elements, ''\n",
    ")\n",
    "\n",
    "model = u_net(SHAPE, **model_kwargs)\n",
    "#model = load_model(pretrain_model, custom_objects={'Swish': Swish})\n",
    "#from keras.models import Model\n",
    "#from keras.layers import Conv2D\n",
    "#model_inputs = model.inputs\n",
    "#model_preout = model.layers[-2].output\n",
    "#new_output = Conv2D(num_cls, 1, activation=\"softmax\", name=\"conv_out\")(model_preout)\n",
    "#model = Model(inputs=model.inputs, outputs=new_output)\n",
    "#pretrain_layers = [\n",
    "#    \"block{}_d_conv{}\".format(block, layer)\n",
    "#    for block in range(1, 4 + 1)\n",
    "#    for layer in range(1, 3)\n",
    "#]\n",
    "#for i, n in enumerate(pretrain_layers):\n",
    "#    model.get_layer(name=n).trainable = False\n",
    "print(model.summary(line_length=124))\n",
    "model.compile(loss=loss_func, optimizer=Adam(lr=1e-3, decay=0.0), metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "main",
     "train"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bthorsted/.pyenv/versions/tensorflow-1.13.2/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/bthorsted/.pyenv/versions/tensorflow-1.13.2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8066e7df29d4e7c83e3730d6e153cb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training', max=400.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1adb5f0e65c48ae89a924b517b7f5d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 0', max=242.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-17:\n",
      "Process ForkPoolWorker-59:\n",
      "Process ForkPoolWorker-31:\n",
      "Process ForkPoolWorker-51:\n",
      "Process ForkPoolWorker-25:\n",
      "Process ForkPoolWorker-22:\n",
      "Process ForkPoolWorker-57:\n",
      "Process ForkPoolWorker-46:\n",
      "Process ForkPoolWorker-48:\n",
      "Process ForkPoolWorker-53:\n",
      "Process ForkPoolWorker-50:\n",
      "Process ForkPoolWorker-41:\n",
      "Process ForkPoolWorker-16:\n",
      "Process ForkPoolWorker-39:\n",
      "Process ForkPoolWorker-54:\n",
      "Process ForkPoolWorker-55:\n",
      "Process ForkPoolWorker-40:\n",
      "Process ForkPoolWorker-36:\n",
      "Process ForkPoolWorker-21:\n",
      "Process ForkPoolWorker-37:\n",
      "Process ForkPoolWorker-45:\n",
      "Process ForkPoolWorker-52:\n",
      "Process ForkPoolWorker-42:\n",
      "Process ForkPoolWorker-60:\n",
      "Process ForkPoolWorker-34:\n",
      "Process ForkPoolWorker-43:\n",
      "Process ForkPoolWorker-12:\n",
      "Process ForkPoolWorker-49:\n",
      "Process ForkPoolWorker-14:\n",
      "Process ForkPoolWorker-47:\n",
      "Process ForkPoolWorker-23:\n",
      "Process ForkPoolWorker-56:\n",
      "Process ForkPoolWorker-44:\n",
      "Process ForkPoolWorker-11:\n",
      "Process ForkPoolWorker-7:\n",
      "Process ForkPoolWorker-8:\n",
      "Process ForkPoolWorker-58:\n",
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-18:\n",
      "Process ForkPoolWorker-20:\n",
      "Process ForkPoolWorker-32:\n",
      "Process ForkPoolWorker-19:\n",
      "Process ForkPoolWorker-13:\n",
      "Process ForkPoolWorker-10:\n",
      "Process ForkPoolWorker-9:\n",
      "Process ForkPoolWorker-38:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process ForkPoolWorker-35:\n",
      "Process ForkPoolWorker-33:\n",
      "Process ForkPoolWorker-24:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n"
     ]
    }
   ],
   "source": [
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from mmciad.utils.callbacks import PatchedModelCheckpoint\n",
    "\n",
    "#class_weights = [1 if k != 12 else 0 for k in active_labels]\n",
    "\n",
    "progressbar = TQDMNotebookCallback(\n",
    "    metric_format=\"{name}: {value:0.4f}\", leave_inner=True, leave_outer=True\n",
    ")\n",
    "#progressbar = TqdmCallback()\n",
    "# tensor_board = TensorBoard(\n",
    "#     log_dir=log_path,\n",
    "#     histogram_freq=0,\n",
    "#     write_graph=True,\n",
    "#     write_grads=False,\n",
    "#     write_images=True,\n",
    "#     embeddings_freq=0,\n",
    "#     update_freq=\"epoch\"\n",
    "# )\n",
    "early_stopper = EarlyStopping(monitor=\"loss\", patience=40, verbose=1, mode=\"auto\")\n",
    "reducer = ReduceLROnPlateau(\n",
    "    monitor=\"loss\",\n",
    "    factor=0.1,\n",
    "    patience=10,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1,\n",
    ")\n",
    "model_checkpoint = PatchedModelCheckpoint(\n",
    "    modelpath, verbose=0, monitor=\"loss\", save_best_only=True,\n",
    ")\n",
    "model_callbacks = [progressbar, early_stopper, reducer, model_checkpoint]\n",
    "\n",
    "\n",
    "\n",
    "#frozen_history = model.fit_generator(\n",
    "#    generator=train_data.prefetch(tf.data.experimental.AUTOTUNE),\n",
    "#    epochs=NB_FROZEN,\n",
    "#    validation_data=test_generator,\n",
    "#    #class_weight=class_weights,\n",
    "#    verbose=VERBOSE,\n",
    "#    callbacks=model_callbacks,\n",
    "#)\n",
    "#for n in pretrain_layers:\n",
    "#    model.get_layer(name=n).trainable = True\n",
    "#\n",
    "#model.compile(loss=loss_func, optimizer=Adam(lr=1e-4, decay=0.0), metrics=[\"acc\"])\n",
    "\n",
    "history = model.fit_generator(\n",
    "    generator=train_generator,\n",
    "    epochs=NB_EPOCH,\n",
    "#    initial_epoch=NB_FROZEN,\n",
    "    validation_data=val_generator,\n",
    "    use_multiprocessing=True,\n",
    "    workers=30,\n",
    "    #class_weight=class_weights,\n",
    "    verbose=VERBOSE,\n",
    "    callbacks=model_callbacks,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    del model\n",
    "    #Clean session\n",
    "    sess = get_session()\n",
    "    clear_session()\n",
    "    sess.close()\n",
    "    K.tensorflow_backend.set_session(tf.Session(config=config))\n",
    "except NameError:\n",
    "    print(\"model does not exist\")\n",
    "\n",
    "model = load_model(modelpath, custom_objects={'Swish': Swish, \"weighted_categorical_crossentropy\": w_ce})\n",
    "\n",
    "for n in pretrain_layers:\n",
    "    model.get_layer(name=n).trainable = True\n",
    "\n",
    "model.compile(loss=loss_func, optimizer=Adam(lr=1e-4, decay=0.0), metrics=[\"acc\"])\n",
    "\n",
    "\n",
    "history = model.fit_generator(\n",
    "    generator=train_generator,\n",
    "    epochs=NB_EPOCH,\n",
    "    initial_epoch=NB_FROZEN,\n",
    "    validation_data=val_generator,\n",
    "    use_multiprocessing=True,\n",
    "    workers=30,\n",
    "    #class_weight=class_weights,\n",
    "    verbose=VERBOSE,\n",
    "    callbacks=model_callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model = load_model(modelpath, custom_objects={'Swish': Swish})\n",
    "\n",
    "history = model.fit_generator(\n",
    "    generator=train_generator,\n",
    "    epochs=NB_EPOCH,\n",
    "    initial_epoch=66,\n",
    "    validation_data=val_generator,\n",
    "    use_multiprocessing=True,\n",
    "    workers=30,\n",
    "    class_weight=class_weights,\n",
    "    verbose=VERBOSE,\n",
    "    callbacks=model_callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "main"
    ]
   },
   "outputs": [],
   "source": [
    "# **** #####################################\"\n",
    "min_loss = np.argmin(history.history['loss'])\n",
    "epoch_init = 65+1\n",
    "print(\"Best loss: %.5f\" % (np.min(history.history['loss'])))\n",
    "print(\"at: %d\" % (65+1+np.argmin(history.history['loss'])))\n",
    "print(f\"accuracy at {epoch_init+min_loss}:            {history.history['acc'][min_loss]:.5f}\")\n",
    "print(f\"validation accuracy at {epoch_init+min_loss}: {history.history['val_acc'][min_loss]:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "model.save(modelpath.replace(\".h5\",\"-final.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "main"
    ]
   },
   "outputs": [],
   "source": [
    "# Find max accuracy of all models\n",
    "best = {key: np.max(m.history[\"categorical_accuracy\"]) for key, m in histories.items()}\n",
    "print(best)\n",
    "print(\n",
    "    \"Highest validation accuracy:\\n{}, score: {}\".format(\n",
    "        max(best, key=lambda key: best[key]), max(best.values())\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "main",
     "visuals"
    ]
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(2, 2, figsize=(10, 10))\n",
    "i_s = [0, 0, 1, 1]\n",
    "j_s = [0, 1, 0, 1]\n",
    "lf = [\n",
    "    \"categorical_crossentropy\",\n",
    "    \"weighted_categorical_crossentropy\",\n",
    "    \"tversky_loss\",\n",
    "    \"weighted_tversky_loss\",\n",
    "]\n",
    "for i, j, m, title in zip(i_s, j_s, histories.values(), lf):\n",
    "    loss = ax1[i, j].plot(m.epoch, m.history['loss'], label='loss')\n",
    "    val_loss = ax1[i, j].plot(m.epoch, m.history['val_loss'], label='validation loss')\n",
    "    ax1[i, j].set_title(title)\n",
    "    if not j:\n",
    "        ax1[i, j].set_ylabel('loss')\n",
    "    if i:\n",
    "        ax1[i, j].set_xlabel('epoch')\n",
    "    ax2 = ax1[i, j].twinx()\n",
    "    if j:\n",
    "        ax2.set_ylabel('Accuracy')\n",
    "    acc = ax2.plot(m.epoch, m.history['categorical_accuracy'], '-m', label='accuracy')\n",
    "    val_acc = ax2.plot(m.epoch, m.history['val_categorical_accuracy'], '-g', label='validation accuracy')\n",
    "    ax1[i, j].set_ylim(0.0, max([max(m.history['loss']), max(m.history['val_loss'])]))\n",
    "    ax2.set_ylim(0.0, 1.0)\n",
    "handles, labels = ax1[0, 0].get_legend_handles_labels()\n",
    "handles2, labels2 = ax2.get_legend_handles_labels()\n",
    "fig.legend(handles=handles+handles2,\n",
    "           bbox_to_anchor=(0., 0.02, 1., .1), # x, y, width, height\n",
    "           loc='lower left',\n",
    "           ncol=4, mode=\"expand\")\n",
    "#fig.tight_layout()\n",
    "fig.suptitle('Training performance')\n",
    "plt.show()\n",
    "fig.savefig(osp.join(\".\",\"results\",\"training performance.svg\"), dpi=300,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "Y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def compare_results(img):\n",
    "    if type(img) is list:\n",
    "        cols = len(img)\n",
    "        for pos, img in zip(range(1, cols * 3, 3), img):\n",
    "            plt.subplot(cols, 3, pos)\n",
    "            plt.imshow(X_test[img, :, :, :] * train_s + train_m)\n",
    "            if pos <= 3:\n",
    "                plt.title(\"Training image\")\n",
    "            plt.subplot(cols, 3, pos + 1)\n",
    "            plt.imshow(colorvec[np.argmax(Y_test[img, :, :, :], axis=-1)])\n",
    "            if pos <= 3:\n",
    "                plt.title(\"Image label\")\n",
    "            plt.subplot(cols, 3, pos + 2)\n",
    "            plt.imshow(colorvec[np.argmax(Y_pred[img, :, :, :], axis=-1)])\n",
    "            if pos <= 3:\n",
    "                plt.title(\"Label prediction\")\n",
    "            pred_list = np.unique(np.argmax(Y_pred[img, :, :, :], axis=-1))\n",
    "            test_list = np.unique(np.argmax(Y_test[img, :, :, :], axis=-1))\n",
    "            print(\"{:^44s}\".format(\"Image \" + str(img)))\n",
    "            print(\n",
    "                \"{:<3s}{:<18s}{:<3s}{:<18s}\".format(\n",
    "                    \"\", \"Actual labels\", \"\", \"Predicted labels:\"\n",
    "                )\n",
    "            )\n",
    "            print(\"-\" * 44)\n",
    "            for i in active_labels:\n",
    "                a = \"\"\n",
    "                p = \"\"\n",
    "                j = \"\"\n",
    "                k = \"\"\n",
    "                if i in test_list:\n",
    "                    j = str(i)\n",
    "                    a = active_classes[i]\n",
    "                if i in pred_list:\n",
    "                    k = str(i)\n",
    "                    p = active_classes[i]\n",
    "                if not a == p == j == k:\n",
    "                    print(\"{:<3s}{:<18s}{:<3s}{:<18s}\".format(j, a, k, p))\n",
    "    else:\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(X_test[img, :, :, :] * train_s + train_m)\n",
    "        plt.title(\"Training image\")\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(colorvec[np.argmax(Y_test[img, :, :, :], axis=-1)])\n",
    "        plt.title(\"Image label\")\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(colorvec[np.argmax(Y_pred[img, :, :, :], axis=-1)])\n",
    "        plt.title(\"Label prediction\")\n",
    "\n",
    "\n",
    "# compare_results([1,4,7,28])\n",
    "for i in range(Y_pred.shape[0]):\n",
    "    compare_results(i)\n",
    "    plt.savefig(\"./figures/test_prediction_tile{}.png\".format(i), format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Quantitative evaluation\n",
    "from dlia_tools.eval import jaccard\n",
    "Y_test_pred = model.predict(X_test)\n",
    "#Y_train_pred = model.predict(X_train)\n",
    "Y_val_pred = model.predict(X_val)\n",
    "\n",
    "#print(\"Jaccard on training set:\", jaccard(Y_train, Y_train_pred))\n",
    "print(\"Jaccard on validation set:\", jaccard(Y_val, Y_val_pred))\n",
    "print(\"Jaccard on test set:\", jaccard(Y_test, Y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#model.save_weights(path+'batchnorm-weights.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "main",
     "test"
    ]
   },
   "outputs": [],
   "source": [
    "def sliding_window(image, stepSize, windowSize):\n",
    "    # slide a window across the image\n",
    "    for y in range(0, image.shape[1] - windowSize[0] + stepSize, stepSize):\n",
    "        for x in range(0, image.shape[0] - windowSize[1] + stepSize, stepSize):\n",
    "            # yield the current window\n",
    "            res_img = image[x : x + windowSize[0], y : y + windowSize[1]]\n",
    "            change = False\n",
    "            if res_img.shape[1] != windowSize[1]:\n",
    "                y = image.shape[1] - windowSize[1]\n",
    "                change = True\n",
    "            if res_img.shape[0] != windowSize[0]:\n",
    "                x = image.shape[0] - windowSize[0]\n",
    "                change = True\n",
    "            if change:\n",
    "                res_img = image[x : x + windowSize[0], y : y + windowSize[1]]\n",
    "            yield (x, y, x + windowSize[0], y + windowSize[1], res_img)\n",
    "\n",
    "\n",
    "def predict_window(model, img, step_size=1000, wsize=1024, num_class=11):\n",
    "    size = Size(img.shape[0], img.shape[1])\n",
    "    dtype = img.dtype\n",
    "    if (size.x > wsize) & (size.y > wsize):\n",
    "        output_img = np.zeros(shape=(size.x, size.y, num_class))\n",
    "        output_img[:] = np.nan\n",
    "        for (x, y, dx, dy, I) in sliding_window(img, step_size, (wsize, wsize)):\n",
    "            window_prediction = model.predict(np.expand_dims(I, axis=0))\n",
    "            output_img[x:dx, y:dy] = np.nanmean(\n",
    "                np.stack((output_img[x:dx, y:dy], np.squeeze(window_prediction)), axis=0), axis=0\n",
    "            ).astype(dtype)\n",
    "        return output_img\n",
    "    output_img = model.predict(img)\n",
    "    return output_img\n",
    "\n",
    "def evaluate_window(model, slide, target, stepSize=1000, wsize=1024, batch_size=None, num_cls=11):\n",
    "    X, Y, _ = slide.shape\n",
    "    if (X > wsize) & (Y > wsize):\n",
    "        input_tiles = []\n",
    "        target_tiles = []\n",
    "        for (x, y, dx, dy, I) in sliding_window(slide, wsize, (wsize, wsize)):\n",
    "            input_tiles.append(I)\n",
    "            target_tiles.append(target[x:dx,y:dy])\n",
    "        input_tiles = np.asarray(input_tiles)\n",
    "        target_tiles = np.asarray(target_tiles)\n",
    "        if batch_size is None:\n",
    "            batch_size = input_tiles.shape[0]\n",
    "        print(target_tiles.shape)\n",
    "        return model.evaluate(x=input_tiles, y=target_tiles, batch_size=batch_size)\n",
    "    else:\n",
    "        return model.evaluate(x=slide, y=target, batch_size=1)\n",
    "\n",
    "\n",
    "def concat_windows(slides, targets, stepSize=1000, wsize=1024):\n",
    "    input_tiles = []\n",
    "    target_tiles = []\n",
    "    for slide, target in zip(slides, targets):\n",
    "        X, Y, _ = slide.shape\n",
    "        if (X > wsize) & (Y > wsize):\n",
    "            for (x, y, dx, dy, I) in sliding_window(slide, wsize, (wsize, wsize)):\n",
    "                input_tiles.append(I)\n",
    "                target_tiles.append(target[x:dx,y:dy])\n",
    "    input_tiles = np.asarray(input_tiles)\n",
    "    target_tiles = np.asarray(target_tiles)\n",
    "    return input_tiles, target_tiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from mmciad.utils.preprocessing import merge_labels\n",
    "test_slides, test_targets = load_slides_as_dict(path, \"test\", train_m, train_s, [x_min, x_max], True, num_cls, colorvec)\n",
    "raw_test_slides = load_slides_as_dict(path, \"test\", load_gt=False)\n",
    "remap_pattern = {0: [0, ], 1: [2, 3, 5], 2: [7, 8, 9], 3: [10, 1, 4, 6]}\n",
    "bin_class = len(remap_pattern)\n",
    "binary_test_targets = {name: to_categorical(merge_labels(np.argmax(img, axis=-1), remap_pattern)) for name, img in test_targets.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print(test_slides[\"N9a-1\"].min(), test_slides[\"N9a-1\"].max())\n",
    "#print(170775/test_slides[\"N10a\"].shape[1])\n",
    "print(test_targets.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def find_contrast_min_and_max(img):\n",
    "    AUTO_THRESHOLD = 5000\n",
    "    pixcount = img.size\n",
    "    limit = pixcount/10\n",
    "    threshold = pixcount/AUTO_THRESHOLD\n",
    "    n_bins = 256\n",
    "    values, histogram = np.histogram(img, n_bins)\n",
    "    i = 0 # start at zero rather than -1 to avoid accounting for empty patches\n",
    "    found = False\n",
    "    count = 0\n",
    "    while True:\n",
    "        i += 1\n",
    "        count = values[i]\n",
    "        if count>limit:\n",
    "            count = 0\n",
    "        found = count> threshold\n",
    "        if found or i>=255:\n",
    "            break\n",
    "    hmin = i\n",
    "    found = False\n",
    "    i = 256\n",
    "    while True:\n",
    "        i -= 1\n",
    "        count = values[i]\n",
    "        if count>limit:\n",
    "            count = 0\n",
    "        found = count> threshold\n",
    "        if found or i<1:\n",
    "            break\n",
    "    hmax = i\n",
    "    return hmin/256, hmax/256\n",
    "\n",
    "def thresholding_algo(y, lag, threshold, influence):\n",
    "    signals = np.zeros(len(y))\n",
    "    filteredY = np.array(y)\n",
    "    avgFilter = [0]*len(y)\n",
    "    stdFilter = [0]*len(y)\n",
    "    avgFilter[lag - 1] = np.mean(y[0:lag])\n",
    "    stdFilter[lag - 1] = np.std(y[0:lag])\n",
    "    for i in range(lag, len(y)):\n",
    "        if abs(y[i] - avgFilter[i-1]) > threshold * stdFilter [i-1]:\n",
    "            if y[i] > avgFilter[i-1]:\n",
    "                signals[i] = 1\n",
    "            else:\n",
    "                signals[i] = -1\n",
    "\n",
    "            filteredY[i] = influence * y[i] + (1 - influence) * filteredY[i-1]\n",
    "            avgFilter[i] = np.mean(filteredY[(i-lag+1):i+1])\n",
    "            stdFilter[i] = np.std(filteredY[(i-lag+1):i+1])\n",
    "        else:\n",
    "            signals[i] = 0\n",
    "            filteredY[i] = y[i]\n",
    "            avgFilter[i] = np.mean(filteredY[(i-lag+1):i+1])\n",
    "            stdFilter[i] = np.std(filteredY[(i-lag+1):i+1])\n",
    "\n",
    "    return dict(signals = np.asarray(signals),\n",
    "                avgFilter = np.asarray(avgFilter),\n",
    "                stdFilter = np.asarray(stdFilter))\n",
    "\n",
    "lag = 10\n",
    "threshold = 2\n",
    "influence = 0\n",
    "\n",
    "def auto_contrast(img, order=['b','r','g']):\n",
    "    from skimage import exposure\n",
    "    from scipy import stats\n",
    "    output_img = np.zeros_like(np.squeeze(img))\n",
    "    CHANNEL_INDEX = {'r': 0, 'g': 1, 'b': 2}\n",
    "    ch = ['red','green','blue']\n",
    "    for i, c in enumerate([CHANNEL_INDEX[channel] for channel in order]):\n",
    "        v_min, v_max = find_contrast_min_and_max(img[..., i])\n",
    "        hist, bins_ = np.histogram(img[..., i], bins=256)\n",
    "        t = thresholding_algo(hist, lag, threshold, influence)\n",
    "        v_min = t[\"signals\"].argmax()/256\n",
    "        #midpoint = v_max - v_min\n",
    "        #v_min = midpoint - 30/256.\n",
    "        #print(ch[c], \"(c: {})\".format(c), order[i], \"(i: {})\".format(i))\n",
    "        #print(\"before:\",v_min, v_max)\n",
    "        if c == 0:\n",
    "            v_min = (t[\"signals\"].argmax()+1)/256\n",
    "            #v_max = np.percentile(img[..., i], (95.0))\n",
    "        elif c == 1:\n",
    "            v_min = t[\"signals\"].argmax()/256\n",
    "        elif c == 2:\n",
    "            v_min = (t[\"signals\"].argmax())/256\n",
    "            #print(t[\"signals\"])\n",
    "            #v_min *= 1.3\n",
    "            #v_min = max(v_min, np.percentile(img[..., i], (40.0)))\n",
    "            #v_max = np.percentile(img[..., i], (98.0))\n",
    "        #print(\"after:\",v_min, v_max)\n",
    "        output_img[..., c] = exposure.rescale_intensity(img[..., i], in_range=(v_min, v_max))\n",
    "    return output_img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "hist, bins_ = np.histogram(raw_test_slides[\"N4b\"][..., 1], bins=256)\n",
    "t = thresholding_algo(hist, lag, threshold, influence)\n",
    "hist\n",
    "t[\"signals\"].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from skimage import exposure\n",
    "from scipy import stats\n",
    "num_slides = len(raw_test_slides)\n",
    "plt.rcParams['figure.figsize'] = (20.0, 16.0)\n",
    "enhanced_slides = {}\n",
    "for n, (name, slide) in enumerate(raw_test_slides.items(), 1):\n",
    "    print(name)\n",
    "    #for i, c in enumerate([1,2,0]):\n",
    "        #zero = stats.percentileofscore(slide[..., c].ravel(), 0)\n",
    "        #mid = stats.percentileofscore(slide[..., c].ravel(), np.median(slide[..., c].ravel()))\n",
    "        #print(\"channel {}: {}\".format(i, zero))\n",
    "        #v_min, v_mid, v_max = np.percentile(slide, (zero+10, mid, 90.0))\n",
    "        #print(\"channel {}: min {} , mid {} , max {}\".format(i, v_min, v_mid, v_max))\n",
    "        #v_min, v_max = find_contrast_min_and_max(slide[..., c])\n",
    "        #print(\"channel {}: min {} , max {}\".format(i, v_min, v_max))\n",
    "        #enhanced_slides[name][..., i] = exposure.rescale_intensity(slide[..., c], in_range=(v_min, v_max))\n",
    "    enhanced_slides[name] = auto_contrast(slide)\n",
    "    plt.subplot(1, num_slides, n)\n",
    "    plt.imshow(enhanced_slides[name])\n",
    "    plt.title(name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train_slides = load_slides_as_dict(path, \"train\", train_m, train_s, False)\n",
    "train_slides.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_slides.pop('N10a')\n",
    "test_slides.pop('N4b')\n",
    "#test_slides.pop('N9a-1')\n",
    "test_slides.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "weight_path = \"./weights/\"\n",
    "results_path = \"./results/\"\n",
    "train_date = \"2019-10-31\"\n",
    "weights = sorted(glob(osp.join(weight_path, train_date,\"*\",\"*\", \"*.h5\")), key=str.lower)\n",
    "\n",
    "#eval_kwargs = model_kwargs\n",
    "#eval_kwargs[\"activation\"] = Swish\n",
    "#eval_kwargs[\"output_channels\"] = num_cls\n",
    "#del model\n",
    "model = load_model(weights[0], custom_objects={'Swish': Swish,'categorical_focal_loss_fixed': categorical_focal_loss()})\n",
    "for name, target in binary_test_targets.items():\n",
    "    slide = np.squeeze(test_slides[name])\n",
    "    #with tf.device('/cpu:*'): # Remember to re-indent model + compile below\n",
    "    print(target.shape)\n",
    "    print(evaluate_window(model, slide, target, stepSize=190, wsize=208, batch_size=12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "weight_path = \"./weights/\"\n",
    "results_path = \"./results/\"\n",
    "train_date = \"2019-10-17\"\n",
    "weights = sorted(glob(osp.join(weight_path, train_date,\"*\",\"*\", \"*.h5\")), key=str.lower)\n",
    "# architecture params\n",
    "NB_FILTERS_0 = 64\n",
    "SIGMA_NOISE = 0.01\n",
    "\n",
    "VERBOSE = 1\n",
    "model_kwargs = {\n",
    "    \"nb_filters\": NB_FILTERS_0,\n",
    "    \"sigma_noise\": SIGMA_NOISE,\n",
    "    \"depth\": 4,\n",
    "    \"maxpool\": False,\n",
    "    \"initialization\": \"he_normal\",\n",
    "    \"activation\": \"Swish\",\n",
    "    \"dropout\": 0,\n",
    "    \"batchnorm\": True,\n",
    "    \"arch\": \"U-Net\",\n",
    "}\n",
    "eval_kwargs = model_kwargs\n",
    "eval_kwargs[\"activation\"] = Swish\n",
    "eval_kwargs[\"output_channels\"] = num_cls\n",
    "slide_list = []\n",
    "target_list = []\n",
    "for name, target in test_targets.items():\n",
    "    slide_list.append(np.squeeze(test_slides[name]))\n",
    "    target_list.append(target)\n",
    "input_tiles, target_tiles = concat_windows(slide_list, target_list, stepSize=190, wsize=208)\n",
    "#with tf.device('/cpu:*'): # Remember to re-indent model + compile below\n",
    "#    eval_model = load_model(weights[0], custom_objects={'Swish': Swish})\n",
    "#    eval_model.compile(\n",
    "#        loss=categorical_crossentropy,\n",
    "#        optimizer=Adam(lr=0.001, decay=0),\n",
    "#        metrics=[\"acc\"],\n",
    "#    )\n",
    "#    print(target.shape)\n",
    "test_metrics = model.evaluate(x=input_tiles, y=target_tiles, batch_size=12)\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "from collections import namedtuple\n",
    "\n",
    "Size = namedtuple(\"Size\", [\"x\", \"y\"])\n",
    "weight_path = \"./weights/\"\n",
    "results_path = \"./results/\"\n",
    "train_date = \"2019-11-18\"\n",
    "weights = sorted(glob(osp.join(weight_path, train_date,\"*\",\"*\", \"*.h5\")), key=str.lower)\n",
    "\n",
    "loss_dir = str(osp.split(modelpath)[0]).split('/')[-2]\n",
    "arch_dir = str(osp.split(modelpath)[0]).split('/')[-1]\n",
    "base_name = osp.split(modelpath)[-1]\n",
    "class_wgt_dir = 'weights_{}'.format('True' in str(base_name))\n",
    "act_dir = '{}'.format(base_name[base_name.rfind('activation_'):base_name.find('-dropout_')])\n",
    "init_dir = '{}'.format(base_name[base_name.rfind('initialization_'):base_name.find('-activation_')])\n",
    "#pre_dir = '{}'.format(base_name[base_name.rfind('pretrain_'):base_name.find('-sigma_')])\n",
    "\n",
    "for name, target in binary_test_targets.items():\n",
    "    slide = np.squeeze(test_slides[name])\n",
    "    #with tf.device('/cpu:*'): # Remember to re-indent model + compile below\n",
    "        #test_model = load_model(weights[0], custom_objects={'Swish': Swish})\n",
    "\n",
    "        #test_model.compile(\n",
    "        #    loss=categorical_crossentropy,\n",
    "        #    optimizer=Adam(lr=0.001, decay=0),\n",
    "        #    metrics=[\"acc\"],\n",
    "        #)\n",
    "    print(target.shape)\n",
    "    output = predict_window(model, slide, step_size=190, wsize=208)\n",
    "    prediction = colorvec[np.argmax(output, axis=-1)]\n",
    "    res_path = osp.join(\n",
    "        results_path,\n",
    "        train_date,\n",
    "        name,\n",
    "        loss_dir,\n",
    "        arch_dir,\n",
    "        ' '.join([class_wgt_dir, init_dir, act_dir])\n",
    "    )\n",
    "    if not osp.exists(res_path):\n",
    "        os.makedirs(res_path)\n",
    "    imsave(res_path + \"/result_argmax.png\", prediction.astype(np.uint8), check_contrast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def talos_predict_window(slide, model_id=None, stepSize=500, wsize=512):\n",
    "    X, Y, _ = slide.shape\n",
    "    if (X > wsize) & (Y > wsize):\n",
    "        output = np.ones(shape=(X, Y, num_cls))\n",
    "        for (x, y, dx, dy, I) in sliding_window(slide, wsize, (wsize, wsize)):\n",
    "            prediction = p.predict(np.expand_dims(I, axis=0), model_id)\n",
    "            output[x:dx, y:dy, :] = prediction\n",
    "        return output\n",
    "    else:\n",
    "        output = p.predict(np.expand_dims(slide, axis=0), model_id)\n",
    "        return output\n",
    "import pickle\n",
    "#with open(\"./weights/talos.pickle\", 'wb') as f:\n",
    "#    pickle.dump(t, f, -1)\n",
    "\n",
    "from keras.backend.tensorflow_backend import clear_session\n",
    "from keras.backend.tensorflow_backend import get_session\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_area_auto_adjustable\n",
    "\n",
    "try:\n",
    "    del t # this is from global space - change this as you need\n",
    "except:\n",
    "    pass\n",
    "\n",
    "#with open(\"./weights/talos.pickle\", 'rb') as f:\n",
    "#    t = pickle.load(f)\n",
    "def batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    counter = 0\n",
    "    for ndx in range(0, l, n):\n",
    "        counter += 1\n",
    "        yield counter, iterable[ndx:min(ndx + n, l)]\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (26.0, 38.0)\n",
    "weight_path = \"./weights/\"\n",
    "results_path = \"./results/\"\n",
    "train_date = \"2019-07-05\"\n",
    "weights = sorted(glob(osp.join(weight_path, train_date,\"cat_CE\", \"*.h5\")), key=str.lower)\n",
    "for count, b in batch(weights, 8):\n",
    "    \n",
    "    row_titles = []\n",
    "\n",
    "    pad = 5 # in points\n",
    "    #test_name = \"T4a\"\n",
    "    try:\n",
    "        for test_name, slide in test_slides.items():\n",
    "            sess = get_session()\n",
    "            clear_session()\n",
    "            sess.close()\n",
    "            sess = get_session()\n",
    "            \n",
    "            config = tf.ConfigProto()\n",
    "            config.gpu_options.allow_growth = True\n",
    "            K.tensorflow_backend.set_session(tf.Session(config=config))\n",
    "            #with tf.device('/cpu:*'): # Remember to re-indent model + compile below\n",
    "            model = u_net(\n",
    "                (None, None, 3),\n",
    "                64,\n",
    "                sigma_noise=0,\n",
    "                depth=4,\n",
    "                dropout=0,\n",
    "                output_channels=num_cls,\n",
    "                batchnorm=True,\n",
    "                pretrain=0,\n",
    "            )\n",
    "\n",
    "            model.compile(\n",
    "                loss=categorical_crossentropy,\n",
    "                optimizer=Adam(lr=0.001, decay=0),\n",
    "                metrics=[\"acc\"],\n",
    "            )\n",
    "\n",
    "            fig, axes = plt.subplots(\n",
    "                nrows=len(b),\n",
    "                ncols=num_cls+2,\n",
    "                sharex=True,\n",
    "                sharey=True,\n",
    "                figsize=(26, 1.5*len(b)),\n",
    "                gridspec_kw={'hspace': 0, 'wspace': 0}\n",
    "            )\n",
    "            for i, w in enumerate(b):\n",
    "                loss_dir = str(osp.split(w)[0]).split('/')[-1].split('-')[0]\n",
    "                base_name = osp.split(w)[-1]\n",
    "                class_wgt_dir = 'weights_{}'.format('True' in str(base_name))\n",
    "                act_dir = '{}'.format(base_name[base_name.rfind('act_'):base_name.find('-decay_')])\n",
    "                init_dir = '{}'.format(base_name[base_name.rfind('init_'):base_name.find('-act_')])\n",
    "                res_path = osp.join(\n",
    "                    results_path,\n",
    "                    train_date,\n",
    "                    test_name,\n",
    "                    loss_dir,\n",
    "                    ' '.join([class_wgt_dir, init_dir, act_dir])\n",
    "                )\n",
    "                row_titles.append(loss_dir + '\\n' + class_wgt_dir + '\\n' +  act_dir + '\\n' +  init_dir)\n",
    "                if not osp.exists(res_path):\n",
    "                    os.makedirs(res_path)\n",
    "                model.load_weights(w)\n",
    "                output = predict_window(slide)\n",
    "                for j in range(num_cls):\n",
    "                    axes[i, j].imshow(output[:,:,j], cmap=\"jet\")\n",
    "                    plt.imsave(res_path + \"/result-{}.png\".format(active_classes[j]), output[:,:,j], cmap=\"jet\")\n",
    "                axes[i, num_cls].imshow(colorvec[np.argmax(output, axis=-1)])\n",
    "                imsave(res_path + \"/result_argmax.png\", colorvec[np.argmax(output, axis=-1)].astype(np.uint8), check_contrast=False)\n",
    "                axes[i, num_cls+1].imshow(slide[...,[1,2,0]])\n",
    "\n",
    "            for ax, col in zip(axes[0], active_classes + [\"argmax\", \"input\"]):\n",
    "                ax.set_title(col)\n",
    "\n",
    "            for ax, row in zip(axes[:,0], row_titles):\n",
    "                ax.annotate(row, xy=(0, 0.5), xytext=(-ax.yaxis.labelpad - pad, 0),\n",
    "                xycoords=ax.yaxis.label, textcoords='offset points',\n",
    "                size='large', ha='right', va='center', wrap=True)\n",
    "            fig.tight_layout(pad=1.5)\n",
    "            fig.subplots_adjust(left=0.15, top=0.95)\n",
    "            plt.show()\n",
    "            fig.savefig(osp.join(\"./results\", train_date, test_name + \"-\" + str(count) + \"-overview.png\"))\n",
    "            fig.clear()\n",
    "            plt.close()\n",
    "    except Exception as e:\n",
    "        logger.error(str(e))\n",
    "        logger.error(traceback.format_exc())\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "from collections import namedtuple\n",
    "\n",
    "Size = namedtuple(\"Size\", [\"x\", \"y\"])\n",
    "\n",
    "weight_path = \"./weights/\"\n",
    "results_path = \"./results/\"\n",
    "train_date = \"2019-10-31\"\n",
    "weights = sorted(glob(osp.join(weight_path, train_date,\"*\",\"*\", \"*.h5\")), key=str.lower)\n",
    "#weights = [modelpath]\n",
    "INV_DPI = 1/100\n",
    "SCALE = 1/8\n",
    "\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_area_auto_adjustable\n",
    "\n",
    "def batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    counter = 0\n",
    "    for ndx in range(0, l, n):\n",
    "        counter += 1\n",
    "        yield counter, iterable[ndx:min(ndx + n, l)]\n",
    "\n",
    "def run_prediction(input_dict, target_dict, classes, colors, weight_list):\n",
    "    subslides = {}\n",
    "    num_classes = len(classes)\n",
    "    for name in target_dict.keys(): #[\"N9a-1\", \"T4a\"]:#\"N10a\", \"T4b-1\", \"T4b-2\"]:\n",
    "        subslides[name] = input_dict[name]\n",
    "    print(subslides.keys())\n",
    "    prediction_byte = {}\n",
    "    jaccard = {}\n",
    "    jaccard_weighted = {}\n",
    "    jaccard_weighted_nobg = {}\n",
    "\n",
    "    for count, b in batch(weight_list, 8):\n",
    "        row_titles = []\n",
    "        col_titles = classes.copy()\n",
    "        col_titles.extend([\"argmax\", \"target\", \"input\"])\n",
    "\n",
    "        pad = 5 # in points\n",
    "        #test_name = \"T4a\"\n",
    "        try:\n",
    "            fig, axes = {}, {}\n",
    "            for name, slide in subslides.items():\n",
    "                slide = np.squeeze(slide)\n",
    "                input_width = slide.shape[1]\n",
    "                input_height = slide.shape[0]\n",
    "                num_columns = num_classes+3\n",
    "                fig_width = input_width*INV_DPI*SCALE\n",
    "                fig_height = input_height*INV_DPI*SCALE\n",
    "                fig[name], axes[name] = plt.subplots(\n",
    "                    nrows=1,\n",
    "                    ncols=num_columns,\n",
    "                    sharex=True,\n",
    "                    sharey=True,\n",
    "                    figsize=(fig_width*num_columns, fig_height),\n",
    "                    gridspec_kw={'hspace': 0, 'wspace': 0}\n",
    "                )\n",
    "            for i, w in enumerate(b):\n",
    "                #sess = get_session()\n",
    "                #clear_session()\n",
    "                #sess.close()\n",
    "                #sess = get_session()\n",
    "\n",
    "                #config = tf.ConfigProto()\n",
    "                #config.gpu_options.allow_growth = True\n",
    "                #K.tensorflow_backend.set_session(tf.Session(config=config))\n",
    "                with tf.device('/cpu:*'): # Remember to re-indent model + compile below\n",
    "                #model = u_net(\n",
    "                #    (None, None, 3),\n",
    "                #    64,\n",
    "                #    sigma_noise=0,\n",
    "                #    depth=4,\n",
    "                #    dropout=0,\n",
    "                #    output_channels=num_cls,\n",
    "                #    batchnorm=True,\n",
    "                #    pretrain=0,\n",
    "                #)\n",
    "                    test_kwargs = model_kwargs\n",
    "                    test_kwargs[\"activation\"] = Swish\n",
    "                    test_kwargs[\"output_channels\"] = num_cls\n",
    "\n",
    "                #test_model = u_net(SHAPE, **test_kwargs)\n",
    "                    test_model = load_model(w, custom_objects={'Swish': Swish})\n",
    "\n",
    "                    test_model.compile(\n",
    "                        loss=categorical_crossentropy,\n",
    "                        optimizer=Adam(lr=0.001, decay=0),\n",
    "                        metrics=[\"acc\"],\n",
    "                    )\n",
    "\n",
    "                for test_name, slide in subslides.items():\n",
    "                    slide = np.squeeze(slide)\n",
    "                    loss_dir = str(osp.split(w)[0]).split('/')[-2]\n",
    "                    arch_dir = str(osp.split(w)[0]).split('/')[-1]\n",
    "                    base_name = osp.split(w)[-1]\n",
    "                    class_wgt_dir = 'weights_{}'.format('True' in str(base_name))\n",
    "                    act_dir = '{}'.format(base_name[base_name.rfind('activation_'):base_name.find('-dropout_')])\n",
    "                    init_dir = '{}'.format(base_name[base_name.rfind('initialization_'):base_name.find('-activation_')])\n",
    "                    #pre_dir = '{}'.format(base_name[base_name.rfind('pretrain_'):base_name.find('-sigma_')])\n",
    "                    res_path = osp.join(\n",
    "                        results_path,\n",
    "                        train_date,\n",
    "                        test_name,\n",
    "                        loss_dir,\n",
    "                        arch_dir,\n",
    "                        ' '.join([class_wgt_dir, init_dir, act_dir])\n",
    "                    )\n",
    "                    row_titles.append(loss_dir + '\\n' + class_wgt_dir + '\\n' +  act_dir + '\\n' +  init_dir)\n",
    "                    if not osp.exists(res_path):\n",
    "                        os.makedirs(res_path)\n",
    "                    raw_input = auto_contrast(slide)\n",
    "                    #test_model.load_weights(w)\n",
    "                    print(f\"slide: {slide.shape!s:>10}\")\n",
    "                    output = predict_window(test_model, slide, num_class=num_classes)\n",
    "                    prediction = colorvec[np.argmax(output, axis=-1)]\n",
    "                    prediction_byte[test_name] = np.argmax(output, axis=-1)\n",
    "                    target_byte = np.argmax(target_dict[test_name], axis=-1)\n",
    "                    print(f\"prediction_byte: {prediction_byte[test_name].shape!s:>10}\")\n",
    "                    print(f\"test_target: {test_targets[test_name].shape!s:>10}\")\n",
    "                    print(f\"test_target_byte: {target_byte.shape!s:>10}\")\n",
    "                    jaccard[test_name] = jaccard_score(np.ndarray.flatten(prediction_byte[test_name]),\n",
    "                                                       np.ndarray.flatten(target_byte),\n",
    "                                                       average=None)\n",
    "                    jaccard_weighted[test_name] = jaccard_score(np.ndarray.flatten(prediction_byte[test_name]),\n",
    "                                                       np.ndarray.flatten(target_byte),\n",
    "                                                       average='weighted')\n",
    "                    jaccard_weighted_nobg[test_name] = jaccard_score(np.ndarray.flatten(prediction_byte[test_name]),\n",
    "                                                       np.ndarray.flatten(target_byte),\n",
    "                                                       labels=active_labels[1:],\n",
    "                                                       average='weighted')\n",
    "                    if len(b) == 1:\n",
    "                        for j in range(num_classes):\n",
    "                            axes[test_name][j].imshow(output[:,:,j], cmap=\"jet\")\n",
    "                            plt.imsave(res_path + \"/result-{}.png\".format(classes[j]), output[:,:,j], cmap=\"jet\")\n",
    "                        axes[test_name][num_classes].imshow(prediction)\n",
    "                        axes[test_name][num_classes+1].imshow(colors[target_byte])\n",
    "                        axes[test_name][num_classes+2].imshow(raw_input)\n",
    "                    else:\n",
    "                        for j in range(num_classes):\n",
    "                            axes[test_name][i, j].imshow(output[:,:,j], cmap=\"jet\")\n",
    "                            plt.imsave(res_path + \"/result-{}.png\".format(classes[j]), output[:,:,j], cmap=\"jet\")\n",
    "                        axes[test_name][i, num_classes].imshow(prediction)\n",
    "                        axes[test_name][i, num_classes+1].imshow(colors[target_byte])\n",
    "                        axes[test_name][i, num_classes+2].imshow(raw_input)\n",
    "                    imsave(res_path + \"/result_argmax.png\", prediction.astype(np.uint8), check_contrast=False)\n",
    "                    imsave(res_path + \"/result_input.png\", np.array(raw_input*256., dtype=np.uint8), check_contrast=False)\n",
    "\n",
    "            for name in subslides.keys():\n",
    "                if len(b) == 1:\n",
    "                    for ax, col in zip(axes[name][:], col_titles):\n",
    "                        ax.set_title(col)\n",
    "                    for row in row_titles:\n",
    "                        axes[name][0].annotate(row, xy=(0, 0.5), xytext=(-axes[name][0].yaxis.labelpad - pad, 0),\n",
    "                        xycoords=axes[name][0].yaxis.label, textcoords='offset points',\n",
    "                        size='large', ha='right', va='center', wrap=True)\n",
    "                else:\n",
    "                    for ax, col in zip(axes[name][0], col_titles):\n",
    "                        ax.set_title(col)\n",
    "                    for ax, row in zip(axes[name][:,0], row_titles):\n",
    "                        ax.annotate(row, xy=(0, 0.5), xytext=(-ax.yaxis.labelpad - pad, 0),\n",
    "                        xycoords=ax.yaxis.label, textcoords='offset points',\n",
    "                        size='large', ha='right', va='center', wrap=True)\n",
    "                fig[name].tight_layout(pad=1.5)\n",
    "                fig[name].subplots_adjust(left=0.15, top=0.95)\n",
    "                plt.show()\n",
    "                fig[name].savefig(osp.join(\"./results\", train_date, name + \"-\" + str(count) + \"-overview.png\"))\n",
    "                fig[name].clear()\n",
    "                plt.close()\n",
    "        except Exception as e:\n",
    "            logger.error(str(e))\n",
    "            logger.error(traceback.format_exc())\n",
    "            raise\n",
    "\n",
    "merged_classes = ['Background', \"Healthy\", \"Cancer\", \"Other\"]\n",
    "merged_colors = np.array([[0, 0, 0], [0, 255, 0], [255, 0, 0], [128, 128, 128]])\n",
    "run_prediction(test_slides, binary_test_targets, merged_classes, merged_colors, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print(\"jaccard:\", jaccard)\n",
    "print(\"jaccard_weighted: \", jaccard_weighted)\n",
    "print(\"jaccard_weighted_nobg: \", jaccard_weighted_nobg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "###################################\n",
    "#Clean session\n",
    "sess = get_session()\n",
    "clear_session()\n",
    "sess.close()\n",
    "# TensorFlow wizardry\n",
    "config = tf.ConfigProto(log_device_placement=True)\n",
    "\n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "# Only allow a total of half the GPU memory to be allocated\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "\n",
    "# Create a session with the above options specified.\n",
    "K.tensorflow_backend.set_session(tf.Session(config=config))\n",
    "###################################\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true,
    "tags": [
     "main",
     "train"
    ]
   },
   "outputs": [],
   "source": [
    "# I/O Params\n",
    "weight_path = \"./weights/\"\n",
    "remap_pattern = {0: [0, ], 1: [2, 3, 5], 2: [7, 8, 9], 3: [10, 1, 4, 6]}\n",
    "bin_class = len(remap_pattern)\n",
    "#IMG_ROWS, IMG_COLS, IMG_CHANNELS = (208, 208, 3)\n",
    "IMG_ROWS, IMG_COLS, IMG_CHANNELS = (None, None, 3)\n",
    "# architecture params\n",
    "NB_FILTERS_0 = 64\n",
    "SIGMA_NOISE = 0.01\n",
    "\n",
    "# ****  deep learning model\n",
    "SHAPE = (IMG_ROWS, IMG_COLS, IMG_CHANNELS)\n",
    "BATCH_SIZE = 12\n",
    "NB_EPOCH = 400\n",
    "NB_FROZEN = 40\n",
    "VERBOSE = 0\n",
    "# fit params\n",
    "today_str = str(datetime.date.today())\n",
    "DROP = 0\n",
    "\n",
    "OPT_NAME = \"adam\"  # choices:adadelta; sgd, rmsprop, adagrad, adam\n",
    "if OPT_NAME == \"sgd\":\n",
    "    OPT = SGD(lr=0.1)\n",
    "elif OPT_NAME == \"rmsprop\":\n",
    "    OPT = RMSprop()\n",
    "elif OPT_NAME == \"adagrad\":\n",
    "    OPT = Adagrad()\n",
    "elif OPT_NAME == \"adadelta\":\n",
    "    OPT = Adadelta()\n",
    "elif OPT_NAME == \"adam\":\n",
    "    OPT = Adam(lr=1e-3, decay=0.0)\n",
    "elif OPT_NAME == \"amsgrad\":\n",
    "    OPT = Adam(lr=1e-4, amsgrad=True)\n",
    "elif OPT_NAME == \"adamax\":\n",
    "    OPT = Adamax()\n",
    "elif OPT_NAME == \"nadam\":\n",
    "    OPT = Nadam()\n",
    "else:\n",
    "    raise NameError(\"Wrong optimizer name\")\n",
    "\n",
    "train_tiles = [\n",
    "    osp.splitext(osp.basename(i))[0]\n",
    "    for i in glob(osp.join(data_path, train_path, \"*.tif\"))\n",
    "]\n",
    "val_tiles = [\n",
    "    osp.splitext(osp.basename(i))[0]\n",
    "    for i in glob(osp.join(data_path, val_path, \"*.tif\"))\n",
    "]\n",
    "\n",
    "train_generator = DataGenerator(\n",
    "    osp.join(data_path, train_path),\n",
    "    colorvec,\n",
    "    train_m,\n",
    "    train_s,\n",
    "    x_min,\n",
    "    x_max,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    dim=(208, 208),\n",
    "    n_channels=3,\n",
    "    n_classes=bin_class,\n",
    "    shuffle=True,\n",
    "    augmenter=True,\n",
    "    remap_labels=remap_pattern\n",
    ")\n",
    "\n",
    "val_generator = DataGenerator(\n",
    "    osp.join(data_path, val_path),\n",
    "    colorvec,\n",
    "    train_m,\n",
    "    train_s,\n",
    "    x_min,\n",
    "    x_max,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    dim=(208, 208),\n",
    "    n_channels=3,\n",
    "    n_classes=bin_class,\n",
    "    shuffle=True,\n",
    "    augmenter=True,\n",
    "    remap_labels=remap_pattern\n",
    ")\n",
    "\n",
    "model_kwargs = {\n",
    "    \"nb_filters\": NB_FILTERS_0,\n",
    "    \"sigma_noise\": SIGMA_NOISE,\n",
    "    \"depth\": 4,\n",
    "    \"maxpool\": False,\n",
    "    \"initialization\": \"he_normal\",\n",
    "    \"activation\": \"Swish\",\n",
    "    \"dropout\": 0,\n",
    "    \"batchnorm\": True,\n",
    "    \"arch\": \"U-Net\",\n",
    "}\n",
    "\n",
    "model_base_path = osp.join(weight_path, today_str, \"cat_CE\", \"arch-\" + model_kwargs[\"arch\"])\n",
    "\n",
    "path_elements = [\n",
    "    '{}_{}'.format(key, val.__name__)\n",
    "    if hasattr(val, '__name__')\n",
    "    else '{}_{}'.format(key, val) for key, val in model_kwargs.items()\n",
    "]\n",
    "path_elements.remove('{}_{}'.format(\"arch\", model_kwargs[\"arch\"]))\n",
    "path_elements.append(\"remapped_labels\")\n",
    "\n",
    "if not os.path.exists(model_base_path):\n",
    "    os.makedirs(model_base_path, exist_ok=True)\n",
    "\n",
    "modelpath = osp.join(\n",
    "    model_base_path,\n",
    "    '-'.join(path_elements) + \".h5\"\n",
    ")\n",
    "\n",
    "log_path = osp.join(\n",
    "    \"./logs/\",\n",
    "    today_str,\n",
    "    \"cat_CE\",\n",
    "    model_kwargs[\"arch\"],\n",
    "    *path_elements, ''\n",
    ")\n",
    "\n",
    "#model = u_net(SHAPE, NB_FILTERS_0, depth=3, dropout=DROP, batchnorm=True, maxpool=False, output_channels=num_cls, resnet=True)\n",
    "model = load_model(osp.join(weight_path,\"2019-09-20\",\"pretrain_U-net_model.h5\"), custom_objects={'Swish': Swish})\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D\n",
    "model_inputs = model.inputs\n",
    "model_preout = model.layers[-2].output\n",
    "new_output = Conv2D(bin_class, 1, activation=\"softmax\", name=\"conv_out\")(model_preout)\n",
    "model = Model(inputs=model.inputs, outputs=new_output)\n",
    "pretrain_layers = [\n",
    "    \"block{}_d_conv{}\".format(block, layer)\n",
    "    for block in range(1, 4 + 1)\n",
    "    for layer in range(1, 3)\n",
    "]\n",
    "for i, n in enumerate(pretrain_layers):\n",
    "    model.get_layer(name=n).trainable = False\n",
    "model.compile(loss=categorical_crossentropy, optimizer=Adam(lr=1e-3, decay=0.0), metrics=[\"acc\"])\n",
    "\n",
    "print(model.summary(line_length=124))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "main",
     "train"
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"from keras_tqdm import TQDMNotebookCallback\n",
    "from mmciad.utils.callbacks import PatchedModelCheckpoint\n",
    "\n",
    "#class_weights = [1 if k != 12 else 0 for k in active_labels]\n",
    "\n",
    "progressbar = TQDMNotebookCallback(\n",
    "    metric_format=\"{name}: {value:0.4f}\", leave_inner=True, leave_outer=True\n",
    ")\n",
    "tensor_board = TensorBoard(\n",
    "    log_dir=log_path,\n",
    "    histogram_freq=0,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    write_graph=True,\n",
    "    write_grads=False,\n",
    "    write_images=True,\n",
    "    embeddings_freq=0,\n",
    "    update_freq=\"epoch\"\n",
    ")\n",
    "early_stopper = EarlyStopping(monitor=\"loss\", patience=40, verbose=1, mode=\"auto\")\n",
    "reducer = ReduceLROnPlateau(\n",
    "    monitor=\"loss\",\n",
    "    factor=0.1,\n",
    "    patience=10,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1,\n",
    ")\n",
    "model_checkpoint = PatchedModelCheckpoint(\n",
    "    modelpath, verbose=0, monitor=\"loss\", save_best_only=True,\n",
    ")\n",
    "model_callbacks = [progressbar, tensor_board, early_stopper, reducer, model_checkpoint]\n",
    "\n",
    "frozen_history = model.fit_generator(\n",
    "    generator=train_generator,\n",
    "    epochs=NB_FROZEN,\n",
    "    validation_data=val_generator,\n",
    "    use_multiprocessing=True,\n",
    "    workers=30,\n",
    "    verbose=VERBOSE,\n",
    "    callbacks=model_callbacks,\n",
    ")\n",
    "\"\"\"\n",
    "model = load_model(modelpath, custom_objects={'Swish': Swish})\n",
    "\n",
    "for n in pretrain_layers:\n",
    "    model.get_layer(name=n).trainable = True\n",
    "\n",
    "model.compile(loss=categorical_crossentropy, optimizer=Adam(lr=1e-4, decay=0.0), metrics=[\"acc\"])\n",
    "\n",
    "history = model.fit_generator(\n",
    "    generator=train_generator,\n",
    "    epochs=NB_EPOCH,\n",
    "    initial_epoch=NB_FROZEN,\n",
    "    validation_data=val_generator,\n",
    "    use_multiprocessing=True,\n",
    "    workers=30,\n",
    "    verbose=VERBOSE,\n",
    "    callbacks=model_callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "min_loss = np.argmin(history.history['loss'])\n",
    "epoch_init = 39+1\n",
    "print(\"Best loss: %.5f\" % (np.min(history.history['loss'])))\n",
    "print(\"at: %d\" % (epoch_init+min_loss))\n",
    "print(f\"accuracy at {epoch_init+min_loss}:            {history.history['acc'][min_loss]:.5f}\")\n",
    "print(f\"validation accuracy at {epoch_init+min_loss}: {history.history['val_acc'][min_loss]:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "main",
     "test"
    ]
   },
   "outputs": [],
   "source": [
    "abr = [\"cc\", \"wcc\", \"tl\", \"wtl\"]\n",
    "lf = [\n",
    "    \"categorical_crossentropy\",\n",
    "    \"weighted_categorical_crossentropy\",\n",
    "    \"tversky_loss\",\n",
    "    \"weighted_tversky_loss\",\n",
    "]\n",
    "test_slides = load_slide(path, \"test\", train_m, train_s, False)\n",
    "model_path = \"./weights/\"\n",
    "results_path = \"./results/\"\n",
    "train_date = \"2019-06-03\"\n",
    "pred_slide = [[None] * len(abr) for _ in range(test_slides.shape[0])]\n",
    "for short, long, outer in zip(abr, lf, range(len(abr))):\n",
    "    weights = osp.join(model_path, train_date,\n",
    "                       \"batchnorm_U-net_model-200epochs_batchsize_16.loss_func_{}-weights.pickle\".format(long))\n",
    "    load_weight_light(model, weights)\n",
    "    if not osp.exists(osp.join(results_path, train_date)):\n",
    "        os.mkdir(osp.join(results_path, train_date))\n",
    "    for i, slide in enumerate(test_slides):\n",
    "        pred_slide[i][outer] = predict_window(slide)\n",
    "\n",
    "    for i, slide in enumerate([sublist[outer] for sublist in pred_slide], 1):\n",
    "        plt.subplot(len(abr) + 1, test_slides.shape[0], i + outer * (len(abr) - 1))\n",
    "        plt.imshow(colorvec[np.argmax(slide, axis=-1)])\n",
    "        imsave(\n",
    "            \"./results/{}/{}-{}.png\".format(train_date, short, i),\n",
    "            colorvec[np.argmax(slide, axis=-1)].astype(np.uint8),\n",
    "            check_contrast=False,\n",
    "        )\n",
    "\n",
    "mean_pred = [None] * len(test_slides)\n",
    "for i, yhat in enumerate(pred_slide):\n",
    "    mean_pred[i] = np.asarray(yhat).mean(axis=0)\n",
    "    plt.subplot(len(abr) + 1, test_slides.shape[0], 1 + i + len(abr) * (len(abr) - 1))\n",
    "    plt.imshow(colorvec[np.argmax(mean_pred[i], axis=-1)])\n",
    "    imsave(\n",
    "        \"./results/{}/mean-{}.png\".format(train_date, i + 1),\n",
    "        colorvec[np.argmax(mean_pred[i], axis=-1)].astype(np.uint8),\n",
    "        check_contrast=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "## Manual Talos prediction\n",
    "test_slides = load_slide(path, \"test\", train_m, train_s, False)\n",
    "model_path = \"./weights/\"\n",
    "results_path = \"./results/\"\n",
    "train_date = \"2019-06-06\"\n",
    "\n",
    "img_rows, img_cols, img_channels = (None, None, 3)\n",
    "# architecture params\n",
    "nb_filters_0 = 64\n",
    "batchnorm = True\n",
    "\n",
    "# ****  deep learning model\n",
    "shape = (img_rows, img_cols, img_channels)\n",
    "batch_size = 16\n",
    "nb_epoch = 200\n",
    "verbose = 0\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20.0, 16.0)\n",
    "\n",
    "weight_pickles = sorted(glob(osp.join(model_path, train_date,\n",
    "                       \"talos_bn_U-net_model-200epochs-*.pickle\")), key=str.lower)\n",
    "pred_slide = [[None] * len(weight_pickles) for _ in range(test_slides.shape[0])]\n",
    "for outer, w in enumerate(weight_pickles[4:]):\n",
    "    if \"cat_FL\" in w:\n",
    "        loss_func = categorical_focal_loss()\n",
    "    elif \"cat_CE\" in w:\n",
    "        loss_func = categorical_crossentropy\n",
    "    else:\n",
    "        raise NameError(\"Something's wrong!\")\n",
    "    \n",
    "    if \"pretrain_2\" in w:\n",
    "        pt = 2\n",
    "    else:\n",
    "        pt = 0\n",
    "    \n",
    "    if \"sigma_0.005\" in w:\n",
    "        sigma = 0.005\n",
    "    else:\n",
    "        sigma = 0\n",
    "\n",
    "    if \"drop_0.05\" in w:\n",
    "        drop = 0.05\n",
    "    else:\n",
    "        drop = 0\n",
    "\n",
    "    model = u_net(shape, nb_filters_0, sigma_noise=sigma, depth=4,\n",
    "                  dropout=drop, output_channels=num_cls, batchnorm=True, pretrain=pt)\n",
    "    model.compile(loss=loss_func, optimizer=Adam(lr=1e-4, decay=0.1))\n",
    "    load_weight_light(model, w)\n",
    "    \n",
    "    if not osp.exists(osp.join(results_path, train_date)):\n",
    "        os.mkdir(osp.join(results_path, train_date))\n",
    "    for i, slide in enumerate(test_slides):\n",
    "        pred_slide[i][outer] = predict_window(slide)\n",
    "\n",
    "    for i, slide in enumerate([sublist[outer] for sublist in pred_slide], 1):\n",
    "        plt.subplot(len(weight_pickles), test_slides.shape[0], i + outer * (test_slides.shape[0]))\n",
    "        plt.imshow(colorvec[np.argmax(slide, axis=-1)])\n",
    "        imsave(\n",
    "            \"./results/{}/{}-{}.png\".format(train_date, osp.split(w)[-1], i),\n",
    "            colorvec[np.argmax(slide, axis=-1)].astype(np.uint8),\n",
    "            check_contrast=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "visuals"
    ]
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "\n",
    "model.load_weights(\n",
    "    path\n",
    "    + \"U-net_model_200epochs.batchsize_16.loss_func_weighted_categorical_crossentropy-weights.h5\"\n",
    ")\n",
    "print(len(model.layers))\n",
    "layer_outputs = [layer.output for layer in model.layers[:10]]\n",
    "activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "\n",
    "activations = activation_model.predict(np.expand_dims(test_slides[1], axis=0))\n",
    "\n",
    "layer_names = []\n",
    "for layer in classifier.layers[:10]:\n",
    "    layer_names.append(\n",
    "        layer.name\n",
    "    )  # Names of the layers, so you can have them as part of your plot\n",
    "\n",
    "images_per_row = 16\n",
    "\n",
    "for layer_name, layer_activation in zip(\n",
    "    layer_names, activations\n",
    "):  # Displays the feature maps\n",
    "    n_features = layer_activation.shape[-1]  # Number of features in the feature map\n",
    "    size = layer_activation.shape[\n",
    "        1\n",
    "    ]  # The feature map has shape (1, size, size, n_features).\n",
    "    n_cols = (\n",
    "        n_features // images_per_row\n",
    "    )  # Tiles the activation channels in this matrix\n",
    "    display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "    for col in range(n_cols):  # Tiles each filter into a big horizontal grid\n",
    "        for row in range(images_per_row):\n",
    "            channel_image = layer_activation[0, :, :, col * images_per_row + row]\n",
    "            channel_image -= (\n",
    "                channel_image.mean()\n",
    "            )  # Post-processes the feature to make it visually palatable\n",
    "            channel_image /= channel_image.std()\n",
    "            channel_image *= 64\n",
    "            channel_image += 128\n",
    "            channel_image = np.clip(channel_image, 0, 255).astype(\"uint8\")\n",
    "            display_grid[\n",
    "                col * size : (col + 1) * size,  # Displays the grid\n",
    "                row * size : (row + 1) * size,\n",
    "            ] = channel_image\n",
    "    scale = 1. / size\n",
    "    plt.figure(figsize=(scale * display_grid.shape[1], scale * display_grid.shape[0]))\n",
    "    plt.title(layer_name)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(display_grid, aspect=\"auto\", cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "visuals"
    ]
   },
   "outputs": [],
   "source": [
    "from keract import get_activations, display_activations\n",
    "print(test_slides[1].shape)\n",
    "with tf.device('/cpu:*'):\n",
    "    cpumodel = u_net(\n",
    "        (None, None, 3),\n",
    "        64,\n",
    "        sigma_noise=0,\n",
    "        depth=4,\n",
    "        dropout=0,\n",
    "        output_channels=num_cls,\n",
    "        batchnorm=True,\n",
    "        pretrain=0,\n",
    "    )\n",
    "\n",
    "    cpumodel.compile(\n",
    "        loss=categorical_crossentropy,\n",
    "        optimizer=Adam(lr=0.001, decay=0),\n",
    "        metrics=[\"acc\"],\n",
    "    )\n",
    "\n",
    "#plt.rcParams['figure.figsize'] = (20.0, 16.0)\n",
    "weights = sorted(glob(osp.join(weight_path, \"2019-06-24\",\"*\", \"*.h5\")), key=str.lower)\n",
    "\n",
    "for i, w in enumerate(weights):\n",
    "    #p = ta.Predict(t)\n",
    "    #output.append(talos_predict_window(test_slides[1]))\n",
    "    cpumodel.load_weights(w)\n",
    "    activations = get_activations(cpumodel, np.expand_dims(test_slides[1], axis=0), \"block1_conv2\")\n",
    "    display_activations(activations, cmap=\"gray\", save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "tags": [
     "visuals"
    ]
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 12))\n",
    "plt.imshow(imread(\"./data/test-N9a-corrected-1.tif\")[-2048:, 500:2548, :])\n",
    "rows = 4\n",
    "columns = 8\n",
    "figact1, axs = plt.subplots(\n",
    "    ncols=columns, nrows=rows, sharex=True, sharey=True, figsize=(12, 12)\n",
    ")\n",
    "first = activations.get(\"conv1_2_1/Relu:0\")\n",
    "print(first.shape)\n",
    "print(first.min(), first.max())\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    img = first[0, :, :, i]\n",
    "    im = ax.imshow(img, cmap=\"jet\")\n",
    "    plt.axis(\"off\")\n",
    "axcb = figact1.colorbar(im, ax=axs.ravel().tolist(), pad=0.04, aspect=30)\n",
    "plt.show()\n",
    "rows = 8\n",
    "columns = 8\n",
    "figact2, axs = plt.subplots(\n",
    "    ncols=columns, nrows=rows, sharex=True, sharey=True, figsize=(12, 12)\n",
    ")\n",
    "second = activations.get(\"conv2_2_1/Relu:0\")\n",
    "print(second.shape)\n",
    "print(second.min(), second.max())\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    img = second[0, :, :, i]\n",
    "    im = ax.imshow(img, cmap=\"jet\")\n",
    "    plt.axis(\"off\")\n",
    "axcb = figact2.colorbar(im, ax=axs.ravel().tolist(), pad=0.04, aspect=30)\n",
    "plt.show()\n",
    "rows = 16\n",
    "columns = 8\n",
    "figact3, axs = plt.subplots(\n",
    "    ncols=columns, nrows=rows, sharex=True, sharey=True, figsize=(12, 12)\n",
    ")\n",
    "third = activations.get(\"conv3_2_1/Relu:0\")\n",
    "print(third.shape)\n",
    "print(third.min(), third.max())\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    img = third[0, :, :, i]\n",
    "    im = ax.imshow(img, cmap=\"jet\")\n",
    "    plt.axis(\"off\")\n",
    "axcb = figact3.colorbar(im, ax=axs.ravel().tolist(), pad=0.04, aspect=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "random_input_image = np.random.random((1, IMG_ROWS, IMG_COLS, IMG_CHANNELS)) * 20 + 128.\n",
    "output_image = model.get_layer('conv_out').output\n",
    "input_image = model.get_layer('input_layer').input\n",
    "target_class = active_labels.index(class_map['Cancer'])\n",
    "\n",
    "loss = (K.mean(output_image[...,target_class], axis=-1)\n",
    "       -K.mean(\n",
    "           K.concatenate((\n",
    "               output_image[...,:target_class],\n",
    "               output_image[...,target_class+1:]\n",
    "               )), axis=-1)\n",
    "       )\n",
    "step = 1.\n",
    "grads = K.gradients(loss, input_image)[0] \n",
    "def normalize(x):\n",
    "    # utility function to normalize a tensor by its L2 norm\n",
    "    return x / (K.sqrt(K.mean(K.square(x))) + 1e-5)\n",
    "grads = normalize(grads)\n",
    "iterate = K.function([input_image], [loss, grads])\n",
    "for i in range(30):\n",
    "    loss_value, grads_value = iterate([random_input_image])\n",
    "    random_input_image += grads_value * step\n",
    "def deprocess_image(x):\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "result_img = deprocess_image(random_input_image[0])\n",
    "plt.rcParams[\"figure.figsize\"] = (12.0, 12.0)\n",
    "plt.imshow(result_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train_slides = load_slides_as_dict(data_path,'train', load_gt=False)\n",
    "print(len(train_slides))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import seaborn as sns\n",
    "num_slides = len(train_slides)\n",
    "plt.rcParams[\"figure.figsize\"] = (20.0, 24.0)\n",
    "fig, axes = plt.subplots(nrows=num_slides, ncols=3)\n",
    "for (row, (name, img)), col in product(enumerate(train_slides.items()), range(3)):\n",
    "    axes[row][col].set_ylabel(name)\n",
    "    sns.distplot(a = np.ravel(img[...,col])*255, bins=256, hist=True, ax=axes[row][col])\n",
    "axes[0][0].set_title(\"SHG\")\n",
    "axes[0][1].set_title(\"CARS\")\n",
    "axes[0][2].set_title(\"TPEF\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2.1",
   "language": "python",
   "name": "tensorflow2.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
