{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# AAA Image Segmentation\n",
    "This notebook will set up and either train a network or predict segmentations based on previous training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary steps\n",
    "Load all the relevant libraries and set up some global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": [
     "preamble",
     "main",
     "main-no_create"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Python version 3.8.2\n",
      "Build 3.8.2 (default, May 12 2020, 20:53:31) \n",
      "[GCC 7.5.0]\n",
      "TensorFlow version 2.2.0\n",
      "Num GPUs: 1\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import sys\n",
    "import resource\n",
    "import os\n",
    "import os.path as osp\n",
    "import shutil\n",
    "import yaml\n",
    "import confuse\n",
    "import datetime\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import traceback\n",
    "from numpngw import write_png\n",
    "\n",
    "os.environ[\"TF_KERAS\"] = \"1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import (\n",
    "    SGD,\n",
    "    RMSprop,\n",
    "    Adagrad,\n",
    "    Adadelta,\n",
    "    Adam,\n",
    "    Adamax,\n",
    "    Nadam,\n",
    ")\n",
    "from keras_radam import RAdam\n",
    "from tensorflow.keras.layers import ReLU\n",
    "from keras_contrib.layers.advanced_activations.swish import Swish\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    ReduceLROnPlateau,\n",
    "    TensorBoard,\n",
    "    CSVLogger,\n",
    ")\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "import tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "from tqdm.keras import TqdmCallback\n",
    "import talos as ta\n",
    "from talos.model.early_stopper import early_stopper\n",
    "\n",
    "# local package\n",
    "from tf_mmciad.utils.io import create_samples, load_slides_as_dict, move_files_in_dir\n",
    "from tf_mmciad.utils.generator import DataGenerator, DataSet\n",
    "from tf_mmciad.utils.u_net import u_net\n",
    "from tf_mmciad.utils.u_resnet import u_resnet\n",
    "from tf_mmciad.utils.custom_loss import (\n",
    "    weighted_loss,\n",
    "    jaccard1_coef,\n",
    "    jaccard2_loss,\n",
    "    tversky_loss,\n",
    "    categorical_focal_loss,\n",
    "    get_weighted_categorical_crossentropy,\n",
    ")\n",
    "from tf_mmciad.utils.preprocessing import (\n",
    "    calculate_stats,\n",
    "    augmentor,\n",
    "    calculate_class_weights,\n",
    "    class_ratio,\n",
    ")\n",
    "from tf_mmciad.utils.callbacks import PatchedModelCheckpoint, DeadReluDetector\n",
    "\n",
    "print(f\"Running Python version {platform.python_version()}\")\n",
    "print(f\"Build {sys.version}\")\n",
    "print(f\"TensorFlow version {tf.__version__}\")\n",
    "\n",
    "###################################\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "print(\"Num GPUs:\", len(gpus))\n",
    "# TensorFlow wizardry\n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "# Only allow a total of half the GPU memory to be allocated\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "\n",
    "###################################\n",
    "\n",
    "# Magic used by the notebook to show figures inline\n",
    "\n",
    "%matplotlib inline\n",
    "# matplotlib default values\n",
    "plt.rcParams[\"figure.figsize\"] = (20.0, 16.0)\n",
    "plt.rcParams[\"image.interpolation\"] = \"nearest\"\n",
    "plt.rcParams[\"image.cmap\"] = \"jet\"\n",
    "\n",
    "# auto-reloading packages\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "preamble",
     "main",
     "main-no_create"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ignore*', 'Zone 1', 'Zone 2', 'Thrombus']\n",
      "{1: [180, 180, 180], 2: [0, 0, 255], 3: [0, 255, 0], 4: [255, 0, 0]}\n",
      "(4, 3)\n",
      "0.0001\n",
      "<class 'float'>\n"
     ]
    }
   ],
   "source": [
    "from skimage.io import imread, imsave\n",
    "from glob import glob\n",
    "config = confuse.Configuration('AAAml', __name__)\n",
    "config.set_file(\"config.yaml\")\n",
    "\n",
    "date_string = config['Runtime']['date_string'].get() #\"2020-05-13\" # If None, current date will be used\n",
    "clean_start = config['Runtime']['clean_start'].get()\n",
    "run_grid_search = config['Runtime']['run_grid_search'].get()\n",
    "run_train = config['Runtime']['run_train'].get()\n",
    "run_predict = config['Runtime']['run_predict'].get()\n",
    "run_eval = config['Runtime']['run_eval'].get()\n",
    "compute_class_weights = config['Runtime']['compute_class_weights'].get()\n",
    "debug = config['Runtime']['debug'].get()\n",
    "make_abundance_table = config['Runtime']['make_abundance_table'].get()\n",
    "\n",
    "#class_map = {\n",
    "#    \"None\": 0,\n",
    "#    \"Ignore*\": 1,\n",
    "#    \"Zone 1\": 2,\n",
    "#    \"Zone 2\": 3,\n",
    "#    \"Thrombus\": 4,\n",
    "#}\n",
    "class_map = config['class_map'].get()\n",
    "\n",
    "class_colors = config['class_colors'].get()#{\n",
    "#    0: [0, 0, 0],\n",
    "#    1: [180, 180, 180],\n",
    "#    2: [0, 0, 255],\n",
    "#    3: [0, 255, 0],\n",
    "#    4: [255, 0, 0],\n",
    "#}\n",
    "active_labels = [1, 2, 3, 4]\n",
    "active_classes = [sorted(class_map, key=class_map.get)[i] for i in active_labels]\n",
    "print(active_classes)\n",
    "colorvec = np.asarray([class_colors[i] for i in active_labels])\n",
    "active_colors = {class_: class_colors[class_] for class_ in active_labels}\n",
    "num_cls = len(active_labels)\n",
    "print(active_colors)\n",
    "print(colorvec.shape)\n",
    "ignore_cls = 0\n",
    "\n",
    "dpaths = config['data'].get()\n",
    "data_path = dpaths['path'] #\"data/\"\n",
    "wsi_path = dpaths['wsi'] #\"data/WSI/\"\n",
    "train_path = dpaths['train'] #\"training/\"\n",
    "val_path = dpaths['val'] #\"validation/\"\n",
    "test_path = dpaths['test'] #\"testing/\"\n",
    "model_storage = dpaths['models'] #\"models\"\n",
    "weight_path = dpaths['models'] #\"./weights/\"\n",
    "ignore_color = class_colors[0]\n",
    "TILE_SIZE = (*config['input_meta']['tile_size'].get(),)\n",
    "print(float(config['statics']['lr'].get()))\n",
    "print(type(config['statics']['lr'].get()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "main"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Train set:\n",
      "    ---------\n",
      "    Created no X tiles in directory: data/data/training/.\n",
      "    Created no Y tiles in directory: data/data/training/gt/.\n",
      "    \n",
      "    Validation set:\n",
      "    ---------------\n",
      "    Created no X tiles in directory: data/data/validation/.\n",
      "    Created no Y tiles in directory: data/data/validation/gt/.\n",
      "    \n",
      "    Test set:\n",
      "    ---------\n",
      "    Created no X tiles in directory data/data/testing/.\n",
      "    Created no Y tiles in directory data/data/testing/gt/.\n"
     ]
    }
   ],
   "source": [
    "if clean_start:\n",
    "    #duplicate = [class_colors[label] for label in [2, 3, 6, 9, 11]]\n",
    "    def get_color(name: str) -> list:\n",
    "        return class_colors[class_map[name]]\n",
    "\n",
    "    filter_dict = {\n",
    "        \"Ignore*\": (get_color(\"Ignore*\"), 0.9, 0.9, 1.0),\n",
    "    }\n",
    "\n",
    "    create_samples(osp.join(wsi_path), filter_dict, output_dir=\"../training\", tile_size=TILE_SIZE)\n",
    "\n",
    "patient_IDs = {osp.splitext(osp.basename(fname))[0].replace('train-', '') for fname in glob(osp.join(wsi_path, \"train-*.tif\"))}\n",
    "patient_patterns = [patient_ID + '*' for patient_ID in patient_IDs]\n",
    "    \n",
    "def file_counter(path: str) -> int:\n",
    "    if osp.exists(path):\n",
    "        return len([name for name in os.listdir(path) if os.path.isfile(osp.join(path, name))])\n",
    "    return \"no\"\n",
    "\n",
    "ds = {\n",
    "    'x':  osp.join(data_path, train_path),\n",
    "    'y':  osp.join(data_path, train_path, \"gt/\"),\n",
    "    'xv': osp.join(data_path, val_path),\n",
    "    'yv': osp.join(data_path, val_path, \"gt/\"),\n",
    "    'xt': osp.join(data_path, test_path),\n",
    "    'yt': osp.join(data_path, test_path, \"gt/\"),\n",
    "}\n",
    "\n",
    "print(\n",
    "    \"\"\"\n",
    "    Train set:\n",
    "    ---------\n",
    "    Created {} X tiles in directory: {}.\n",
    "    Created {} Y tiles in directory: {}.\n",
    "    \n",
    "    Validation set:\n",
    "    ---------------\n",
    "    Created {} X tiles in directory: {}.\n",
    "    Created {} Y tiles in directory: {}.\n",
    "    \n",
    "    Test set:\n",
    "    ---------\n",
    "    Created {} X tiles in directory {}.\n",
    "    Created {} Y tiles in directory {}.\"\"\".\n",
    "    format(\n",
    "        file_counter(ds['x']), ds['x'],\n",
    "        file_counter(ds['y']), ds['y'],\n",
    "        file_counter(ds['xv']), ds['xv'],\n",
    "        file_counter(ds['yv']), ds['yv'],\n",
    "        file_counter(ds['xt']), ds['xt'],\n",
    "        file_counter(ds['yt']), ds['yt'],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "main",
     "preamble",
     "main-no_create"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset\n",
      "-------\n",
      "Mean:    [210.52194532 196.59868844 201.91357681]\n",
      "St.dev.: [32.27907747 52.38655931 41.60488245]\n",
      "Min:     [0. 0. 0.]\n",
      "Max:     [255. 255. 255.]\n"
     ]
    }
   ],
   "source": [
    "if clean_start:\n",
    "    train_m, train_s, x_min, x_max = calculate_stats(path=\"data/WSI/\") #, local=False)\n",
    "    #TODO write to config\n",
    "else:\n",
    "    train_m = np.array(config['stats']['train_m'].get())\n",
    "    train_s = np.array(config['stats']['train_s'].get())\n",
    "    x_min = np.array(config['stats']['x_min'].get())\n",
    "    x_max = np.array(config['stats']['x_max'].get())\n",
    "\n",
    "print(f\"Dataset\\n-------\\nMean:    {train_m:}\\nSt.dev.: {train_s:}\")\n",
    "print(f\"Min:     {x_min}\\nMax:     {x_max}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug:\n",
    "    import imgaug as ia\n",
    "    from imgaug import augmenters as iaa\n",
    "    plt.rcParams['figure.figsize'] = (20.0, 16.0)\n",
    "    mytest = imread(\"./data/train/gt/X_1001.tif\")\n",
    "    warp = iaa.PiecewiseAffine(scale=0.05, nb_rows=6, nb_cols=6, mode='reflect')\n",
    "    trans = iaa.ElasticTransformation(alpha=80, sigma=(8.0), mode=\"reflect\")\n",
    "    warp_label = warp.augment_image(mytest)\n",
    "    twarp_label = trans.augment_image(warp_label)\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(mytest)\n",
    "    plt.title(\"label\")\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(warp_label)\n",
    "    plt.title(\"warp\")\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(twarp_label)\n",
    "    plt.title(\"warp+elastic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation for Segmentation\n",
    "This part will artificially increase the data set to improve the networks ability to generalize.\n",
    "Currently this is a very rudimentary procedure involving flips and 90 degree rotations. This can be changed in the future (See e.g. [ImgAug](https://github.com/aleju/imgaug))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## U-net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "main",
     "model_init",
     "main-no_create"
    ]
   },
   "outputs": [],
   "source": [
    "if compute_class_weights:\n",
    "    # Calculate the class weights for the training data set\n",
    "    # Optionally exclude a label by settings its weight to 0 using the ignore=label option\n",
    "    cls_wgts = calculate_class_weights(data_path, active_labels, class_colors, ignore=ignore_cls)\n",
    "    #TODO write to config\n",
    "    print(\"cls_wgts:\\n\", cls_wgts)\n",
    "    class_ratios = class_ratio(data_path, active_labels, class_colors)\n",
    "    print(\"class_ratios:\\n\", class_ratios)\n",
    "else:\n",
    "    # Replace with a read from config later\n",
    "    cls_wgts = {i: 1 if i != ignore_cls else 0 for i in active_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compute_class_weights:\n",
    "    from functools import partial\n",
    "    from mmciad.utils.custom_loss import w_categorical_crossentropy\n",
    "    cls_wgts = {0: 0.6462842253714038, 1: 4.277279367175925, 2: 0.7650382887989682, 3: 2.3366233721836207,\n",
    "                5: 0.38495865467512297, 6: 11.749891543465838, 7: 0.7357313031667244,\n",
    "                9: 3.3815931126719256, 10: 107.61779250337312, 11: 0.5449941506459005, 12: 0}\n",
    "    w_array = np.ones((num_cls,num_cls))\n",
    "    for cls_id, weight in enumerate(cls_wgts.values()):\n",
    "        w_array[cls_id, :] = weight # populate False negatives\n",
    "    w_array[:, -1] = 100.0 # Increase False Negative penalty for IGNORE class\n",
    "    np.fill_diagonal(w_array, 1) # Populate True positives\n",
    "    w_array[-1, :] = 0.0 # Remove False positives penalty for IGNORE class\n",
    "    #w_array_t = w_array.swapaxes(0, 1)\n",
    "    w_array[2,  7] = 70 # Guessing Epithelium as Dysplasia\n",
    "    w_array[2,  9] = 80 # Guessing Epithelium as Cancer\n",
    "    w_array[9,  2] = 100 # Guessing Cancer as Epithelium\n",
    "    w_array[7,  2] = 90 # Guessing Dysplasia as Epithelium\n",
    "    w_array[4,  6] = 2 # Guessing Stroma as Inflammation\n",
    "    w_array[4,  9] = 40 # Guessing Stroma as Cancer\n",
    "    w_array[6,  4] = 4 # Guessing Inflammation as Stroma\n",
    "    w_array[6,  9] = 30 # Guessing Inflammation as Cancer\n",
    "\n",
    "\n",
    "\n",
    "    r\"\"\"\n",
    "        Example weight matrix\n",
    "\n",
    "     -> False positives\n",
    "     v  False negatives\n",
    "     \\ True positives, always 1\n",
    "\n",
    "                    True class\n",
    "    P\n",
    "    r    ___|  A  |  B  |  C  |  D  |  E\n",
    "    e c   A |  1  | 3.0 | 0.5 | 1.7 | 0.3 \n",
    "    d l   B | 0.6 |  1  | 0.5 | 1.7 | 0.3\n",
    "    i a   C | 0.6 | 3.0 |  1  | 1.7 | 0.3\n",
    "    c s   D | 0.6 | 3.0 | 0.5 |  1  | 0.3\n",
    "    t s   E | 0.6 | 3.0 | 0.5 | 1.7 |  1\n",
    "    e\n",
    "    d\n",
    "    \"\"\"\n",
    "    with np.printoptions(precision=3, suppress=True, linewidth=100):\n",
    "        print(w_array)\n",
    "    w_ce = partial(w_categorical_crossentropy, weights=w_array)\n",
    "    w_ce.__name__ = 'weighted_categorical_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "main",
     "train",
     "model_init",
     "main-no_create"
    ]
   },
   "outputs": [],
   "source": [
    "if compute_class_weights:\n",
    "    w_TL = weighted_loss(tversky_loss, cls_wgts)\n",
    "    #w_cat_CE = weighted_loss(categorical_crossentropy, cls_wgts)\n",
    "    #w_cat_CE = get_weighted_categorical_crossentropy(weights=[v for v in cls_wgts.values()])\n",
    "    w_TL.__name__ = \"w_TL\"\n",
    "    #w_cat_CE.__name__ = \"w_cat_CE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "main",
     "train",
     "model_init",
     "main-no_create"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Already finished!: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from tf_mmciad.utils.hyper import prepare_for_talos\n",
    "\n",
    "# I/O Params\n",
    "\n",
    "IMG_ROWS, IMG_COLS, IMG_CHANNELS = (None, None, config['input_meta']['channels'].get())\n",
    "# architecture params\n",
    "NB_FILTERS_0 = config['nb_filters_0'].get()\n",
    "SIGMA_NOISE = 0.01\n",
    "\n",
    "# ****  deep learning model\n",
    "SHAPE = (IMG_ROWS, IMG_COLS, IMG_CHANNELS)\n",
    "BATCH_SIZE = config['batch_size'].get()\n",
    "NB_EPOCH = config['nb_epoch'].get()\n",
    "NB_FROZEN = config['nb_frozen'].get()\n",
    "VERBOSE = config['verbose'].get()\n",
    "\n",
    "# ****  train\n",
    "if not date_string:\n",
    "    date_string = str(datetime.date.today())\n",
    "\n",
    "if run_grid_search:\n",
    "    train_generator = DataGenerator(\n",
    "        train_path,\n",
    "        active_colors,\n",
    "        train_m,\n",
    "        train_s,\n",
    "        x_min,\n",
    "        x_max,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        dim=TILE_SIZE,\n",
    "        n_channels=config['input_meta']['channels'].get(),\n",
    "        n_classes=config['statics']['num_cls'].get(),\n",
    "        shuffle=True,\n",
    "        augment=True,\n",
    "    )\n",
    "\n",
    "    val_generator = DataGenerator(\n",
    "        val_path,\n",
    "        active_colors,\n",
    "        train_m,\n",
    "        train_s,\n",
    "        x_min,\n",
    "        x_max,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        dim=TILE_SIZE,\n",
    "        n_channels=config['input_meta']['channels'].get(),\n",
    "        n_classes=config['statics']['num_cls'].get(),\n",
    "        shuffle=True,\n",
    "        augment=False,\n",
    "    )\n",
    "\n",
    "#     statics = {\n",
    "#         \"shape\": SHAPE,\n",
    "#         \"nb_epoch\": 50,#NB_EPOCH,\n",
    "#         #\"nb_frozen\": NB_FROZEN,\n",
    "#         \"nb_filters_0\": NB_FILTERS_0,\n",
    "#         \"batch_size\": BATCH_SIZE,\n",
    "#         \"verbose\": VERBOSE,\n",
    "#         \"num_cls\": num_cls,\n",
    "#         \"batchnorm\": True,\n",
    "#         \"maxpool\": False,\n",
    "#         \"date\": date_string,\n",
    "#         #\"opt\": Adam,\n",
    "#         \"depth\": 4,\n",
    "#         #\"arch\": \"U-Net\",\n",
    "#         \"dropout\": 0,\n",
    "#         \"decay\": 0.0,\n",
    "#         \"sigma_noise\": 0,\n",
    "#         #\"act\": 'relu',\n",
    "#         \"pretrain\": 0,\n",
    "#         \"lr\": 1e-4,\n",
    "#         \"class_weights\": False,\n",
    "#         #\"loss_func\": \"cat_CE\",\n",
    "#         #\"init\": \"he_normal\",\n",
    "#     }\n",
    "    statics = config['statics'].get()\n",
    "    statics['date'] = date_string\n",
    "    p = config['grid_params'].get()\n",
    "    # fit params\n",
    "#     p = {\n",
    "#         #\"dropout\": [0],\n",
    "#         #\"decay\": [0.0],\n",
    "#         #\"lr\": [1e-3, 1e-4, 1e-5],\n",
    "#         #\"sigma_noise\": [0],\n",
    "#         \"nb_filters_0\": [12, 16, 32, 64],\n",
    "#         #\"pretrain\": [0, 2, 4],\n",
    "#         #\"class_weights\": [True, False],\n",
    "#         \"loss_func\": [\"cat_CE\", \"tversky_loss\", \"cat_FL\"],\n",
    "#         \"arch\": [\"U-Net\"],\n",
    "#         \"act\": [\"swish\", \"relu\"],\n",
    "#         \"opt\": [\"adam\",],\n",
    "#         \"init\": [\"he_normal\",]# \"glorot_uniform\"]\n",
    "#     }\n",
    "\n",
    "    talos_model = prepare_for_talos(model_storage, cls_wgts, statics, train_generator, val_generator, debug=debug)\n",
    "\n",
    "    dummy_x = np.empty((1, BATCH_SIZE, 384, 384))\n",
    "    dummy_y = np.empty((1, BATCH_SIZE))\n",
    "\n",
    "    scan_object = ta.Scan(\n",
    "        x=dummy_x,\n",
    "        y=dummy_y,\n",
    "        disable_progress_bar=False,\n",
    "        print_params=True,\n",
    "        model=talos_model,\n",
    "        params=p,\n",
    "        experiment_name=dpaths['grid'] + date_string,\n",
    "        #reduction_method='gamify',\n",
    "        allow_resume=True,\n",
    "    )\n",
    "\n",
    "    #print(model.summary(line_length=124))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_object = ta.Analyze(scan_object)\n",
    "#analyze_object.plot_corr('acc',['val_acc','acc','loss','val_loss', 'val_jaccard1_coef'], 10)\n",
    "#analyze_object.table('jaccard1_coef')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "main",
     "test"
    ]
   },
   "outputs": [],
   "source": [
    "from tempfile import mkstemp\n",
    "def sliding_window(image, stepSize, windowSize):\n",
    "    # slide a window across the image\n",
    "    for y in range(0, image.shape[1] - windowSize[0] + stepSize, stepSize):\n",
    "        for x in range(0, image.shape[0] - windowSize[1] + stepSize, stepSize):\n",
    "            # yield the current window\n",
    "            res_img = image[x : x + windowSize[0], y : y + windowSize[1]]\n",
    "            change = False\n",
    "            if res_img.shape[1] != windowSize[1]:\n",
    "                y = image.shape[1] - windowSize[1]\n",
    "                change = True\n",
    "            if res_img.shape[0] != windowSize[0]:\n",
    "                x = image.shape[0] - windowSize[0]\n",
    "                change = True\n",
    "            if change:\n",
    "                res_img = image[x : x + windowSize[0], y : y + windowSize[1]]\n",
    "            yield (x, y, x + windowSize[0], y + windowSize[1], res_img)\n",
    "\n",
    "\n",
    "def predict_window(model, img, step_size=1000, wsize=1024, num_class=11):\n",
    "    size = Size(img.shape[0], img.shape[1])\n",
    "    dtype = img.dtype\n",
    "    if (size.x > wsize) & (size.y > wsize):\n",
    "        output_img = np.memmap(mkstemp(dir=\"data/tmp/\")[1], dtype=dtype, mode=\"w+\", shape=(size.x, size.y, num_class))\n",
    "        #output_img = np.zeros(shape=(size.x, size.y, num_class))\n",
    "        output_img[:] = np.nan\n",
    "        x_total = (img.shape[0] - wsize + step_size) // step_size\n",
    "        y_total = (img.shape[1] - wsize + step_size) // step_size\n",
    "        pbar = tqdm.auto.tqdm(total=x_total*y_total)\n",
    "        for (x, y, dx, dy, I) in sliding_window(img, step_size, (wsize, wsize)):\n",
    "            window_prediction = model.predict(np.expand_dims(I, axis=0))\n",
    "            if output_img[x:dx, y:dy].shape != np.squeeze(window_prediction).shape:\n",
    "                print(f\"incoming tile shape ({np.squeeze(window_prediction).shape}) is different from existing shape ({output_img[x:dx, y:dy].shape})\")\n",
    "            output_img[x:dx, y:dy] = np.nanmean(\n",
    "                np.stack((output_img[x:dx, y:dy], np.squeeze(window_prediction)), axis=0), axis=0\n",
    "            ).astype(dtype)\n",
    "            pbar.update(1)\n",
    "        pbar.close()\n",
    "        return output_img\n",
    "    output_img = model.predict(img)\n",
    "    return output_img\n",
    "\n",
    "def evaluate_window(model, slide, target, stepSize=1000, wsize=1024, batch_size=None, num_cls=11):\n",
    "    X, Y, _ = slide.shape\n",
    "    if (X > wsize) & (Y > wsize):\n",
    "        input_tiles = []\n",
    "        target_tiles = []\n",
    "        for (x, y, dx, dy, I) in sliding_window(slide, wsize, (wsize, wsize)):\n",
    "            input_tiles.append(I)\n",
    "            target_tiles.append(target[x:dx,y:dy])\n",
    "        input_tiles = np.asarray(input_tiles)\n",
    "        target_tiles = np.asarray(target_tiles)\n",
    "        if batch_size is None:\n",
    "            batch_size = input_tiles.shape[0]\n",
    "        print(target_tiles.shape)\n",
    "        return model.evaluate(x=input_tiles, y=target_tiles, batch_size=batch_size)\n",
    "    else:\n",
    "        return model.evaluate(x=slide, y=target, batch_size=1)\n",
    "\n",
    "\n",
    "def concat_windows(slides, targets, stepSize=1000, wsize=1024):\n",
    "    input_tiles = []\n",
    "    target_tiles = []\n",
    "    for slide, target in zip(slides, targets):\n",
    "        X, Y, _ = slide.shape\n",
    "        if (X > wsize) & (Y > wsize):\n",
    "            for (x, y, dx, dy, I) in sliding_window(slide, wsize, (wsize, wsize)):\n",
    "                input_tiles.append(I)\n",
    "                target_tiles.append(target[x:dx,y:dy])\n",
    "    input_tiles = np.asarray(input_tiles)\n",
    "    target_tiles = np.asarray(target_tiles)\n",
    "    return input_tiles, target_tiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c6ab22e74c484392e641711564d197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2 29.72s\n",
      "3 53.03s\n",
      "4 166.99s, total time: 0:04:09.738520\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad822cf373fc403392a133bc8b2491e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=48.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5075235a97a48469a7e59f78cbd4e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "6 52.42s\n",
      "7 1.48s\n",
      "8 3.39s\n",
      "9 5.70s\n",
      "10 4.22s, total time: 0:01:07.216260\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "043d97a3b8c04fd08bfe9dbf4bbd7046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=48.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from mmciad.utils.preprocessing import merge_labels\n",
    "test_slides, test_targets = load_slides_as_dict(\"data/WSI/\", \"*3295 5V\", train_m, train_s, 255, \"gt\", num_cls, colorvec)\n",
    "#raw_test_slides = load_slides_as_dict(\"data/WSI/\", \"*3295 5V\")\n",
    "#remap_pattern = {0: [0, ], 1: [2, 3, 5], 2: [7, 8, 9], 3: [10, 1, 4, 6]}\n",
    "#bin_class = len(remap_pattern)\n",
    "#binary_test_targets = {name: to_categorical(merge_labels(np.argmax(img, axis=-1), remap_pattern)) for name, img in test_targets.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['3295 5V AAA WEIGERT - 2020-02-27 17.20.54'])\n",
      "(41216, 51200, 4)\n"
     ]
    }
   ],
   "source": [
    "#print(test_slides[\"N9a-1\"].min(), test_slides[\"N9a-1\"].max())\n",
    "#print(170775/test_slides[\"N10a\"].shape[1])\n",
    "print(test_targets.keys())\n",
    "print(test_targets[[i for i in test_targets.keys()][0]].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_contrast_min_and_max(img):\n",
    "    AUTO_THRESHOLD = 5000\n",
    "    pixcount = img.size\n",
    "    limit = pixcount/10\n",
    "    threshold = pixcount/AUTO_THRESHOLD\n",
    "    n_bins = 256\n",
    "    values, histogram = np.histogram(img, n_bins)\n",
    "    i = 0 # start at zero rather than -1 to avoid accounting for empty patches\n",
    "    found = False\n",
    "    count = 0\n",
    "    while True:\n",
    "        i += 1\n",
    "        count = values[i]\n",
    "        if count>limit:\n",
    "            count = 0\n",
    "        found = count> threshold\n",
    "        if found or i>=255:\n",
    "            break\n",
    "    hmin = i\n",
    "    found = False\n",
    "    i = 256\n",
    "    while True:\n",
    "        i -= 1\n",
    "        count = values[i]\n",
    "        if count>limit:\n",
    "            count = 0\n",
    "        found = count> threshold\n",
    "        if found or i<1:\n",
    "            break\n",
    "    hmax = i\n",
    "    return hmin/256, hmax/256\n",
    "\n",
    "def thresholding_algo(y, lag, threshold, influence):\n",
    "    signals = np.zeros(len(y))\n",
    "    filteredY = np.array(y)\n",
    "    avgFilter = [0]*len(y)\n",
    "    stdFilter = [0]*len(y)\n",
    "    avgFilter[lag - 1] = np.mean(y[0:lag])\n",
    "    stdFilter[lag - 1] = np.std(y[0:lag])\n",
    "    for i in range(lag, len(y)):\n",
    "        if abs(y[i] - avgFilter[i-1]) > threshold * stdFilter [i-1]:\n",
    "            if y[i] > avgFilter[i-1]:\n",
    "                signals[i] = 1\n",
    "            else:\n",
    "                signals[i] = -1\n",
    "\n",
    "            filteredY[i] = influence * y[i] + (1 - influence) * filteredY[i-1]\n",
    "            avgFilter[i] = np.mean(filteredY[(i-lag+1):i+1])\n",
    "            stdFilter[i] = np.std(filteredY[(i-lag+1):i+1])\n",
    "        else:\n",
    "            signals[i] = 0\n",
    "            filteredY[i] = y[i]\n",
    "            avgFilter[i] = np.mean(filteredY[(i-lag+1):i+1])\n",
    "            stdFilter[i] = np.std(filteredY[(i-lag+1):i+1])\n",
    "\n",
    "    return dict(signals = np.asarray(signals),\n",
    "                avgFilter = np.asarray(avgFilter),\n",
    "                stdFilter = np.asarray(stdFilter))\n",
    "\n",
    "lag = 10\n",
    "threshold = 2\n",
    "influence = 0\n",
    "\n",
    "def auto_contrast(img, order=['b','r','g']):\n",
    "    from skimage import exposure\n",
    "    from scipy import stats\n",
    "    output_img = np.zeros_like(np.squeeze(img))\n",
    "    CHANNEL_INDEX = {'r': 0, 'g': 1, 'b': 2}\n",
    "    ch = ['red','green','blue']\n",
    "    for i, c in enumerate([CHANNEL_INDEX[channel] for channel in order]):\n",
    "        v_min, v_max = find_contrast_min_and_max(img[..., i])\n",
    "        hist, bins_ = np.histogram(img[..., i], bins=256)\n",
    "        t = thresholding_algo(hist, lag, threshold, influence)\n",
    "        v_min = t[\"signals\"].argmax()/256\n",
    "        #midpoint = v_max - v_min\n",
    "        #v_min = midpoint - 30/256.\n",
    "        #print(ch[c], \"(c: {})\".format(c), order[i], \"(i: {})\".format(i))\n",
    "        #print(\"before:\",v_min, v_max)\n",
    "        if c == 0:\n",
    "            v_min = (t[\"signals\"].argmax()+1)/256\n",
    "            #v_max = np.percentile(img[..., i], (95.0))\n",
    "        elif c == 1:\n",
    "            v_min = t[\"signals\"].argmax()/256\n",
    "        elif c == 2:\n",
    "            v_min = (t[\"signals\"].argmax())/256\n",
    "            #print(t[\"signals\"])\n",
    "            #v_min *= 1.3\n",
    "            #v_min = max(v_min, np.percentile(img[..., i], (40.0)))\n",
    "            #v_max = np.percentile(img[..., i], (98.0))\n",
    "        #print(\"after:\",v_min, v_max)\n",
    "        output_img[..., c] = exposure.rescale_intensity(img[..., i], in_range=(v_min, v_max))\n",
    "    return output_img\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da4657f89fcf421f9dc79d8d6462e591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=17082.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95d0d9e358894bffbead153e10b62288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=413.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "from collections import namedtuple\n",
    "\n",
    "Size = namedtuple(\"Size\", [\"x\", \"y\"])\n",
    "weight_path = \"./models/\"\n",
    "results_path = \"./results/\"\n",
    "train_date = \"2020-05-15\"\n",
    "models = sorted(glob(osp.join(model_storage, train_date, \"*.h5\")), key=str.lower)\n",
    "cat_fl = categorical_focal_loss()\n",
    "custom_objects={\n",
    "    'Swish': Swish,\n",
    "    'cat_CE': categorical_crossentropy,\n",
    "    'tversky_loss': tversky_loss,\n",
    "    'categorical_focal_loss_fixed': cat_fl,\n",
    "    'jaccard1_coef': jaccard1_coef,\n",
    "}\n",
    "\n",
    "for modelpath in models:\n",
    "    base_name = osp.basename(modelpath)\n",
    "    for name, target in test_targets.items():\n",
    "        slide = test_slides[name][..., :3]\n",
    "        target = target[..., :3]\n",
    "        #with tf.device('/cpu:*'): # Remember to re-indent model + compile below\n",
    "        test_model = load_model(modelpath, custom_objects=custom_objects)\n",
    "        output = predict_window(test_model, slide, step_size=350, wsize=384, num_class=num_cls)\n",
    "        prediction = np.memmap(mkstemp(dir=\"data/tmp/\")[1], dtype='uint8', shape=(*output.shape[:2], 3), mode='w+')\n",
    "        row_step = 100\n",
    "        for rows in tqdm.auto.tqdm(range(0,output.shape[0], row_step)):\n",
    "            temp_array = colorvec[np.argmax(output[rows:rows+row_step], axis=-1)]\n",
    "            prediction[rows:rows+row_step] = temp_array\n",
    "            prediction.flush()\n",
    "        res_path = osp.join(\n",
    "            results_path,\n",
    "            train_date,\n",
    "            name\n",
    "        )\n",
    "        if not osp.exists(res_path):\n",
    "            os.makedirs(res_path)\n",
    "        %timeit -n1 -r1 write_png(osp.join(res_path, base_name.replace(\".h5\",\"_result_argmax.png\")), prediction.astype(np.uint8), use_palette=True)\n",
    "        os.unlink(output.filename)\n",
    "        os.unlink(prediction.filename)\n",
    "        del output, prediction, test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ta.Deploy(t,\"U-nets\", metric=\"acc\")\n",
    "#t.best_model(metric=\"acc\")\n",
    "from keras.models import model_from_json\n",
    "custom_layers = {'Swish': Swish, 'RAdam': RAdam}\n",
    "best_model = model_from_json(t.saved_models[7], custom_layers)\n",
    "best_model.set_weights(t.saved_weights[7])\n",
    "best_model.save(\"best_model.h5\")\n",
    "best_model.summary(line_length=127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "main",
     "train"
    ]
   },
   "outputs": [],
   "source": [
    "# I/O Params\n",
    "weight_path = \"./weights/\"\n",
    "\n",
    "IMG_ROWS, IMG_COLS, IMG_CHANNELS = (*TILE_SIZE, 3)\n",
    "#IMG_ROWS, IMG_COLS, IMG_CHANNELS = (None, None, 3)\n",
    "# architecture params\n",
    "NB_FILTERS_0 = 32\n",
    "SIGMA_NOISE = 0.01\n",
    "\n",
    "# ****  deep learning model\n",
    "SHAPE = (IMG_ROWS, IMG_COLS, IMG_CHANNELS)\n",
    "BATCH_SIZE = 16\n",
    "NB_EPOCH = 200\n",
    "NB_FROZEN = 40\n",
    "VERBOSE = 0\n",
    "# fit params\n",
    "if not date_string:\n",
    "    date_string = str(datetime.date.today())\n",
    "DROP = 0\n",
    "\n",
    "OPT_NAME = \"adam\"  # choices:adadelta; sgd, rmsprop, adagrad, adam\n",
    "if OPT_NAME == \"sgd\":\n",
    "    OPT = SGD(lr=0.1)\n",
    "elif OPT_NAME == \"rmsprop\":\n",
    "    OPT = RMSprop()\n",
    "elif OPT_NAME == \"adagrad\":\n",
    "    OPT = Adagrad()\n",
    "elif OPT_NAME == \"adadelta\":\n",
    "    OPT = Adadelta()\n",
    "elif OPT_NAME == \"adam\":\n",
    "    OPT = Adam(lr=1e-3, decay=0.0)\n",
    "elif OPT_NAME == \"amsgrad\":\n",
    "    OPT = Adam(lr=1e-4, amsgrad=True)\n",
    "elif OPT_NAME == \"adamax\":\n",
    "    OPT = Adamax()\n",
    "elif OPT_NAME == \"nadam\":\n",
    "    OPT = Nadam()\n",
    "else:\n",
    "    raise NameError(\"Wrong optimizer name\")\n",
    "\n",
    "def moveFilesinDir(src_dir: str, dst_dir: str, pattern=None) -> None:\n",
    "    # Check if both the are directories\n",
    "    if os.path.isdir(src_dir) and os.path.isdir(dst_dir) :\n",
    "        # Iterate over all the files in source directory\n",
    "        if pattern is None:\n",
    "            files = glob(src_dir + '*')\n",
    "            with tqdm(total=len(files)) as pbar:\n",
    "                for file_path in files:\n",
    "                    # Move each file to destination Directory\n",
    "                    shutil.move(file_path, dst_dir)\n",
    "                    pbar.update(1)\n",
    "        if isinstance(pattern, str):\n",
    "            files = glob(src_dir + pattern)\n",
    "            with tqdm(total=len(files)) as pbar:\n",
    "                for file_path in files:\n",
    "                    # Move each file to destination Directory\n",
    "                    shutil.move(file_path, dst_dir)\n",
    "                    pbar.update(1)\n",
    "        if isinstance(pattern, list):\n",
    "            with tqdm(total=len(pattern)) as pbar:\n",
    "                for group in pattern:\n",
    "                    files = glob(src_dir + group)\n",
    "                    with tqdm(total=len(files)) as inner_pbar:\n",
    "                        for file_path in files:\n",
    "                            # Move each file to destination Directory\n",
    "                            shutil.move(file_path, dst_dir)\n",
    "                            inner_pbar.update(1)\n",
    "                    pbar.update(1)\n",
    "    else:\n",
    "        print(\"src_dir & dst_dir should be directories\")\n",
    "\n",
    "#patient_patterns = [name.replace('train-','') for name in patient_patterns]\n",
    "if clean_start:\n",
    "    print(patient_patterns[-3:])\n",
    "    moveFilesinDir(osp.join(data_path, train_path, ''), osp.join(data_path, val_path, ''), patient_patterns[-3:])\n",
    "    moveFilesinDir(osp.join(data_path, train_path, 'gt', ''), osp.join(data_path, val_path, 'gt', ''), patient_patterns[-3:])\n",
    "#moveFilesinDir(osp.join(data_path, val_path, ''), osp.join(data_path, train_path, ''), patient_patterns[-1])\n",
    "#moveFilesinDir(osp.join(data_path, val_path, 'gt', ''), osp.join(data_path, train_path, 'gt', ''), patient_patterns[-1])\n",
    "if run_train:\n",
    "    train_generator = DataGenerator(\n",
    "        osp.join(data_path, train_path),\n",
    "        active_colors,\n",
    "        train_m,\n",
    "        train_s,\n",
    "        x_min,\n",
    "        x_max,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        dim=TILE_SIZE,\n",
    "        n_channels=3,\n",
    "        n_classes=num_cls,\n",
    "        shuffle=True,\n",
    "        augment=True,\n",
    "    )\n",
    "\n",
    "    val_generator = DataGenerator(\n",
    "        osp.join(data_path, val_path),\n",
    "        active_colors,\n",
    "        train_m,\n",
    "        train_s,\n",
    "        x_min,\n",
    "        x_max,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        dim=TILE_SIZE,\n",
    "        n_channels=3,\n",
    "        n_classes=num_cls,\n",
    "        shuffle=True,\n",
    "        augment=False,\n",
    "    )\n",
    "\n",
    "    # test_generator = DataGenerator(\n",
    "    #     osp.join(data_path, test_path),\n",
    "    #     colorvec,\n",
    "    #     train_m,\n",
    "    #     train_s,\n",
    "    #     x_min,\n",
    "    #     x_max,\n",
    "    #     batch_size=BATCH_SIZE,\n",
    "    #     dim=(208, 208),\n",
    "    #     n_channels=3,\n",
    "    #     n_classes=num_cls,\n",
    "    #     shuffle=True,\n",
    "    #     augmenter=True,\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "main",
     "train"
    ]
   },
   "outputs": [],
   "source": [
    "if run_train: \n",
    "    model_kwargs = {\n",
    "        \"nb_filters\": NB_FILTERS_0,\n",
    "        \"sigma_noise\": SIGMA_NOISE,\n",
    "        \"depth\": 4,\n",
    "        \"maxpool\": False,\n",
    "        \"initialization\": \"he_normal\",\n",
    "        \"activation\": Swish,\n",
    "        \"dropout\": 0,\n",
    "        \"output_channels\": num_cls,\n",
    "        \"batchnorm\": True,\n",
    "        \"arch\": \"U-Net\",\n",
    "    }\n",
    "    cat_fl = categorical_focal_loss()\n",
    "    loss_func = cat_fl\n",
    "    model_base_path = osp.join(model_storage, date_string)\n",
    "    #pretrain_model = osp.join(weight_path,\"2019-09-20\",\"pretrain_U-net_model.h5\")\n",
    "    path_elements = [\n",
    "        '{}_{}'.format(key, val.__name__)\n",
    "        if hasattr(val, '__name__')\n",
    "        else '{}_{}'.format(key, val) for key, val in model_kwargs.items()\n",
    "    ]\n",
    "    path_elements.remove('{}_{}'.format(\"arch\", model_kwargs[\"arch\"]))\n",
    "\n",
    "    if not os.path.exists(model_base_path):\n",
    "        os.makedirs(model_base_path, exist_ok=True)\n",
    "\n",
    "    basename = \"model\"\n",
    "\n",
    "    suffix = datetime.datetime.now().strftime(\"%y-%m-%d_%H%M%S\")\n",
    "    model_handle = \"_\".join([basename, suffix])  # e.g. 'mylogfile_120508_171442'\n",
    "    modelpath = osp.join(model_base_path, model_handle)\n",
    "\n",
    "    log_path = osp.join(\"./logs/\", date_string, model_handle, '')\n",
    "\n",
    "    if os.path.exists(modelpath):\n",
    "        custom_objects = {\n",
    "            'Swish': Swish,\n",
    "        }\n",
    "        model = load_model(modelpath, custom_objects=custom_objects)\n",
    "    else:\n",
    "        model = u_net(SHAPE, **model_kwargs)\n",
    "    #model = load_model(pretrain_model, custom_objects={'Swish': Swish})\n",
    "    #from keras.models import Model\n",
    "    #from keras.layers import Conv2D\n",
    "    #model_inputs = model.inputs\n",
    "    #model_preout = model.layers[-2].output\n",
    "    #new_output = Conv2D(num_cls, 1, activation=\"softmax\", name=\"conv_out\")(model_preout)\n",
    "    #model = Model(inputs=model.inputs, outputs=new_output)\n",
    "    #pretrain_layers = [\n",
    "    #    \"block{}_d_conv{}\".format(block, layer)\n",
    "    #    for block in range(1, 4 + 1)\n",
    "    #    for layer in range(1, 3)\n",
    "    #]\n",
    "    #for i, n in enumerate(pretrain_layers):\n",
    "    #    model.get_layer(name=n).trainable = False\n",
    "    print(log_path)\n",
    "    print(model.summary(line_length=124))\n",
    "    model.compile(loss=loss_func, optimizer=Adam(lr=1e-3, decay=0.0), metrics=[\"accuracy\", jaccard1_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true,
    "tags": [
     "main",
     "train"
    ]
   },
   "outputs": [],
   "source": [
    "from pdb import set_trace\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from tf_mmciad.utils.callbacks import PatchedModelCheckpoint, ValidationHook\n",
    "from tf_mmciad.utils.tb_info import ModelDiagnoser\n",
    "from tensorflow import data\n",
    "\n",
    "class MemoryCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.current_mem_usage = 1\n",
    "        self.prev_mem_usage = 1\n",
    "        \n",
    "    def on_epoch_end(self, epoch, log={}):\n",
    "        self.prev_mem_usage = self.current_mem_usage\n",
    "        self.current_mem_usage = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss * 1000 # func returns kilobytes\n",
    "        increase = (self.current_mem_usage / self.prev_mem_usage) * 100\n",
    "        if epoch == 0:\n",
    "            print(f\"Total memory usage: {self.convert_bytes(self.current_mem_usage)}\")\n",
    "        else:\n",
    "            print(f\"Total memory usage: {self.convert_bytes(self.current_mem_usage)} ({increase-100} % increase)\")\n",
    "        \n",
    "    def convert_bytes(self, num):\n",
    "        \"\"\"\n",
    "        this function will convert bytes to MB.... GB... etc\n",
    "        \"\"\"\n",
    "        step_unit = 1024.0 #1024 bad the size\n",
    "\n",
    "        for x in ['bytes', 'KiB', 'MiB', 'GiB', 'TiB']:\n",
    "            if num < step_unit:\n",
    "                return \"%3.1f %s\" % (num, x)\n",
    "            num /= step_unit\n",
    "\n",
    "def get_string(name_or_str):\n",
    "    if hasattr(name_or_str, \"__name__\"):\n",
    "        output = name_or_str.__name__\n",
    "    elif isinstance(name_or_str, str):\n",
    "        output = name_or_str\n",
    "    else:\n",
    "        output = str(name_or_str)\n",
    "    return output\n",
    "\n",
    "if run_train:\n",
    "    with open(file=modelpath + \".cfg\", mode=\"w\") as f:\n",
    "        f.write(\"#\" * 62 + \"\\n#\" + \" \" * 60 + \"#\\n\")\n",
    "        f.write(\"#\" + f\"Model Paramters for {model_handle}_*.h5\".center(60) + \"#\\n\")\n",
    "        f.write(\"#\" + \" \" * 60 + \"#\\n\" + \"#\" * 62 + \"\\n\\n\")\n",
    "        f.write(\"Parameters:\\n\")\n",
    "        for key, val in model_kwargs.items():\n",
    "            f.write(f\"  {key} = {get_string(val)}\\n\")\n",
    "    #            f.write(\"\\nTalos Parameters:\\n\")\n",
    "    #            for key, val in talos_params.items():\n",
    "    #                f.write(f\"  {key} = {get_string(val)}\\n\")\n",
    "        f.write(\n",
    "            f\"\\nTraining started: {datetime.datetime.now().strftime('%d-%m-%Y %H:%M:%S.%f')}\\n\"\n",
    "        )\n",
    "\n",
    "    #class_weights = [1 if k != 12 else 0 for k in active_labels]\n",
    "    tqdm_callback = tfa.callbacks.TQDMProgressBar()\n",
    "\n",
    "    val_hook = ValidationHook(val_generator)\n",
    "\n",
    "    mem_cb = MemoryCallback()\n",
    "\n",
    "    tensor_board = TensorBoard(\n",
    "        log_dir=log_path,\n",
    "        histogram_freq=0,\n",
    "        write_graph=False,\n",
    "        write_images=False,\n",
    "        profile_batch=2,\n",
    "        update_freq=\"epoch\"\n",
    "    )\n",
    "    early_stopper = EarlyStopping(monitor=\"loss\", patience=40, verbose=1, mode=\"auto\")\n",
    "    reducer = ReduceLROnPlateau(\n",
    "        monitor=\"loss\",\n",
    "        factor=0.1,\n",
    "        patience=10,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    jaccard_model_checkpoint = PatchedModelCheckpoint(\n",
    "        modelpath + \"_epoch_{epoch}_val_jacc1_{val_jaccard1_coef:0.4f}.h5\",\n",
    "        verbose=0,\n",
    "        monitor=\"val_jaccard1_coef\",\n",
    "        save_best_only=True,\n",
    "    )\n",
    "    loss_model_checkpoint = PatchedModelCheckpoint(\n",
    "        modelpath + \"_epoch_{epoch}_val_loss_{val_loss:0.4f}.h5\",\n",
    "        verbose=0,\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "    )\n",
    "\n",
    "    csv_log = CSVLogger(filename=modelpath + '.fit.csv', append=True)\n",
    "\n",
    "    diagnoser = ModelDiagnoser(train_generator, BATCH_SIZE, 2, log_path, active_colors, train_m, train_s)\n",
    "\n",
    "    model_callbacks = [tqdm_callback, mem_cb, tensor_board, early_stopper, reducer, jaccard_model_checkpoint, loss_model_checkpoint, csv_log] # diagnoser\n",
    "\n",
    "    history = model.fit(\n",
    "        x=train_generator,\n",
    "        epochs=200,\n",
    "        steps_per_epoch=len(train_generator),\n",
    "    #   initial_epoch=50,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=len(val_generator),\n",
    "    #   use_multiprocessing=True,\n",
    "        workers=20,\n",
    "    #   class_weight=class_weights,\n",
    "        verbose=VERBOSE,\n",
    "        callbacks=model_callbacks,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "  \n",
    "     \n",
    "         \n",
    "            # def gen_enqueuer(generator):\n",
    "#     def my_enqueuer():\n",
    "#         enq = tf.keras.utils.OrderedEnqueuer(generator)\n",
    "#         enq.start(workers=40, max_queue_size=40)\n",
    "#         while True:\n",
    "#             batch_xs, batch_ys = next(enq.get())\n",
    "#             yield batch_xs, batch_ys\n",
    "#     return my_enqueuer\n",
    "\n",
    "# train_enqueuer = gen_enqueuer(train_generator)\n",
    "# val_enqueuer = gen_enqueuer(val_generator)\n",
    "# train_data = data.Dataset.from_generator(train_enqueuer,\n",
    "#                                          (tf.float64, tf.int64),\n",
    "#                                          (tf.TensorShape([ SHAPE[0], SHAPE[1], SHAPE[2]]),\n",
    "#                                           tf.TensorShape([ SHAPE[0], SHAPE[1], num_cls])\n",
    "#                                          )\n",
    "#                                         )\n",
    "# val_data = data.Dataset.from_generator(val_enqueuer,\n",
    "#                                          (tf.float64, tf.int64),\n",
    "#                                          (tf.TensorShape([ SHAPE[0], SHAPE[1], SHAPE[2]]),\n",
    "#                                           tf.TensorShape([ SHAPE[0], SHAPE[1], num_cls])\n",
    "#                                          )\n",
    "#                                         )\n",
    "\n",
    "#trainer = train_data.batch(batch_size=BATCH_SIZE, drop_remainder=True)\n",
    "#validator = val_data.batch(batch_size=BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "# history = model.fit(\n",
    "#     x=trainer.data,\n",
    "#     epochs=NB_EPOCH,\n",
    "#     validation_data=validator.data,\n",
    "#     workers=30,\n",
    "#     verbose=VERBOSE,\n",
    "#     callbacks=model_callbacks,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "main"
    ]
   },
   "outputs": [],
   "source": [
    "# **** #####################################\"\n",
    "min_loss = np.argmin(history.history['loss'])\n",
    "epoch_init = 0+1\n",
    "print(\"Best loss: %.5f\" % (np.min(history.history['loss'])))\n",
    "print(\"at: %d\" % (epoch_init+np.argmin(history.history['loss'])))\n",
    "print(f\"accuracy at {epoch_init+min_loss}:            {history.history['accuracy'][min_loss]:.5f}\")\n",
    "print(f\"validation accuracy at {epoch_init+min_loss}: {history.history['val_accuracy'][min_loss]:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "main"
    ]
   },
   "outputs": [],
   "source": [
    "# Find max accuracy of all models\n",
    "best = {key: np.max(m.history[\"categorical_accuracy\"]) for key, m in histories.items()}\n",
    "print(best)\n",
    "print(\n",
    "    \"Highest validation accuracy:\\n{}, score: {}\".format(\n",
    "        max(best, key=lambda key: best[key]), max(best.values())\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "main",
     "visuals"
    ]
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(2, 2, figsize=(10, 10))\n",
    "i_s = [0, 0, 1, 1]\n",
    "j_s = [0, 1, 0, 1]\n",
    "lf = [\n",
    "    \"categorical_crossentropy\",\n",
    "    \"weighted_categorical_crossentropy\",\n",
    "    \"tversky_loss\",\n",
    "    \"weighted_tversky_loss\",\n",
    "]\n",
    "for i, j, m, title in zip(i_s, j_s, histories.values(), lf):\n",
    "    loss = ax1[i, j].plot(m.epoch, m.history['loss'], label='loss')\n",
    "    val_loss = ax1[i, j].plot(m.epoch, m.history['val_loss'], label='validation loss')\n",
    "    ax1[i, j].set_title(title)\n",
    "    if not j:\n",
    "        ax1[i, j].set_ylabel('loss')\n",
    "    if i:\n",
    "        ax1[i, j].set_xlabel('epoch')\n",
    "    ax2 = ax1[i, j].twinx()\n",
    "    if j:\n",
    "        ax2.set_ylabel('Accuracy')\n",
    "    acc = ax2.plot(m.epoch, m.history['categorical_accuracy'], '-m', label='accuracy')\n",
    "    val_acc = ax2.plot(m.epoch, m.history['val_categorical_accuracy'], '-g', label='validation accuracy')\n",
    "    ax1[i, j].set_ylim(0.0, max([max(m.history['loss']), max(m.history['val_loss'])]))\n",
    "    ax2.set_ylim(0.0, 1.0)\n",
    "handles, labels = ax1[0, 0].get_legend_handles_labels()\n",
    "handles2, labels2 = ax2.get_legend_handles_labels()\n",
    "fig.legend(handles=handles+handles2,\n",
    "           bbox_to_anchor=(0., 0.02, 1., .1), # x, y, width, height\n",
    "           loc='lower left',\n",
    "           ncol=4, mode=\"expand\")\n",
    "#fig.tight_layout()\n",
    "fig.suptitle('Training performance')\n",
    "plt.show()\n",
    "fig.savefig(osp.join(\".\",\"results\",\"training performance.svg\"), dpi=300,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def compare_results(img):\n",
    "    if type(img) is list:\n",
    "        cols = len(img)\n",
    "        for pos, img in zip(range(1, cols * 3, 3), img):\n",
    "            plt.subplot(cols, 3, pos)\n",
    "            plt.imshow(X_test[img, :, :, :] * train_s + train_m)\n",
    "            if pos <= 3:\n",
    "                plt.title(\"Training image\")\n",
    "            plt.subplot(cols, 3, pos + 1)\n",
    "            plt.imshow(colorvec[np.argmax(Y_test[img, :, :, :], axis=-1)])\n",
    "            if pos <= 3:\n",
    "                plt.title(\"Image label\")\n",
    "            plt.subplot(cols, 3, pos + 2)\n",
    "            plt.imshow(colorvec[np.argmax(Y_pred[img, :, :, :], axis=-1)])\n",
    "            if pos <= 3:\n",
    "                plt.title(\"Label prediction\")\n",
    "            pred_list = np.unique(np.argmax(Y_pred[img, :, :, :], axis=-1))\n",
    "            test_list = np.unique(np.argmax(Y_test[img, :, :, :], axis=-1))\n",
    "            print(\"{:^44s}\".format(\"Image \" + str(img)))\n",
    "            print(\n",
    "                \"{:<3s}{:<18s}{:<3s}{:<18s}\".format(\n",
    "                    \"\", \"Actual labels\", \"\", \"Predicted labels:\"\n",
    "                )\n",
    "            )\n",
    "            print(\"-\" * 44)\n",
    "            for i in active_labels:\n",
    "                a = \"\"\n",
    "                p = \"\"\n",
    "                j = \"\"\n",
    "                k = \"\"\n",
    "                if i in test_list:\n",
    "                    j = str(i)\n",
    "                    a = active_classes[i]\n",
    "                if i in pred_list:\n",
    "                    k = str(i)\n",
    "                    p = active_classes[i]\n",
    "                if not a == p == j == k:\n",
    "                    print(\"{:<3s}{:<18s}{:<3s}{:<18s}\".format(j, a, k, p))\n",
    "    else:\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(X_test[img, :, :, :] * train_s + train_m)\n",
    "        plt.title(\"Training image\")\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(colorvec[np.argmax(Y_test[img, :, :, :], axis=-1)])\n",
    "        plt.title(\"Image label\")\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(colorvec[np.argmax(Y_pred[img, :, :, :], axis=-1)])\n",
    "        plt.title(\"Label prediction\")\n",
    "\n",
    "\n",
    "# compare_results([1,4,7,28])\n",
    "for i in range(Y_pred.shape[0]):\n",
    "    compare_results(i)\n",
    "    plt.savefig(\"./figures/test_prediction_tile{}.png\".format(i), format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Quantitative evaluation\n",
    "from dlia_tools.eval import jaccard\n",
    "Y_test_pred = model.predict(X_test)\n",
    "#Y_train_pred = model.predict(X_train)\n",
    "Y_val_pred = model.predict(X_val)\n",
    "\n",
    "#print(\"Jaccard on training set:\", jaccard(Y_train, Y_train_pred))\n",
    "print(\"Jaccard on validation set:\", jaccard(Y_val, Y_val_pred))\n",
    "print(\"Jaccard on test set:\", jaccard(Y_test, Y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_weights(path+'batchnorm-weights.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist, bins_ = np.histogram(raw_test_slides[\"N4b\"][..., 1], bins=256)\n",
    "t = thresholding_algo(hist, lag, threshold, influence)\n",
    "hist\n",
    "t[\"signals\"].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import exposure\n",
    "from scipy import stats\n",
    "num_slides = len(raw_test_slides)\n",
    "plt.rcParams['figure.figsize'] = (20.0, 16.0)\n",
    "enhanced_slides = {}\n",
    "for n, (name, slide) in enumerate(raw_test_slides.items(), 1):\n",
    "    print(name)\n",
    "    #for i, c in enumerate([1,2,0]):\n",
    "        #zero = stats.percentileofscore(slide[..., c].ravel(), 0)\n",
    "        #mid = stats.percentileofscore(slide[..., c].ravel(), np.median(slide[..., c].ravel()))\n",
    "        #print(\"channel {}: {}\".format(i, zero))\n",
    "        #v_min, v_mid, v_max = np.percentile(slide, (zero+10, mid, 90.0))\n",
    "        #print(\"channel {}: min {} , mid {} , max {}\".format(i, v_min, v_mid, v_max))\n",
    "        #v_min, v_max = find_contrast_min_and_max(slide[..., c])\n",
    "        #print(\"channel {}: min {} , max {}\".format(i, v_min, v_max))\n",
    "        #enhanced_slides[name][..., i] = exposure.rescale_intensity(slide[..., c], in_range=(v_min, v_max))\n",
    "    enhanced_slides[name] = auto_contrast(slide)\n",
    "    plt.subplot(1, num_slides, n)\n",
    "    plt.imshow(enhanced_slides[name])\n",
    "    plt.title(name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_slides = load_slides_as_dict(path, \"train\", train_m, train_s, False)\n",
    "train_slides.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_slides.pop('N10a')\n",
    "test_slides.pop('N4b')\n",
    "#test_slides.pop('N9a-1')\n",
    "test_slides.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = \"./weights/\"\n",
    "results_path = \"./results/\"\n",
    "train_date = \"2020-10-31\"\n",
    "weights = sorted(glob(osp.join(weight_path, train_date,\"*\",\"*\", \"*.h5\")), key=str.lower)\n",
    "\n",
    "#eval_kwargs = model_kwargs\n",
    "#eval_kwargs[\"activation\"] = Swish\n",
    "#eval_kwargs[\"output_channels\"] = num_cls\n",
    "#del model\n",
    "model = load_model(weights[0], custom_objects={'Swish': Swish,'categorical_focal_loss_fixed': categorical_focal_loss()})\n",
    "for name, target in binary_test_targets.items():\n",
    "    slide = np.squeeze(test_slides[name])\n",
    "    #with tf.device('/cpu:*'): # Remember to re-indent model + compile below\n",
    "    print(target.shape)\n",
    "    print(evaluate_window(model, slide, target, stepSize=190, wsize=208, batch_size=12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = \"./weights/\"\n",
    "results_path = \"./results/\"\n",
    "train_date = \"2019-10-17\"\n",
    "weights = sorted(glob(osp.join(weight_path, train_date,\"*\",\"*\", \"*.h5\")), key=str.lower)\n",
    "# architecture params\n",
    "NB_FILTERS_0 = 64\n",
    "SIGMA_NOISE = 0.01\n",
    "\n",
    "VERBOSE = 1\n",
    "model_kwargs = {\n",
    "    \"nb_filters\": NB_FILTERS_0,\n",
    "    \"sigma_noise\": SIGMA_NOISE,\n",
    "    \"depth\": 4,\n",
    "    \"maxpool\": False,\n",
    "    \"initialization\": \"he_normal\",\n",
    "    \"activation\": \"Swish\",\n",
    "    \"dropout\": 0,\n",
    "    \"batchnorm\": True,\n",
    "    \"arch\": \"U-Net\",\n",
    "}\n",
    "eval_kwargs = model_kwargs\n",
    "eval_kwargs[\"activation\"] = Swish\n",
    "eval_kwargs[\"output_channels\"] = num_cls\n",
    "slide_list = []\n",
    "target_list = []\n",
    "for name, target in test_targets.items():\n",
    "    slide_list.append(np.squeeze(test_slides[name]))\n",
    "    target_list.append(target)\n",
    "input_tiles, target_tiles = concat_windows(slide_list, target_list, stepSize=190, wsize=208)\n",
    "#with tf.device('/cpu:*'): # Remember to re-indent model + compile below\n",
    "#    eval_model = load_model(weights[0], custom_objects={'Swish': Swish})\n",
    "#    eval_model.compile(\n",
    "#        loss=categorical_crossentropy,\n",
    "#        optimizer=Adam(lr=0.001, decay=0),\n",
    "#        metrics=[\"acc\"],\n",
    "#    )\n",
    "#    print(target.shape)\n",
    "test_metrics = model.evaluate(x=input_tiles, y=target_tiles, batch_size=12)\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(globals().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-371c71db0a92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "os.unlink(output.filename)\n",
    "os.unlink(prediction.filename)\n",
    "del output, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def talos_predict_window(slide, model_id=None, stepSize=500, wsize=512):\n",
    "    X, Y, _ = slide.shape\n",
    "    if (X > wsize) & (Y > wsize):\n",
    "        output = np.ones(shape=(X, Y, num_cls))\n",
    "        for (x, y, dx, dy, I) in sliding_window(slide, wsize, (wsize, wsize)):\n",
    "            prediction = p.predict(np.expand_dims(I, axis=0), model_id)\n",
    "            output[x:dx, y:dy, :] = prediction\n",
    "        return output\n",
    "    else:\n",
    "        output = p.predict(np.expand_dims(slide, axis=0), model_id)\n",
    "        return output\n",
    "import pickle\n",
    "#with open(\"./weights/talos.pickle\", 'wb') as f:\n",
    "#    pickle.dump(t, f, -1)\n",
    "\n",
    "from keras.backend.tensorflow_backend import clear_session\n",
    "from keras.backend.tensorflow_backend import get_session\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_area_auto_adjustable\n",
    "\n",
    "try:\n",
    "    del t # this is from global space - change this as you need\n",
    "except:\n",
    "    pass\n",
    "\n",
    "#with open(\"./weights/talos.pickle\", 'rb') as f:\n",
    "#    t = pickle.load(f)\n",
    "def batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    counter = 0\n",
    "    for ndx in range(0, l, n):\n",
    "        counter += 1\n",
    "        yield counter, iterable[ndx:min(ndx + n, l)]\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (26.0, 38.0)\n",
    "weight_path = \"./weights/\"\n",
    "results_path = \"./results/\"\n",
    "train_date = \"2019-07-05\"\n",
    "weights = sorted(glob(osp.join(weight_path, train_date,\"cat_CE\", \"*.h5\")), key=str.lower)\n",
    "for count, b in batch(weights, 8):\n",
    "    \n",
    "    row_titles = []\n",
    "\n",
    "    pad = 5 # in points\n",
    "    #test_name = \"T4a\"\n",
    "    try:\n",
    "        for test_name, slide in test_slides.items():\n",
    "            sess = get_session()\n",
    "            clear_session()\n",
    "            sess.close()\n",
    "            sess = get_session()\n",
    "            \n",
    "            config = tf.ConfigProto()\n",
    "            config.gpu_options.allow_growth = True\n",
    "            K.tensorflow_backend.set_session(tf.Session(config=config))\n",
    "            #with tf.device('/cpu:*'): # Remember to re-indent model + compile below\n",
    "            model = u_net(\n",
    "                (None, None, 3),\n",
    "                64,\n",
    "                sigma_noise=0,\n",
    "                depth=4,\n",
    "                dropout=0,\n",
    "                output_channels=num_cls,\n",
    "                batchnorm=True,\n",
    "                pretrain=0,\n",
    "            )\n",
    "\n",
    "            model.compile(\n",
    "                loss=categorical_crossentropy,\n",
    "                optimizer=Adam(lr=0.001, decay=0),\n",
    "                metrics=[\"acc\"],\n",
    "            )\n",
    "\n",
    "            fig, axes = plt.subplots(\n",
    "                nrows=len(b),\n",
    "                ncols=num_cls+2,\n",
    "                sharex=True,\n",
    "                sharey=True,\n",
    "                figsize=(26, 1.5*len(b)),\n",
    "                gridspec_kw={'hspace': 0, 'wspace': 0}\n",
    "            )\n",
    "            for i, w in enumerate(b):\n",
    "                loss_dir = str(osp.split(w)[0]).split('/')[-1].split('-')[0]\n",
    "                base_name = osp.split(w)[-1]\n",
    "                class_wgt_dir = 'weights_{}'.format('True' in str(base_name))\n",
    "                act_dir = '{}'.format(base_name[base_name.rfind('act_'):base_name.find('-decay_')])\n",
    "                init_dir = '{}'.format(base_name[base_name.rfind('init_'):base_name.find('-act_')])\n",
    "                res_path = osp.join(\n",
    "                    results_path,\n",
    "                    train_date,\n",
    "                    test_name,\n",
    "                    loss_dir,\n",
    "                    ' '.join([class_wgt_dir, init_dir, act_dir])\n",
    "                )\n",
    "                row_titles.append(loss_dir + '\\n' + class_wgt_dir + '\\n' +  act_dir + '\\n' +  init_dir)\n",
    "                if not osp.exists(res_path):\n",
    "                    os.makedirs(res_path)\n",
    "                model.load_weights(w)\n",
    "                output = predict_window(slide)\n",
    "                for j in range(num_cls):\n",
    "                    axes[i, j].imshow(output[:,:,j], cmap=\"jet\")\n",
    "                    plt.imsave(res_path + \"/result-{}.png\".format(active_classes[j]), output[:,:,j], cmap=\"jet\")\n",
    "                axes[i, num_cls].imshow(colorvec[np.argmax(output, axis=-1)])\n",
    "                imsave(res_path + \"/result_argmax.png\", colorvec[np.argmax(output, axis=-1)].astype(np.uint8), check_contrast=False)\n",
    "                axes[i, num_cls+1].imshow(slide[...,[1,2,0]])\n",
    "\n",
    "            for ax, col in zip(axes[0], active_classes + [\"argmax\", \"input\"]):\n",
    "                ax.set_title(col)\n",
    "\n",
    "            for ax, row in zip(axes[:,0], row_titles):\n",
    "                ax.annotate(row, xy=(0, 0.5), xytext=(-ax.yaxis.labelpad - pad, 0),\n",
    "                xycoords=ax.yaxis.label, textcoords='offset points',\n",
    "                size='large', ha='right', va='center', wrap=True)\n",
    "            fig.tight_layout(pad=1.5)\n",
    "            fig.subplots_adjust(left=0.15, top=0.95)\n",
    "            plt.show()\n",
    "            fig.savefig(osp.join(\"./results\", train_date, test_name + \"-\" + str(count) + \"-overview.png\"))\n",
    "            fig.clear()\n",
    "            plt.close()\n",
    "    except Exception as e:\n",
    "        logger.error(str(e))\n",
    "        logger.error(traceback.format_exc())\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "from collections import namedtuple\n",
    "\n",
    "Size = namedtuple(\"Size\", [\"x\", \"y\"])\n",
    "\n",
    "weight_path = \"./weights/\"\n",
    "results_path = \"./results/\"\n",
    "train_date = \"2019-10-31\"\n",
    "weights = sorted(glob(osp.join(weight_path, train_date,\"*\",\"*\", \"*.h5\")), key=str.lower)\n",
    "#weights = [modelpath]\n",
    "INV_DPI = 1/100\n",
    "SCALE = 1/8\n",
    "\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_area_auto_adjustable\n",
    "\n",
    "def batch(iterable, n=1):\n",
    "    l = len(iterable)\n",
    "    counter = 0\n",
    "    for ndx in range(0, l, n):\n",
    "        counter += 1\n",
    "        yield counter, iterable[ndx:min(ndx + n, l)]\n",
    "\n",
    "def run_prediction(input_dict, target_dict, classes, colors, weight_list):\n",
    "    subslides = {}\n",
    "    num_classes = len(classes)\n",
    "    for name in target_dict.keys(): #[\"N9a-1\", \"T4a\"]:#\"N10a\", \"T4b-1\", \"T4b-2\"]:\n",
    "        subslides[name] = input_dict[name]\n",
    "    print(subslides.keys())\n",
    "    prediction_byte = {}\n",
    "    jaccard = {}\n",
    "    jaccard_weighted = {}\n",
    "    jaccard_weighted_nobg = {}\n",
    "\n",
    "    for count, b in batch(weight_list, 8):\n",
    "        row_titles = []\n",
    "        col_titles = classes.copy()\n",
    "        col_titles.extend([\"argmax\", \"target\", \"input\"])\n",
    "\n",
    "        pad = 5 # in points\n",
    "        #test_name = \"T4a\"\n",
    "        try:\n",
    "            fig, axes = {}, {}\n",
    "            for name, slide in subslides.items():\n",
    "                slide = np.squeeze(slide)\n",
    "                input_width = slide.shape[1]\n",
    "                input_height = slide.shape[0]\n",
    "                num_columns = num_classes+3\n",
    "                fig_width = input_width*INV_DPI*SCALE\n",
    "                fig_height = input_height*INV_DPI*SCALE\n",
    "                fig[name], axes[name] = plt.subplots(\n",
    "                    nrows=1,\n",
    "                    ncols=num_columns,\n",
    "                    sharex=True,\n",
    "                    sharey=True,\n",
    "                    figsize=(fig_width*num_columns, fig_height),\n",
    "                    gridspec_kw={'hspace': 0, 'wspace': 0}\n",
    "                )\n",
    "            for i, w in enumerate(b):\n",
    "                #sess = get_session()\n",
    "                #clear_session()\n",
    "                #sess.close()\n",
    "                #sess = get_session()\n",
    "\n",
    "                #config = tf.ConfigProto()\n",
    "                #config.gpu_options.allow_growth = True\n",
    "                #K.tensorflow_backend.set_session(tf.Session(config=config))\n",
    "                with tf.device('/cpu:*'): # Remember to re-indent model + compile below\n",
    "                #model = u_net(\n",
    "                #    (None, None, 3),\n",
    "                #    64,\n",
    "                #    sigma_noise=0,\n",
    "                #    depth=4,\n",
    "                #    dropout=0,\n",
    "                #    output_channels=num_cls,\n",
    "                #    batchnorm=True,\n",
    "                #    pretrain=0,\n",
    "                #)\n",
    "                    test_kwargs = model_kwargs\n",
    "                    test_kwargs[\"activation\"] = Swish\n",
    "                    test_kwargs[\"output_channels\"] = num_cls\n",
    "\n",
    "                #test_model = u_net(SHAPE, **test_kwargs)\n",
    "                    test_model = load_model(w, custom_objects={'Swish': Swish})\n",
    "\n",
    "                    test_model.compile(\n",
    "                        loss=categorical_crossentropy,\n",
    "                        optimizer=Adam(lr=0.001, decay=0),\n",
    "                        metrics=[\"acc\"],\n",
    "                    )\n",
    "\n",
    "                for test_name, slide in subslides.items():\n",
    "                    slide = np.squeeze(slide)\n",
    "                    loss_dir = str(osp.split(w)[0]).split('/')[-2]\n",
    "                    arch_dir = str(osp.split(w)[0]).split('/')[-1]\n",
    "                    base_name = osp.split(w)[-1]\n",
    "                    class_wgt_dir = 'weights_{}'.format('True' in str(base_name))\n",
    "                    act_dir = '{}'.format(base_name[base_name.rfind('activation_'):base_name.find('-dropout_')])\n",
    "                    init_dir = '{}'.format(base_name[base_name.rfind('initialization_'):base_name.find('-activation_')])\n",
    "                    #pre_dir = '{}'.format(base_name[base_name.rfind('pretrain_'):base_name.find('-sigma_')])\n",
    "                    res_path = osp.join(\n",
    "                        results_path,\n",
    "                        train_date,\n",
    "                        test_name,\n",
    "                        loss_dir,\n",
    "                        arch_dir,\n",
    "                        ' '.join([class_wgt_dir, init_dir, act_dir])\n",
    "                    )\n",
    "                    row_titles.append(loss_dir + '\\n' + class_wgt_dir + '\\n' +  act_dir + '\\n' +  init_dir)\n",
    "                    if not osp.exists(res_path):\n",
    "                        os.makedirs(res_path)\n",
    "                    raw_input = auto_contrast(slide)\n",
    "                    #test_model.load_weights(w)\n",
    "                    print(f\"slide: {slide.shape!s:>10}\")\n",
    "                    output = predict_window(test_model, slide, num_class=num_classes)\n",
    "                    prediction = colorvec[np.argmax(output, axis=-1)]\n",
    "                    prediction_byte[test_name] = np.argmax(output, axis=-1)\n",
    "                    target_byte = np.argmax(target_dict[test_name], axis=-1)\n",
    "                    print(f\"prediction_byte: {prediction_byte[test_name].shape!s:>10}\")\n",
    "                    print(f\"test_target: {test_targets[test_name].shape!s:>10}\")\n",
    "                    print(f\"test_target_byte: {target_byte.shape!s:>10}\")\n",
    "                    jaccard[test_name] = jaccard_score(np.ndarray.flatten(prediction_byte[test_name]),\n",
    "                                                       np.ndarray.flatten(target_byte),\n",
    "                                                       average=None)\n",
    "                    jaccard_weighted[test_name] = jaccard_score(np.ndarray.flatten(prediction_byte[test_name]),\n",
    "                                                       np.ndarray.flatten(target_byte),\n",
    "                                                       average='weighted')\n",
    "                    jaccard_weighted_nobg[test_name] = jaccard_score(np.ndarray.flatten(prediction_byte[test_name]),\n",
    "                                                       np.ndarray.flatten(target_byte),\n",
    "                                                       labels=active_labels[1:],\n",
    "                                                       average='weighted')\n",
    "                    if len(b) == 1:\n",
    "                        for j in range(num_classes):\n",
    "                            axes[test_name][j].imshow(output[:,:,j], cmap=\"jet\")\n",
    "                            plt.imsave(res_path + \"/result-{}.png\".format(classes[j]), output[:,:,j], cmap=\"jet\")\n",
    "                        axes[test_name][num_classes].imshow(prediction)\n",
    "                        axes[test_name][num_classes+1].imshow(colors[target_byte])\n",
    "                        axes[test_name][num_classes+2].imshow(raw_input)\n",
    "                    else:\n",
    "                        for j in range(num_classes):\n",
    "                            axes[test_name][i, j].imshow(output[:,:,j], cmap=\"jet\")\n",
    "                            plt.imsave(res_path + \"/result-{}.png\".format(classes[j]), output[:,:,j], cmap=\"jet\")\n",
    "                        axes[test_name][i, num_classes].imshow(prediction)\n",
    "                        axes[test_name][i, num_classes+1].imshow(colors[target_byte])\n",
    "                        axes[test_name][i, num_classes+2].imshow(raw_input)\n",
    "                    imsave(res_path + \"/result_argmax.png\", prediction.astype(np.uint8), check_contrast=False)\n",
    "                    imsave(res_path + \"/result_input.png\", np.array(raw_input*256., dtype=np.uint8), check_contrast=False)\n",
    "\n",
    "            for name in subslides.keys():\n",
    "                if len(b) == 1:\n",
    "                    for ax, col in zip(axes[name][:], col_titles):\n",
    "                        ax.set_title(col)\n",
    "                    for row in row_titles:\n",
    "                        axes[name][0].annotate(row, xy=(0, 0.5), xytext=(-axes[name][0].yaxis.labelpad - pad, 0),\n",
    "                        xycoords=axes[name][0].yaxis.label, textcoords='offset points',\n",
    "                        size='large', ha='right', va='center', wrap=True)\n",
    "                else:\n",
    "                    for ax, col in zip(axes[name][0], col_titles):\n",
    "                        ax.set_title(col)\n",
    "                    for ax, row in zip(axes[name][:,0], row_titles):\n",
    "                        ax.annotate(row, xy=(0, 0.5), xytext=(-ax.yaxis.labelpad - pad, 0),\n",
    "                        xycoords=ax.yaxis.label, textcoords='offset points',\n",
    "                        size='large', ha='right', va='center', wrap=True)\n",
    "                fig[name].tight_layout(pad=1.5)\n",
    "                fig[name].subplots_adjust(left=0.15, top=0.95)\n",
    "                plt.show()\n",
    "                fig[name].savefig(osp.join(\"./results\", train_date, name + \"-\" + str(count) + \"-overview.png\"))\n",
    "                fig[name].clear()\n",
    "                plt.close()\n",
    "        except Exception as e:\n",
    "            logger.error(str(e))\n",
    "            logger.error(traceback.format_exc())\n",
    "            raise\n",
    "\n",
    "merged_classes = ['Background', \"Healthy\", \"Cancer\", \"Other\"]\n",
    "merged_colors = np.array([[0, 0, 0], [0, 255, 0], [255, 0, 0], [128, 128, 128]])\n",
    "run_prediction(test_slides, binary_test_targets, merged_classes, merged_colors, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"jaccard:\", jaccard)\n",
    "print(\"jaccard_weighted: \", jaccard_weighted)\n",
    "print(\"jaccard_weighted_nobg: \", jaccard_weighted_nobg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "###################################\n",
    "#Clean session\n",
    "sess = get_session()\n",
    "clear_session()\n",
    "sess.close()\n",
    "# TensorFlow wizardry\n",
    "config = tf.ConfigProto(log_device_placement=True)\n",
    "\n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "# Only allow a total of half the GPU memory to be allocated\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "\n",
    "# Create a session with the above options specified.\n",
    "K.tensorflow_backend.set_session(tf.Session(config=config))\n",
    "###################################\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true,
    "tags": [
     "main",
     "train"
    ]
   },
   "outputs": [],
   "source": [
    "# I/O Params\n",
    "weight_path = \"./weights/\"\n",
    "remap_pattern = {0: [0, ], 1: [2, 3, 5], 2: [7, 8, 9], 3: [10, 1, 4, 6]}\n",
    "bin_class = len(remap_pattern)\n",
    "#IMG_ROWS, IMG_COLS, IMG_CHANNELS = (208, 208, 3)\n",
    "IMG_ROWS, IMG_COLS, IMG_CHANNELS = (None, None, 3)\n",
    "# architecture params\n",
    "NB_FILTERS_0 = 64\n",
    "SIGMA_NOISE = 0.01\n",
    "\n",
    "# ****  deep learning model\n",
    "SHAPE = (IMG_ROWS, IMG_COLS, IMG_CHANNELS)\n",
    "BATCH_SIZE = 12\n",
    "NB_EPOCH = 400\n",
    "NB_FROZEN = 40\n",
    "VERBOSE = 0\n",
    "# fit params\n",
    "today_str = str(datetime.date.today())\n",
    "DROP = 0\n",
    "\n",
    "OPT_NAME = \"adam\"  # choices:adadelta; sgd, rmsprop, adagrad, adam\n",
    "if OPT_NAME == \"sgd\":\n",
    "    OPT = SGD(lr=0.1)\n",
    "elif OPT_NAME == \"rmsprop\":\n",
    "    OPT = RMSprop()\n",
    "elif OPT_NAME == \"adagrad\":\n",
    "    OPT = Adagrad()\n",
    "elif OPT_NAME == \"adadelta\":\n",
    "    OPT = Adadelta()\n",
    "elif OPT_NAME == \"adam\":\n",
    "    OPT = Adam(lr=1e-3, decay=0.0)\n",
    "elif OPT_NAME == \"amsgrad\":\n",
    "    OPT = Adam(lr=1e-4, amsgrad=True)\n",
    "elif OPT_NAME == \"adamax\":\n",
    "    OPT = Adamax()\n",
    "elif OPT_NAME == \"nadam\":\n",
    "    OPT = Nadam()\n",
    "else:\n",
    "    raise NameError(\"Wrong optimizer name\")\n",
    "\n",
    "train_tiles = [\n",
    "    osp.splitext(osp.basename(i))[0]\n",
    "    for i in glob(osp.join(data_path, train_path, \"*.tif\"))\n",
    "]\n",
    "val_tiles = [\n",
    "    osp.splitext(osp.basename(i))[0]\n",
    "    for i in glob(osp.join(data_path, val_path, \"*.tif\"))\n",
    "]\n",
    "\n",
    "train_generator = DataGenerator(\n",
    "    osp.join(data_path, train_path),\n",
    "    colorvec,\n",
    "    train_m,\n",
    "    train_s,\n",
    "    x_min,\n",
    "    x_max,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    dim=(208, 208),\n",
    "    n_channels=3,\n",
    "    n_classes=bin_class,\n",
    "    shuffle=True,\n",
    "    augmenter=True,\n",
    "    remap_labels=remap_pattern\n",
    ")\n",
    "\n",
    "val_generator = DataGenerator(\n",
    "    osp.join(data_path, val_path),\n",
    "    colorvec,\n",
    "    train_m,\n",
    "    train_s,\n",
    "    x_min,\n",
    "    x_max,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    dim=(208, 208),\n",
    "    n_channels=3,\n",
    "    n_classes=bin_class,\n",
    "    shuffle=True,\n",
    "    augmenter=True,\n",
    "    remap_labels=remap_pattern\n",
    ")\n",
    "\n",
    "model_kwargs = {\n",
    "    \"nb_filters\": NB_FILTERS_0,\n",
    "    \"sigma_noise\": SIGMA_NOISE,\n",
    "    \"depth\": 4,\n",
    "    \"maxpool\": False,\n",
    "    \"initialization\": \"he_normal\",\n",
    "    \"activation\": \"Swish\",\n",
    "    \"dropout\": 0,\n",
    "    \"batchnorm\": True,\n",
    "    \"arch\": \"U-Net\",\n",
    "}\n",
    "\n",
    "model_base_path = osp.join(weight_path, today_str, \"cat_CE\", \"arch-\" + model_kwargs[\"arch\"])\n",
    "\n",
    "path_elements = [\n",
    "    '{}_{}'.format(key, val.__name__)\n",
    "    if hasattr(val, '__name__')\n",
    "    else '{}_{}'.format(key, val) for key, val in model_kwargs.items()\n",
    "]\n",
    "path_elements.remove('{}_{}'.format(\"arch\", model_kwargs[\"arch\"]))\n",
    "path_elements.append(\"remapped_labels\")\n",
    "\n",
    "if not os.path.exists(model_base_path):\n",
    "    os.makedirs(model_base_path, exist_ok=True)\n",
    "\n",
    "modelpath = osp.join(\n",
    "    model_base_path,\n",
    "    '-'.join(path_elements) + \".h5\"\n",
    ")\n",
    "\n",
    "log_path = osp.join(\n",
    "    \"./logs/\",\n",
    "    today_str,\n",
    "    \"cat_CE\",\n",
    "    model_kwargs[\"arch\"],\n",
    "    *path_elements, ''\n",
    ")\n",
    "\n",
    "#model = u_net(SHAPE, NB_FILTERS_0, depth=3, dropout=DROP, batchnorm=True, maxpool=False, output_channels=num_cls, resnet=True)\n",
    "model = load_model(osp.join(weight_path,\"2019-09-20\",\"pretrain_U-net_model.h5\"), custom_objects={'Swish': Swish})\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D\n",
    "model_inputs = model.inputs\n",
    "model_preout = model.layers[-2].output\n",
    "new_output = Conv2D(bin_class, 1, activation=\"softmax\", name=\"conv_out\")(model_preout)\n",
    "model = Model(inputs=model.inputs, outputs=new_output)\n",
    "pretrain_layers = [\n",
    "    \"block{}_d_conv{}\".format(block, layer)\n",
    "    for block in range(1, 4 + 1)\n",
    "    for layer in range(1, 3)\n",
    "]\n",
    "for i, n in enumerate(pretrain_layers):\n",
    "    model.get_layer(name=n).trainable = False\n",
    "model.compile(loss=categorical_crossentropy, optimizer=Adam(lr=1e-3, decay=0.0), metrics=[\"acc\"])\n",
    "\n",
    "print(model.summary(line_length=124))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": [
     "main",
     "train"
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"from keras_tqdm import TQDMNotebookCallback\n",
    "from mmciad.utils.callbacks import PatchedModelCheckpoint\n",
    "\n",
    "#class_weights = [1 if k != 12 else 0 for k in active_labels]\n",
    "\n",
    "progressbar = TQDMNotebookCallback(\n",
    "    metric_format=\"{name}: {value:0.4f}\", leave_inner=True, leave_outer=True\n",
    ")\n",
    "tensor_board = TensorBoard(\n",
    "    log_dir=log_path,\n",
    "    histogram_freq=0,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    write_graph=True,\n",
    "    write_grads=False,\n",
    "    write_images=True,\n",
    "    embeddings_freq=0,\n",
    "    update_freq=\"epoch\"\n",
    ")\n",
    "early_stopper = EarlyStopping(monitor=\"loss\", patience=40, verbose=1, mode=\"auto\")\n",
    "reducer = ReduceLROnPlateau(\n",
    "    monitor=\"loss\",\n",
    "    factor=0.1,\n",
    "    patience=10,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1,\n",
    ")\n",
    "model_checkpoint = PatchedModelCheckpoint(\n",
    "    modelpath, verbose=0, monitor=\"loss\", save_best_only=True,\n",
    ")\n",
    "model_callbacks = [progressbar, tensor_board, early_stopper, reducer, model_checkpoint]\n",
    "\n",
    "frozen_history = model.fit_generator(\n",
    "    generator=train_generator,\n",
    "    epochs=NB_FROZEN,\n",
    "    validation_data=val_generator,\n",
    "    use_multiprocessing=True,\n",
    "    workers=30,\n",
    "    verbose=VERBOSE,\n",
    "    callbacks=model_callbacks,\n",
    ")\n",
    "\"\"\"\n",
    "model = load_model(modelpath, custom_objects={'Swish': Swish})\n",
    "\n",
    "for n in pretrain_layers:\n",
    "    model.get_layer(name=n).trainable = True\n",
    "\n",
    "model.compile(loss=categorical_crossentropy, optimizer=Adam(lr=1e-4, decay=0.0), metrics=[\"acc\"])\n",
    "\n",
    "history = model.fit_generator(\n",
    "    generator=train_generator,\n",
    "    epochs=NB_EPOCH,\n",
    "    initial_epoch=NB_FROZEN,\n",
    "    validation_data=val_generator,\n",
    "    use_multiprocessing=True,\n",
    "    workers=30,\n",
    "    verbose=VERBOSE,\n",
    "    callbacks=model_callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "min_loss = np.argmin(history.history['loss'])\n",
    "epoch_init = 39+1\n",
    "print(\"Best loss: %.5f\" % (np.min(history.history['loss'])))\n",
    "print(\"at: %d\" % (epoch_init+min_loss))\n",
    "print(f\"accuracy at {epoch_init+min_loss}:            {history.history['acc'][min_loss]:.5f}\")\n",
    "print(f\"validation accuracy at {epoch_init+min_loss}: {history.history['val_acc'][min_loss]:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": [
     "main",
     "test"
    ]
   },
   "outputs": [],
   "source": [
    "abr = [\"cc\", \"wcc\", \"tl\", \"wtl\"]\n",
    "lf = [\n",
    "    \"categorical_crossentropy\",\n",
    "    \"weighted_categorical_crossentropy\",\n",
    "    \"tversky_loss\",\n",
    "    \"weighted_tversky_loss\",\n",
    "]\n",
    "test_slides = load_slide(path, \"test\", train_m, train_s, False)\n",
    "model_path = \"./weights/\"\n",
    "results_path = \"./results/\"\n",
    "train_date = \"2019-06-03\"\n",
    "pred_slide = [[None] * len(abr) for _ in range(test_slides.shape[0])]\n",
    "for short, long, outer in zip(abr, lf, range(len(abr))):\n",
    "    weights = osp.join(model_path, train_date,\n",
    "                       \"batchnorm_U-net_model-200epochs_batchsize_16.loss_func_{}-weights.pickle\".format(long))\n",
    "    load_weight_light(model, weights)\n",
    "    if not osp.exists(osp.join(results_path, train_date)):\n",
    "        os.mkdir(osp.join(results_path, train_date))\n",
    "    for i, slide in enumerate(test_slides):\n",
    "        pred_slide[i][outer] = predict_window(slide)\n",
    "\n",
    "    for i, slide in enumerate([sublist[outer] for sublist in pred_slide], 1):\n",
    "        plt.subplot(len(abr) + 1, test_slides.shape[0], i + outer * (len(abr) - 1))\n",
    "        plt.imshow(colorvec[np.argmax(slide, axis=-1)])\n",
    "        imsave(\n",
    "            \"./results/{}/{}-{}.png\".format(train_date, short, i),\n",
    "            colorvec[np.argmax(slide, axis=-1)].astype(np.uint8),\n",
    "            check_contrast=False,\n",
    "        )\n",
    "\n",
    "mean_pred = [None] * len(test_slides)\n",
    "for i, yhat in enumerate(pred_slide):\n",
    "    mean_pred[i] = np.asarray(yhat).mean(axis=0)\n",
    "    plt.subplot(len(abr) + 1, test_slides.shape[0], 1 + i + len(abr) * (len(abr) - 1))\n",
    "    plt.imshow(colorvec[np.argmax(mean_pred[i], axis=-1)])\n",
    "    imsave(\n",
    "        \"./results/{}/mean-{}.png\".format(train_date, i + 1),\n",
    "        colorvec[np.argmax(mean_pred[i], axis=-1)].astype(np.uint8),\n",
    "        check_contrast=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "## Manual Talos prediction\n",
    "test_slides = load_slide(path, \"test\", train_m, train_s, False)\n",
    "model_path = \"./weights/\"\n",
    "results_path = \"./results/\"\n",
    "train_date = \"2019-06-06\"\n",
    "\n",
    "img_rows, img_cols, img_channels = (None, None, 3)\n",
    "# architecture params\n",
    "nb_filters_0 = 64\n",
    "batchnorm = True\n",
    "\n",
    "# ****  deep learning model\n",
    "shape = (img_rows, img_cols, img_channels)\n",
    "batch_size = 16\n",
    "nb_epoch = 200\n",
    "verbose = 0\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20.0, 16.0)\n",
    "\n",
    "weight_pickles = sorted(glob(osp.join(model_path, train_date,\n",
    "                       \"talos_bn_U-net_model-200epochs-*.pickle\")), key=str.lower)\n",
    "pred_slide = [[None] * len(weight_pickles) for _ in range(test_slides.shape[0])]\n",
    "for outer, w in enumerate(weight_pickles[4:]):\n",
    "    if \"cat_FL\" in w:\n",
    "        loss_func = categorical_focal_loss()\n",
    "    elif \"cat_CE\" in w:\n",
    "        loss_func = categorical_crossentropy\n",
    "    else:\n",
    "        raise NameError(\"Something's wrong!\")\n",
    "    \n",
    "    if \"pretrain_2\" in w:\n",
    "        pt = 2\n",
    "    else:\n",
    "        pt = 0\n",
    "    \n",
    "    if \"sigma_0.005\" in w:\n",
    "        sigma = 0.005\n",
    "    else:\n",
    "        sigma = 0\n",
    "\n",
    "    if \"drop_0.05\" in w:\n",
    "        drop = 0.05\n",
    "    else:\n",
    "        drop = 0\n",
    "\n",
    "    model = u_net(shape, nb_filters_0, sigma_noise=sigma, depth=4,\n",
    "                  dropout=drop, output_channels=num_cls, batchnorm=True, pretrain=pt)\n",
    "    model.compile(loss=loss_func, optimizer=Adam(lr=1e-4, decay=0.1))\n",
    "    load_weight_light(model, w)\n",
    "    \n",
    "    if not osp.exists(osp.join(results_path, train_date)):\n",
    "        os.mkdir(osp.join(results_path, train_date))\n",
    "    for i, slide in enumerate(test_slides):\n",
    "        pred_slide[i][outer] = predict_window(slide)\n",
    "\n",
    "    for i, slide in enumerate([sublist[outer] for sublist in pred_slide], 1):\n",
    "        plt.subplot(len(weight_pickles), test_slides.shape[0], i + outer * (test_slides.shape[0]))\n",
    "        plt.imshow(colorvec[np.argmax(slide, axis=-1)])\n",
    "        imsave(\n",
    "            \"./results/{}/{}-{}.png\".format(train_date, osp.split(w)[-1], i),\n",
    "            colorvec[np.argmax(slide, axis=-1)].astype(np.uint8),\n",
    "            check_contrast=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": [
     "visuals"
    ]
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "\n",
    "model.load_weights(\n",
    "    path\n",
    "    + \"U-net_model_200epochs.batchsize_16.loss_func_weighted_categorical_crossentropy-weights.h5\"\n",
    ")\n",
    "print(len(model.layers))\n",
    "layer_outputs = [layer.output for layer in model.layers[:10]]\n",
    "activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "\n",
    "activations = activation_model.predict(np.expand_dims(test_slides[1], axis=0))\n",
    "\n",
    "layer_names = []\n",
    "for layer in classifier.layers[:10]:\n",
    "    layer_names.append(\n",
    "        layer.name\n",
    "    )  # Names of the layers, so you can have them as part of your plot\n",
    "\n",
    "images_per_row = 16\n",
    "\n",
    "for layer_name, layer_activation in zip(\n",
    "    layer_names, activations\n",
    "):  # Displays the feature maps\n",
    "    n_features = layer_activation.shape[-1]  # Number of features in the feature map\n",
    "    size = layer_activation.shape[\n",
    "        1\n",
    "    ]  # The feature map has shape (1, size, size, n_features).\n",
    "    n_cols = (\n",
    "        n_features // images_per_row\n",
    "    )  # Tiles the activation channels in this matrix\n",
    "    display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "    for col in range(n_cols):  # Tiles each filter into a big horizontal grid\n",
    "        for row in range(images_per_row):\n",
    "            channel_image = layer_activation[0, :, :, col * images_per_row + row]\n",
    "            channel_image -= (\n",
    "                channel_image.mean()\n",
    "            )  # Post-processes the feature to make it visually palatable\n",
    "            channel_image /= channel_image.std()\n",
    "            channel_image *= 64\n",
    "            channel_image += 128\n",
    "            channel_image = np.clip(channel_image, 0, 255).astype(\"uint8\")\n",
    "            display_grid[\n",
    "                col * size : (col + 1) * size,  # Displays the grid\n",
    "                row * size : (row + 1) * size,\n",
    "            ] = channel_image\n",
    "    scale = 1. / size\n",
    "    plt.figure(figsize=(scale * display_grid.shape[1], scale * display_grid.shape[0]))\n",
    "    plt.title(layer_name)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(display_grid, aspect=\"auto\", cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": [
     "visuals"
    ]
   },
   "outputs": [],
   "source": [
    "from keract import get_activations, display_activations\n",
    "print(test_slides[1].shape)\n",
    "with tf.device('/cpu:*'):\n",
    "    cpumodel = u_net(\n",
    "        (None, None, 3),\n",
    "        64,\n",
    "        sigma_noise=0,\n",
    "        depth=4,\n",
    "        dropout=0,\n",
    "        output_channels=num_cls,\n",
    "        batchnorm=True,\n",
    "        pretrain=0,\n",
    "    )\n",
    "\n",
    "    cpumodel.compile(\n",
    "        loss=categorical_crossentropy,\n",
    "        optimizer=Adam(lr=0.001, decay=0),\n",
    "        metrics=[\"acc\"],\n",
    "    )\n",
    "\n",
    "#plt.rcParams['figure.figsize'] = (20.0, 16.0)\n",
    "weights = sorted(glob(osp.join(weight_path, \"2019-06-24\",\"*\", \"*.h5\")), key=str.lower)\n",
    "\n",
    "for i, w in enumerate(weights):\n",
    "    #p = ta.Predict(t)\n",
    "    #output.append(talos_predict_window(test_slides[1]))\n",
    "    cpumodel.load_weights(w)\n",
    "    activations = get_activations(cpumodel, np.expand_dims(test_slides[1], axis=0), \"block1_conv2\")\n",
    "    display_activations(activations, cmap=\"gray\", save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": [
     "visuals"
    ]
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 12))\n",
    "plt.imshow(imread(\"./data/test-N9a-corrected-1.tif\")[-2048:, 500:2548, :])\n",
    "rows = 4\n",
    "columns = 8\n",
    "figact1, axs = plt.subplots(\n",
    "    ncols=columns, nrows=rows, sharex=True, sharey=True, figsize=(12, 12)\n",
    ")\n",
    "first = activations.get(\"conv1_2_1/Relu:0\")\n",
    "print(first.shape)\n",
    "print(first.min(), first.max())\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    img = first[0, :, :, i]\n",
    "    im = ax.imshow(img, cmap=\"jet\")\n",
    "    plt.axis(\"off\")\n",
    "axcb = figact1.colorbar(im, ax=axs.ravel().tolist(), pad=0.04, aspect=30)\n",
    "plt.show()\n",
    "rows = 8\n",
    "columns = 8\n",
    "figact2, axs = plt.subplots(\n",
    "    ncols=columns, nrows=rows, sharex=True, sharey=True, figsize=(12, 12)\n",
    ")\n",
    "second = activations.get(\"conv2_2_1/Relu:0\")\n",
    "print(second.shape)\n",
    "print(second.min(), second.max())\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    img = second[0, :, :, i]\n",
    "    im = ax.imshow(img, cmap=\"jet\")\n",
    "    plt.axis(\"off\")\n",
    "axcb = figact2.colorbar(im, ax=axs.ravel().tolist(), pad=0.04, aspect=30)\n",
    "plt.show()\n",
    "rows = 16\n",
    "columns = 8\n",
    "figact3, axs = plt.subplots(\n",
    "    ncols=columns, nrows=rows, sharex=True, sharey=True, figsize=(12, 12)\n",
    ")\n",
    "third = activations.get(\"conv3_2_1/Relu:0\")\n",
    "print(third.shape)\n",
    "print(third.min(), third.max())\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    img = third[0, :, :, i]\n",
    "    im = ax.imshow(img, cmap=\"jet\")\n",
    "    plt.axis(\"off\")\n",
    "axcb = figact3.colorbar(im, ax=axs.ravel().tolist(), pad=0.04, aspect=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "random_input_image = np.random.random((1, IMG_ROWS, IMG_COLS, IMG_CHANNELS)) * 20 + 128.\n",
    "output_image = model.get_layer('conv_out').output\n",
    "input_image = model.get_layer('input_layer').input\n",
    "target_class = active_labels.index(class_map['Cancer'])\n",
    "\n",
    "loss = (K.mean(output_image[...,target_class], axis=-1)\n",
    "       -K.mean(\n",
    "           K.concatenate((\n",
    "               output_image[...,:target_class],\n",
    "               output_image[...,target_class+1:]\n",
    "               )), axis=-1)\n",
    "       )\n",
    "step = 1.\n",
    "grads = K.gradients(loss, input_image)[0] \n",
    "def normalize(x):\n",
    "    # utility function to normalize a tensor by its L2 norm\n",
    "    return x / (K.sqrt(K.mean(K.square(x))) + 1e-5)\n",
    "grads = normalize(grads)\n",
    "iterate = K.function([input_image], [loss, grads])\n",
    "for i in range(30):\n",
    "    loss_value, grads_value = iterate([random_input_image])\n",
    "    random_input_image += grads_value * step\n",
    "def deprocess_image(x):\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "result_img = deprocess_image(random_input_image[0])\n",
    "plt.rcParams[\"figure.figsize\"] = (12.0, 12.0)\n",
    "plt.imshow(result_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train_slides = load_slides_as_dict(data_path,'train', load_gt=False)\n",
    "print(len(train_slides))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import seaborn as sns\n",
    "num_slides = len(train_slides)\n",
    "plt.rcParams[\"figure.figsize\"] = (20.0, 24.0)\n",
    "fig, axes = plt.subplots(nrows=num_slides, ncols=3)\n",
    "for (row, (name, img)), col in product(enumerate(train_slides.items()), range(3)):\n",
    "    axes[row][col].set_ylabel(name)\n",
    "    sns.distplot(a = np.ravel(img[...,col])*255, bins=256, hist=True, ax=axes[row][col])\n",
    "axes[0][0].set_title(\"SHG\")\n",
    "axes[0][1].set_title(\"CARS\")\n",
    "axes[0][2].set_title(\"TPEF\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2.2 (Python 3.8.2)",
   "language": "python",
   "name": "py38-tf22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "043d97a3b8c04fd08bfe9dbf4bbd7046": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_ee236b4a920343aa9d3ead7daecf02c4",
        "IPY_MODEL_141f0528f0434415be43e0fc363ef925"
       ],
       "layout": "IPY_MODEL_5d1097789f4b4dcfad7b65e31b95097c"
      }
     },
     "0a7694f1b1884d7bb1033e18b76ec516": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "141f0528f0434415be43e0fc363ef925": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_c3240166784d47269a82dd13afd5b23b",
       "style": "IPY_MODEL_414721cb5cc14798a1ce042b0928bf3b",
       "value": " 48/48 [04:20&lt;00:00,  5.43s/it]"
      }
     },
     "19edca90bee94a7aa61d378964c5cc3a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "1dc42ad5f6fe472888b3a8efb86087b9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "23a0b9b05a7c448c880e8b532579304a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3a2741c716cd4708899547e99820edac": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3b7f2b243e4041908573ea2a2f3a498e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "40568be930874b31a24f51a9d100ed62": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_46da599069cc4bfb99b8a7bfc58356e3",
       "style": "IPY_MODEL_970b49f6261e45ba8424b7c287aa297d",
       "value": " 17346/? [14:26&lt;00:00, 20.02it/s]"
      }
     },
     "414721cb5cc14798a1ce042b0928bf3b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "467e3974f4f24dce9cc0656bf87e13d1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "46da599069cc4bfb99b8a7bfc58356e3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "47df57f591c0409b8167076825b1ce41": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "4d9033ee79e54fb5a29bb78efe16c850": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "4dfd1adf0c6a4d6c84e6a5767d0157de": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_0a7694f1b1884d7bb1033e18b76ec516",
       "style": "IPY_MODEL_47df57f591c0409b8167076825b1ce41",
       "value": " 48/48 [01:19&lt;00:00,  1.66s/it]"
      }
     },
     "5346ea70bc4543458af1f611f3471e14": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "5d1097789f4b4dcfad7b65e31b95097c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5de2cf30bb6c498cb67555692a15d204": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_23a0b9b05a7c448c880e8b532579304a",
       "max": 17082,
       "style": "IPY_MODEL_3b7f2b243e4041908573ea2a2f3a498e",
       "value": 17082
      }
     },
     "5ef3017da7ef475aa551113c5b01e302": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_9ac1ca6313344a1aafeceb3bdccfeb72",
       "style": "IPY_MODEL_1dc42ad5f6fe472888b3a8efb86087b9",
       "value": " 1/1 [09:53&lt;00:00, 593.15s/it]"
      }
     },
     "5f21ee4899394061a396c71f94d84901": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6e8d0de6576146fd8c00d2060f729a8a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "6fb21b3b6bff4200a353a292d3f6e8cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "85d9763acc604c66986ca4c97239e9b7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8835e2e1a7fa47c78f9057c0212cdd1e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8837ccfb6e274caf8dd5635dcba7e21a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "95d0d9e358894bffbead153e10b62288": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_9f230aee82654d09bf999abe47871d8d",
        "IPY_MODEL_b394ab042eff4789bf2fa5e77d3b7751"
       ],
       "layout": "IPY_MODEL_3a2741c716cd4708899547e99820edac"
      }
     },
     "970b49f6261e45ba8424b7c287aa297d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "9ac1ca6313344a1aafeceb3bdccfeb72": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9f230aee82654d09bf999abe47871d8d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "100%",
       "layout": "IPY_MODEL_467e3974f4f24dce9cc0656bf87e13d1",
       "max": 413,
       "style": "IPY_MODEL_6e8d0de6576146fd8c00d2060f729a8a",
       "value": 413
      }
     },
     "aa5891959e8b49e1ad471a9be3f284f0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ad822cf373fc403392a133bc8b2491e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_e2fe27f79a474f1d9a4a90fc77c3587f",
        "IPY_MODEL_4dfd1adf0c6a4d6c84e6a5767d0157de"
       ],
       "layout": "IPY_MODEL_f20f53eef4074783aea167040caba921"
      }
     },
     "b394ab042eff4789bf2fa5e77d3b7751": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_c4cc0faac5354cbc820bcf2ac858cbc2",
       "style": "IPY_MODEL_4d9033ee79e54fb5a29bb78efe16c850",
       "value": " 413/413 [06:03&lt;00:00,  1.14it/s]"
      }
     },
     "c3240166784d47269a82dd13afd5b23b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c4cc0faac5354cbc820bcf2ac858cbc2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c6a244781210447cbb1cb2987b4cf9d3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c7549bbd7a2944ec9a90937fedf3cd27": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "100%",
       "layout": "IPY_MODEL_aa5891959e8b49e1ad471a9be3f284f0",
       "max": 1,
       "style": "IPY_MODEL_5346ea70bc4543458af1f611f3471e14",
       "value": 1
      }
     },
     "ce1c9ff385d740e8854e9875a3b7aa76": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "d002a6fbfa4c436dbe654076e8ef4c37": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "100%",
       "layout": "IPY_MODEL_85d9763acc604c66986ca4c97239e9b7",
       "max": 1,
       "style": "IPY_MODEL_ce1c9ff385d740e8854e9875a3b7aa76",
       "value": 1
      }
     },
     "da4657f89fcf421f9dc79d8d6462e591": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_5de2cf30bb6c498cb67555692a15d204",
        "IPY_MODEL_40568be930874b31a24f51a9d100ed62"
       ],
       "layout": "IPY_MODEL_8837ccfb6e274caf8dd5635dcba7e21a"
      }
     },
     "debd1f769f3043b5a817a804b79be51d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e2fe27f79a474f1d9a4a90fc77c3587f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "100%",
       "layout": "IPY_MODEL_5f21ee4899394061a396c71f94d84901",
       "max": 48,
       "style": "IPY_MODEL_6fb21b3b6bff4200a353a292d3f6e8cb",
       "value": 48
      }
     },
     "ee236b4a920343aa9d3ead7daecf02c4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "100%",
       "layout": "IPY_MODEL_8835e2e1a7fa47c78f9057c0212cdd1e",
       "max": 48,
       "style": "IPY_MODEL_19edca90bee94a7aa61d378964c5cc3a",
       "value": 48
      }
     },
     "f1c6ab22e74c484392e641711564d197": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_c7549bbd7a2944ec9a90937fedf3cd27",
        "IPY_MODEL_5ef3017da7ef475aa551113c5b01e302"
       ],
       "layout": "IPY_MODEL_c6a244781210447cbb1cb2987b4cf9d3"
      }
     },
     "f20f53eef4074783aea167040caba921": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f4544a6ac7254267aed0efd1b0cff8dd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f5075235a97a48469a7e59f78cbd4e3e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_d002a6fbfa4c436dbe654076e8ef4c37",
        "IPY_MODEL_faee12e2b30b405188e557a97da6f04c"
       ],
       "layout": "IPY_MODEL_f4544a6ac7254267aed0efd1b0cff8dd"
      }
     },
     "faee12e2b30b405188e557a97da6f04c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_debd1f769f3043b5a817a804b79be51d",
       "style": "IPY_MODEL_fd28991404d54c0bb6cf6c4659593e6d",
       "value": " 1/1 [07:02&lt;00:00, 422.68s/it]"
      }
     },
     "fd28991404d54c0bb6cf6c4659593e6d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
